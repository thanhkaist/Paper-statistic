      <p><b>Non-Asymptotic Analysis of Fractional Langevin Monte Carlo for Non-Convex Optimization</b><br><i>Thanh Huy Nguyen (Telecom ParisTech) &middot; Umut Simsekli (Telecom ParisTech) &middot; Gaël RICHARD (Télécom ParisTech)</i></p>
      <p><b>A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks</b><br><i>Umut Simsekli (Telecom ParisTech) &middot; Levent Sagun (CEA) &middot; Mert Gurbuzbalaban (Rutgers University)</i></p>
      <p><b>Sliced-Wasserstein Flows: Nonparametric Generative Modeling via Optimal Transport and Diffusions</b><br><i>Antoine Liutkus (Inria) &middot; Umut Simsekli (Telecom ParisTech) &middot; Szymon Majewski (IMPAN) &middot; Alain Durmus (ENS) &middot; Fabian-Robert Stöter (Inria)</i></p>
      <p><b>Automatic Classifiers as Scientific Instruments: One Step Further Away from Ground-Truth</b><br><i>Jacob Whitehill (Worcester Polytechnic Institute) &middot; Anand Ramakrishnan (Worcester Polytechnic Institute)</i></p>
      <p><b>Decentralized Exploration in Multi-Armed Bandits</b><br><i>Raphael Feraud (Orange Labs) &middot; REDA ALAMI (Orange Labs - Paris Saclay University - INRIA) &middot; Romain Laroche (Microsoft Research)</i></p>
      <p><b>Unsupervised Deep Learning by Neighbourhood Discovery</b><br><i>Jiabo Huang (Queen Mary University of London) &middot; Qi Dong (Queen Mary University of London) &middot; Shaogang Gong (Queen Mary University of London) &middot; Xiatian Zhu (Vision Semantics Limited)</i></p>
      <p><b>Statistical Foundations of Virtual Democracy</b><br><i>Anson Kahng (Carnegie Mellon University) &middot; Min Kyung Lee (CMU) &middot; Ritesh Noothigattu (Carnegie Mellon University) &middot; Ariel Procaccia (Carnegie Mellon University) &middot; Christos-Alexandros Psomas (Carnegie Mellon University)</i></p>
      <p><b>DP-GP-LVM: A Bayesian Non-Parametric Model for Learning Multivariate Dependency Structures</b><br><i>Andrew R Lawrence (University of Bath) &middot; Carl Henrik Ek (University of Bristol) &middot; Neill Campbell (University of Bath)</i></p>
      <p><b>Complexity of Linear Regions in Deep Networks</b><br><i>Boris Hanin (Texas A&M) &middot; David Rolnick (University of Pennsylvania)</i></p>
      <p><b>Linear-Complexity Data-Parallel Earth Mover&#39;s Distance Approximations</b><br><i>Kubilay Atasu (IBM Research - Zurich) &middot; Thomas Mittelholzer (HSR Univ. Applied Sciences, Rapperswil, Switzerland)</i></p>
      <p><b>Communication Constrained Inference and the Role of Shared Randomness</b><br><i>Jayadev Acharya (Cornell University) &middot; Clément Canonne (Stanford University) &middot; Himanshu Tyagi (IISC)</i></p>
      <p><b>Communication Complexity in Locally Private Distribution Estimation and Heavy Hitters</b><br><i>Jayadev Acharya (Cornell University) &middot; Ziteng Sun (Cornell University)</i></p>
      <p><b>Domain Agnostic Learning with Disentangled Representations</b><br><i>Xingchao Peng (Boston University) &middot; Zijun Huang (Columbia University) &middot; Ximeng Sun (Boston University) &middot; Kate Saenko (Boston University)</i></p>
      <p><b>Sever: A Robust Meta-Algorithm for Stochastic Optimization</b><br><i>Ilias Diakonikolas (USC) &middot; Gautam Kamath (MIT) &middot; Daniel Kane (UCSD) &middot; Jerry Li (MIT) &middot; Jacob Steinhardt (University of California, Berkeley) &middot; Alistair Stewart (University of Southern California)</i></p>
      <p><b>Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations</b><br><i>Tri Dao (Stanford University) &middot; Albert Gu (Stanford University) &middot; Matthew Eichhorn (University at Buffalo) &middot; Atri Rudra (University at Buffalo, SUNY) &middot; Christopher Re (Stanford)</i></p>
      <p><b>Fast Incremental von Neumann Graph Entropy Computation: Theory, Algorithm, and Applications</b><br><i>Pin-Yu Chen (IBM Research AI) &middot; Lingfei Wu (IBM Research) &middot; Sijia Liu (MIT-IBM Watson AI Lab) &middot; Indika Rajapakse ()</i></p>
      <p><b>Training Neural Networks with Local Error Signals</b><br><i>Arild Nøkland (Kongsberg Seatex) &middot; Lars Hiller Eidnes (None)</i></p>
      <p><b>Batch Policy Learning under Constraints</b><br><i>Hoang Le (Caltech) &middot; Cameron Voloshin (Caltech) &middot; Yisong Yue (Caltech)</i></p>
      <p><b>Exploration Conscious Reinforcement Learning Revisited</b><br><i>Lior Shani (Technion) &middot; Yonathan Efroni (Technion) &middot; Shie Mannor (Technion)</i></p>
      <p><b>Temporal Gaussian Mixture Layer for Videos</b><br><i>AJ Piergiovanni (Indiana University) &middot; Michael Ryoo (EgoVid / Indiana University)</i></p>
      <p><b>Probabilistic Neural Symbolic Models for Interpretable Visual Question Answering</b><br><i>Ramakrishna Vedantam (Facebook AI Research) &middot; Karan Desai (Georgia Tech) &middot; Stefan Lee (Georgia Institute of Technology) &middot; Marcus Rohrbach (Facebook AI Research) &middot; Dhruv Batra (Georgia Institute of Technology / Facebook AI Research) &middot; Devi Parikh (Georgia Tech & Facebook AI Research)</i></p>
      <p><b>Unifying Orthogonal Monte Carlo Methods</b><br><i>Krzysztof Choromanski (Google Brain Robotics) &middot; Mark Rowland (University of Cambridge) &middot; Wenyu Chen (MIT) &middot; Adrian Weller (University of Cambridge, Alan Turing Institute)</i></p>
      <p><b>TibGM: A Transferable and Information-Based Graphical Model Approach for Reinforcement Learning</b><br><i>Tameem Adel (University of Cambridge) &middot; Adrian Weller (University of Cambridge, Alan Turing Institute)</i></p>
      <p><b>SELFIE: Refurbishing Unclean Samples for Robust Deep Learning</b><br><i>Hwanjun Song (KAIST) &middot; Minseok Kim (KAIST) &middot; Jae-Gil Lee (KAIST)</i></p>
      <p><b>Statistics and Samples in Distributional Reinforcement Learning</b><br><i>Mark Rowland (DeepMind) &middot; Robert Dadashi (Google AI Residency Program) &middot; Saurabh Kumar (Google) &middot; Remi Munos (DeepMind) &middot; Marc Bellemare (Google Brain) &middot; Will Dabney (DeepMind)</i></p>
      <p><b>Revisiting precision recall definition for generative modeling</b><br><i>Loic Simon (GREYC ENSICAEN) &middot; Ryan Webster (UniCaen) &middot; Julien Rabin (Unicaen)</i></p>
      <p><b>Action Robust Reinforcement Learning and Applications in Continuous Control</b><br><i>Chen Tessler (Technion) &middot; Yonathan Efroni (Technion) &middot; Shie Mannor (Technion)</i></p>
      <p><b>Anomaly Detection With Multiple-Hypotheses Predictions</b><br><i>Duc Tam Nguyen (University of Freiburg) &middot; Zhongyu Lou (Bosch) &middot; Michael Klar (Bosch) &middot; Thomas Brox (University of Freiburg)</i></p>
      <p><b>Band-limited Training and Inference for Convolutional Neural Network</b><br><i>Adam Dziedzic (University of Chicago) &middot; John Paparrizos (University of Chicago) &middot; Sanjay Krishnan (U Chicago) &middot; Aaron Elmore (University of Chicago) &middot; Michael Franklin (University of Chicago)</i></p>
      <p><b>Greedy Layerwise Learning Can Scale To ImageNet</b><br><i>Eugene Belilovsky (Mila, University of Montreal) &middot; Michael Eickenberg (UC Berkeley) &middot; Edouard Oyallon (CentraleSupélec)</i></p>
      <p><b>Monge blunts Bayes: Hardness Results for Adversarial Training</b><br><i>Zac Cranko (ANU) &middot; Aditya Menon (Google Research) &middot; Richard Nock (Data61, The Australian National University and the University of Sydney) &middot; Cheng Soon Ong (Data61 and ANU) &middot; Zhan Shi (University of Illinois at Chicago) &middot; Christian Walder (Data61, the Australian National University)</i></p>
      <p><b>Adaptive Monte Carlo Multiple Testing via Multi-Armed Bandits</b><br><i>Martin Zhang (Stanford University) &middot; James Zou (Stanford) &middot; David Tse (Stanford University)</i></p>
      <p><b>Submodular Cost Submodular Cover with an Approximate Oracle</b><br><i>Victoria Crawford (University of Florida) &middot; Alan Kuhnle (Florida State University) &middot; My T Thai (University of Florida)</i></p>
      <p><b>Lossless or Quantized Boosting with Integer Arithmetic</b><br><i>Richard Nock (Data61, The Australian National University and the University of Sydney) &middot; Robert C Williamson (ANU)</i></p>
      <p><b>Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels</b><br><i>Pengfei Chen (The Chinese University of Hong Kong) &middot; Ben Ben Liao (Tencent) &middot; Guangyong Chen (Tencent) &middot; Shengyu Zhang (Tencent; The Chinese University of Hong Kong)</i></p>
      <p><b>HexaGAN: Generative Adversarial Nets for Real World Classification</b><br><i>Uiwon Hwang (Seoul National University) &middot; Dahuin Jung (Seoul National University) &middot; Sungroh Yoon (Seoul National University)</i></p>
      <p><b>Neural Collaborative Subspace Clustering</b><br><i>Tong Zhang (The Australian National University) &middot; Pan Ji (NEC Laboratories America) &middot; Mehrtash Harandi (Monash University) &middot; Wenbing Huang (Tencent AI Lab) &middot; HONGDONG LI (Australian National University, Australia)</i></p>
      <p><b>Fast Direct Search in an Optimally Compressed Continuous Target Space for Efficient Multi-Label Active Learning</b><br><i>weishi shi (Rochester Institute of Technology) &middot; Qi Yu (Rochester Institute of Technology)</i></p>
      <p><b>Improved Convergence for $\ell_1$ and $\ell_\infty$ Regression via Iteratively Reweighted Least Squares</b><br><i>Alina Ene (Boston University) &middot; Adrian Vladu (Boston University)</i></p>
      <p><b>Flat Metric Minimization with Applications in Generative Modeling</b><br><i>Thomas Möllenhoff (TU Munich) &middot; Daniel Cremers (TU Munich)</i></p>
      <p><b>Learning to Collaborate in Markov Decision Processes</b><br><i>Goran Radanovic (Harvard University) &middot; Rati Devidze (Max Planck Institute for Software Systems) &middot; David Parkes (Harvard University) &middot; Adish Singla (Max Planck Institute (MPI-SWS))</i></p>
      <p><b>Fast and flexible inference of joint distributions from their marginals</b><br><i>Charles Frogner (MIT) &middot; Tomaso Poggio (Massachusetts Institute of Technology)</i></p>
      <p><b>Learning Dependency Structures for Weak Supervision Models</b><br><i>Paroma Varma (Stanford University) &middot; Frederic Sala (Stanford) &middot; Ann He (Stanford University) &middot; Alexander J Ratner (Stanford University) &middot; Christopher Re (Stanford)</i></p>
      <p><b>SWALP : Stochastic Weight Averaging in Low Precision Training</b><br><i>Guandao Yang (Cornell University) &middot; Tianyi Zhang (Cornell University) &middot; Polina Kirichenko (Cornell) &middot; Junwen Bai (Cornell) &middot; Andrew Wilson (Cornell University) &middot; Chris De Sa (Cornell)</i></p>
      <p><b>Neural Separation of Observed and Unobserved Distributions</b><br><i>Tavi Halperin (Hebrew University of Jerusalem) &middot; Ariel Ephrat (HUJI) &middot; Yedid Hoshen ()</i></p>
      <p><b>Better generalization with less data using robust gradient descent</b><br><i>Matthew Holland (Osaka University) &middot; Kazushi Ikeda (Nara Institute of Science and Technology)</i></p>
      <p><b>Learning to Exploit Long-term Relational Dependencies in Knowledge Graphs</b><br><i>Lingbing Guo (Nanjing University) &middot; Zequn Sun (Nanjing University) &middot; Wei Hu (Nanjing University)</i></p>
      <p><b>Kernel Mean Matching for Content Addressability of GANs</b><br><i>Wittawat Jitkrittum (Max Planck Institute for Intelligent Systems) &middot; Patsorn Sangkloy (Georgia Institution of Technology) &middot; Muhammad Waleed Gondal (Max Planck Institute for Intelligent Systems) &middot; Amit Raj (Georgia Institute of Technology) &middot; James Hays (Georgia Institute of Technology, USA) &middot; Bernhard Schölkopf (MPI for Intelligent Systems Tübingen, Germany)</i></p>
      <p><b>Sublinear Sampling for Determinantal Point Processes</b><br><i>Jennifer Gillenwater (Google Research NYC) &middot; Alex Kulesza (Google) &middot; Zelda Mariet (MIT) &middot; Sergei Vassilvitskii (Google)</i></p>
      <p><b>Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning</b><br><i>Natasha Jaques (MIT) &middot; Angeliki Lazaridou (DeepMind) &middot; Edward Hughes (DeepMind) &middot; Caglar Gulcehre (DeepMind) &middot; Pedro Ortega (DeepMind) &middot; DJ Strouse (Princeton University) &middot; Joel Z Leibo (DeepMind) &middot; Nando de Freitas (DeepMind)</i></p>
      <p><b>Greedy Sequential Subset Selection via Sequential Facility Location</b><br><i>Ehsan Elhamifar (Northeastern University)</i></p>
      <p><b>TarMAC: Targeted Multi-Agent Communication</b><br><i>Abhishek Das (Georgia Tech) &middot; Theophile Gervet (Carnegie Mellon University) &middot; Joshua Romoff (McGill University) &middot; Dhruv Batra (Georgia Institute of Technology / Facebook AI Research) &middot; Devi Parikh (Georgia Tech & Facebook AI Research) &middot; Michael Rabbat (Facebook) &middot; Joelle Pineau (Facebook)</i></p>
      <p><b>A Kernel Theory of Modern Data Augmentation</b><br><i>Tri Dao (Stanford University) &middot; Albert Gu (Stanford University) &middot; Alexander J Ratner (Stanford University) &middot; Virginia Smith (Carnegie Mellon University) &middot; Chris De Sa (Cornell) &middot; Christopher Re (Stanford)</i></p>
      <p><b>Geometry Aware Convolutional Filters for Omnidirectional Images Representation</b><br><i>Renata Khasanova (Ecole Polytechnique Federale de Lausanne (EPFL)) &middot; Pascal Frossard (EPFL)</i></p>
      <p><b>Convolutional Poisson Gamma Belief Network</b><br><i>CHAOJIE WANG (XIDIAN UNIVERSITY) &middot; Bo Chen (School of Electronic Engineering, Xidian University) &middot; Sucheng Xiao (Xidian University) &middot; Mingyuan Zhou (University of Texas at Austin)</i></p>
      <p><b>Improving Adversarial Robustness via Promoting Ensemble Diversity</b><br><i>Tianyu Pang (Tsinghua University) &middot; Kun Xu (Tsinghua University) &middot; Chao Du (Tsinghua University) &middot; Ning Chen () &middot; Jun Zhu (Tsinghua University)</i></p>
      <p><b>Faster Stochastic Alternating Direction Method of Multipliers for Nonconvex Optimization</b><br><i>Feihu Huang (University of Pittsburgh) &middot; Songcan Chen (Nanjing University of Aeronautics and Astronautics) &middot; Heng Huang (University of Pittsburgh)</i></p>
      <p><b>Myopic Posterior Sampling for Adaptive Goal Oriented Design of Experiments</b><br><i>Kirthevasan Kandasamy (Carnegie Mellon University) &middot; Willie Neiswanger (CMU) &middot; Reed Zhang (Carnegie Mellon University) &middot; Akshay Krishnamurthy (Microsoft Research) &middot; Jeff Schneider (Uber/CMU) &middot; Barnabás Póczos (CMU)</i></p>
      <p><b>Neural Inverse Knitting: From Images to Manufacturing Instructions</b><br><i>Alexandre Kaspar (MIT CSAIL) &middot; Tae-Hyun Oh (MIT CSAIL) &middot; Liane Makatura (MIT) &middot; Petr Kellnhofer (MIT) &middot; Wojciech Matusik (MIT)</i></p>
      <p><b>Differentially Private Empirical Risk Minimization with Non-convex Loss Functions</b><br><i>Di Wang (State University of New York at Buffalo) &middot; Changyou Chen (SUNY Buffalo) &middot; Jinhui Xu (SUNY Buffalo)</i></p>
      <p><b>Bayesian Generative Active Deep Learning</b><br><i>Toan Tran (University of Adelaide) &middot; Thanh-Toan Do (The University of Liverpool) &middot; Ian Reid ("University of Adelaide, Australia") &middot; Gustavo Carneiro (University of Adelaide)</i></p>
      <p><b>Understanding the Origins of Bias in Word Embeddings</b><br><i>Marc-Etienne Brunet (University of Toronto) &middot; Colleen Alkalay-Houlihan (University of Toronto) &middot; Ashton Anderson (University of Toronto) &middot; Richard Zemel (Vector Institute)</i></p>
      <p><b>GDPP: Learning Diverse Generations using Determinantal Point Processes</b><br><i>Mohamed Elfeki (CRCV) &middot; Camille Couprie (FAIR) &middot; Morgane Riviere (Facebook Artificial Intelligence Research) &middot; Mohamed Elhoseiny (KAUST and Baidu SVAIL)</i></p>
      <p><b>Multi-Agent Adversarial Inverse Reinforcement Learning</b><br><i>Lantao Yu (Stanford University) &middot; Jiaming Song (Stanford) &middot; Stefano Ermon (Stanford University)</i></p>
      <p><b>Differentiable Learning to Learn to Normalize</b><br><i>Ping Luo (The University of Hong Kong) &middot; Peng Zhanglin (SenseTime) &middot; Shao Wenqi (CUHK) &middot; Zhang ruimao (cuhk) &middot; Ren jiamin (sensetime) &middot; Wu lingyun (sensetime)</i></p>
      <p><b>Learning Distance for Sequences by Learning a Ground Metric</b><br><i>Bing Su (Institute of Software, Chinese Academy of Sciences) &middot; Ying Wu (Northwestern University)</i></p>
      <p><b>Classification from Positive, Unlabeled and Biased Negative Data</b><br><i>Yu-Guan Hsieh (École normale supérieure) &middot; Gang Niu (RIKEN) &middot; Masashi Sugiyama (RIKEN / The University of Tokyo)</i></p>
      <p><b>Improved Parallel Algorithms for Density-Based Network Clustering</b><br><i>Mohsen Ghaffari (ETH Zurich) &middot; Silvio Lattanzi (Google Zurich) &middot; Slobodan Mitrović (MIT)</i></p>
      <p><b>Hierarchically Structured Meta-learning</b><br><i>Huaxiu Yao (Pennsylvania State University) &middot; Ying WEI (Tencent AI Lab) &middot; Junzhou Huang (University of Texas at Arlington / Tencent AI Lab) &middot; Zhenhui (Jessie) Li (Penn State University)</i></p>
      <p><b>Nonlinear Distributional Gradient Temporal-Difference Learning</b><br><i>chao qu (Ant Financial Service Group) &middot; Shie Mannor (Technion) &middot; Huan Xu (Georgia Tech)</i></p>
      <p><b>Differentiable Linearized ADMM</b><br><i>Xingyu Xie (Peking Unversity) &middot; Jianlong Wu (Peking University) &middot; Guangcan Liu (Nanjing University of Information Science and Technology) &middot; Zhisheng Zhong (Peking University) &middot; Zhouchen Lin (Peking University)</i></p>
      <p><b>Bridging Theory and Algorithm for Domain Adaptation</b><br><i>Yuchen Zhang (Tsinghua University) &middot; Tianle Liu (Tsinghua University) &middot; Mingsheng Long (Tsinghua University) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>Sublinear Time Nearest Neighbor Search over Generalized Weighted Space</b><br><i>Yifan Lei (National University of Singapore) &middot; Qiang Huang (National University of Singapore) &middot; Mohan Kankanhalli (National University of Singapore,) &middot; Anthony Tung (NUS)</i></p>
      <p><b>Imitation Learning from Imperfect Demonstration</b><br><i>Yueh-Hua Wu (National Taiwan University) &middot; Nontawat Charoenphakdee (The University of Tokyo / RIKEN) &middot; Han Bao (The University of Tokyo / RIKEN) &middot; Voot Tangkaratt (RIKEN AIP) &middot; Masashi Sugiyama (RIKEN / The University of Tokyo)</i></p>
      <p><b>Adversarial Online Learning with noise</b><br><i>ALON RESLER (Tel Aviv University) &middot; Yishay Mansour (Google and Tel Aviv University)</i></p>
      <p><b>Near optimal finite time identification of arbitrary linear dynamical systems</b><br><i>Tuhin Sarkar (MIT) &middot; Alexander Rakhlin (MIT)</i></p>
      <p><b>Bayesian Joint Spike-and-Slab Graphical Lasso</b><br><i>Zehang Li (Yale School of Public Health) &middot; Tyler Mccormick (University of Washington) &middot; Samuel Clark (The Ohio State University)</i></p>
      <p><b>Dynamic Weights in Multi-Objective Deep Reinforcement Learning</b><br><i>Axel Abels (Université Libre de Bruxelles) &middot; Diederik Roijers (VUB) &middot; Tom Lenaerts (Vrije Universiteit Brussel) &middot; Ann Nowé (Vrije Universiteit Brussel) &middot; Denis Steckelmacher (Vrije Universiteit Brussel)</i></p>
      <p><b>The Wasserstein Transform</b><br><i>Facundo Memoli (Ohio State University) &middot; Zane Smith (University of Minnesota) &middot; Zhengchao Wan (The Ohio State University)</i></p>
      <p><b>Sum-of-Squares Polynomial Flow</b><br><i>Priyank Jaini (University of Waterloo, Vector Institute) &middot; Kira A. Selby (University of Waterloo) &middot; Yaoliang Yu (University of Waterloo)</i></p>
      <p><b>Graphical-model based estimation and inference for differential privacy</b><br><i>Ryan McKenna (UMass Amherst) &middot; Daniel Sheldon (University of Massachusetts Amherst) &middot; Gerome Miklau (University of Massachusetts, Amherst)</i></p>
      <p><b>Control Regularization for Reduced Variance Reinforcement Learning</b><br><i>Richard Cheng (California Institute of Technology) &middot; Abhinav Verma (Rice University) &middot; Gabor Orosz (University of Michigan) &middot; Swarat Chaudhuri (Rice University) &middot; Yisong Yue (Caltech) &middot; Joel Burdick (Caltech)</i></p>
      <p><b>Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables</b><br><i>Kate Rakelly (UC Berkeley) &middot; Aurick Zhou (UC Berkeley) &middot; Chelsea Finn (Stanford, Google, UC Berkeley) &middot; Sergey Levine (Berkeley) &middot; Deirdre Quillen (UC Berkeley)</i></p>
      <p><b>On Sparse Linear Regression in the Local Differential Privacy Model</b><br><i>Di Wang (State University of New York at Buffalo) &middot; Jinhui Xu (SUNY Buffalo)</i></p>
      <p><b>Rethinking Lossy Compression: The Rate-Distortion-Perception Tradeoff</b><br><i>Yochai Blau (Technion) &middot; Tomer Michaeli (Technion)</i></p>
      <p><b>Transferable Adversarial Training: A General Approach to Adapting Deep Classifiers</b><br><i>Hong Liu (Tsinghua University) &middot; Mingsheng Long (Tsinghua University) &middot; Jianmin Wang (Tsinghua University) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>Adaptive Neural Trees</b><br><i>Ryutaro Tanno (University College London) &middot; Kai Arulkumaran (Imperial College London) &middot; Daniel Alexander (University College London) &middot; Antonio Criminisi (Microsoft) &middot; Aditya Nori (Microsoft Research Cambridge)</i></p>
      <p><b>A Recurrent Neural Cascade-based Model for Continuous-Time Diffusion</b><br><i>Sylvain Lamprier (LIP6 - Sorbonne Universités)</i></p>
      <p><b>Learning Efficient Feature Augmentation with Non-local Relations for Visual Recognition</b><br><i>Songyang Zhang (ShanghaiTech University) &middot; Xuming He (ShanghaiTech University) &middot; Shipeng Yan (ShanghaiTech University)</i></p>
      <p><b>Learning Structured Decision Problems with Unawareness</b><br><i>Craig Innes (University of Edinburgh) &middot; Alex Lascarides (University of Edinburgh)</i></p>
      <p><b>Improving model selection by employing the test data</b><br><i>Max Westphal (University of Bremen) &middot; Werner Brannath (University of Bremen)</i></p>
      <p><b>CapsAndRuns: An Improved Method for Approximately Optimal Algorithm Configuration</b><br><i>Gellért Weisz (DeepMind) &middot; Andras Gyorgy (DeepMind) &middot; Csaba Szepesvari (DeepMind/University of Alberta)</i></p>
      <p><b>Dead-ends and Secure Exploration in Reinforcement Learning</b><br><i>Mehdi Fatemi (Microsoft Research) &middot; Shikhar Sharma (Microsoft Research) &middot; Harm van Seijen (Microsoft Research) &middot; Samira Ebrahimi Kahou (Microsoft Research)</i></p>
      <p><b>The information-theoretic value of unlabeled data in semi-supervised learning</b><br><i>Alexander Golovnev (Harvard) &middot; David Pal (Expedia) &middot; Balazs Szorenyi (Yahoo Research)</i></p>
      <p><b>Nearest neighbor and kernel survival analysis: Nonasymptotic error bounds and strong consistency rates</b><br><i>George Chen (Carnegie Mellon University)</i></p>
      <p><b>Recursive Sketches for Modular Deep Learning</b><br><i>Badih Ghazi (Google) &middot; Rina Panigrahy (Google) &middot; Joshua R. Wang (Google)</i></p>
      <p><b>Off-Policy Deep Reinforcement Learning without Exploration</b><br><i>Scott Fujimoto (McGill University) &middot; David Meger (McGill University) &middot; Doina Precup (McGill University / DeepMind)</i></p>
      <p><b>GEOMetrics: Exploiting Geometric Structure for Graph-Encoded Objects</b><br><i>Edward Smith (McGill University) &middot; Adriana Romero (FAIR) &middot; Scott Fujimoto (McGill University) &middot; David Meger (McGill University)</i></p>
      <p><b>Population Random Measure Embedding</b><br><i>Aonan Zhang (Columbia University) &middot; John Paisley (Columbia University)</i></p>
      <p><b>Learning to Prove Theorems via Interacting with Proof Assistants</b><br><i>Kaiyu Yang (Princeton University) &middot; Jia Deng (Princeton University)</i></p>
      <p><b>Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints</b><br><i>Andrew Cotter (Google AI) &middot; Maya Gupta (Google) &middot; Heinrich Jiang (Google Research) &middot; Nati Srebro (Toyota Technological Institute at Chicago) &middot; Karthik Sridharan (Cornell University) &middot; Serena Wang (Google) &middot; Blake Woodworth (TTI-Chicago) &middot; Seungil You (Kakao Mobility)</i></p>
      <p><b>Defending Against Saddle Point Attack in Byzantine-Robust Distributed Learning</b><br><i>Dong Yin (UC Berkeley) &middot; Yudong Chen (Cornell University) &middot; Kannan Ramchandran (UC Berkeley) &middot; Peter Bartlett (UC Berkeley)</i></p>
      <p><b>Rethinking Model Scaling for Deep Convolutional Neural Networks</b><br><i>Mingxing Tan (Google Brain) &middot; Quoc Le (Google Brain)</i></p>
      <p><b>NATTACK: Improved Black-Box Adversarial Attack with Normal Distributions</b><br><i>Yandong li (University of Central Florida) &middot; Lijun Li (Beihang University) &middot; Liqiang Wang (University of Central Florida) &middot; Tong Zhang (Tencent) &middot; Boqing Gong (Google)</i></p>
      <p><b>Greedy Orthogonal Pivoting for Non-Negative Matrix Factorization</b><br><i>Kai Zhang (Temple University) &middot; Sheng Zhang (Temple University) &middot; Jun Liu (Infinia ML Inc.) &middot; Jun Wang (Alibaba) &middot; Jie Zhang (Fudan University)</i></p>
      <p><b>Population Based Augmentation: Efficient Learning of Augmentation Policy Schedules</b><br><i>Daniel Ho (UC Berkeley) &middot; Eric Liang (UC Berkeley) &middot; Xi Chen (UC Berkeley) &middot; Ion Stoica (UC Berkeley) &middot; Pieter Abbeel (UC Berkeley)</i></p>
      <p><b>Weak Detection of Signal in the Spiked Wigner Model</b><br><i>Hye Won Chung (KAIST) &middot; Ji Oon Lee (KAIST)</i></p>
      <p><b>Compressing Gradient Optimizers via Count-Sketches</b><br><i>Ryan Spring (Rice University) &middot; Anastasios Kyrillidis (Rice University) &middot; Vijai Mohan () &middot; Anshumali Shrivastava (Rice University)</i></p>
      <p><b>Variational Laplace Autoencoders</b><br><i>Yookoon Park (Seoul National University) &middot; Chris Kim (Seoul National University) &middot; Gunhee Kim (Seoul National University)</i></p>
      <p><b>New results on information theoretic clustering</b><br><i>Ferdinando Cicalese (University of Verona) &middot; Eduardo Laber (PUC-RIO) &middot; Lucas Murtinho (PUC-RJ)</i></p>
      <p><b>On Medians of (Randomized) Pairwise Means</b><br><i>Stephan Clemencon (Telecom ParisTech) &middot; Pierre Laforgue (Télécom ParisTech) &middot; Patrice Bertail (Université Paris Nanterre)</i></p>
      <p><b>Molecular Hypergraph Grammar with Its Application to Molecular Optimization</b><br><i>Hiroshi Kajino (MIT-IBM Watson AI Lab / IBM Research)</i></p>
      <p><b>Dimension-Wise Importance Sampling Weight Clipping for Sample-Efficient Reinforcement Learning</b><br><i>Seungyul Han (KAIST) &middot; Youngchul Sung (KAIST)</i></p>
      <p><b>Bandit Multiclass Linear Classification: Efficient Algorithms for the Separable Case</b><br><i>Alina Beygelzimer (Yahoo Research) &middot; David Pal (Expedia) &middot; Balazs Szorenyi (Yahoo Research) &middot; Devanathan Thiruvenkatachari (New York University) &middot; Chen-Yu Wei (University of Southern California) &middot; Chicheng Zhang (Microsoft Research)</i></p>
      <p><b>Warm-starting Contextual Bandits: Robustly Combining Supervised and Bandit Feedback</b><br><i>Chicheng Zhang (Microsoft Research) &middot; Alekh Agarwal (Microsoft Research) &middot; Hal Daume (Microsoft Research) &middot; John Langford (Microsoft Research) &middot; Sahand Negahban (YALE)</i></p>
      <p><b>Weakly-Supervised Temporal Localization via Occurrence Count Learning</b><br><i>Julien Schroeter (Cardiff University) &middot; Kirill Sidorov (Cardiff University) &middot; David Marshall (Cardiff University)</i></p>
      <p><b>Imputing Missing Events in Continuous-Time Event Streams</b><br><i>Hongyuan Mei (Johns Hopkins University) &middot; Guanghui Qin (Peking University) &middot; Jason Eisner (Johns Hopkins University)</i></p>
      <p><b>Graph U-Nets</b><br><i>Hongyang Gao (Texas A&M University) &middot; Shuiwang Ji (Texas A&M University)</i></p>
      <p><b>First-Order Algorithms Converge Faster than $O(1/k)$ on Convex Problems</b><br><i>Ching-pei Lee (University of Wisconsin-Madison) &middot; Stephen Wright (University of Wisconsin-Madison)</i></p>
      <p><b>Composing Entropic Policies using Divergence Correction</b><br><i>Jonathan Hunt (DeepMind) &middot; Andre Barreto (DeepMind) &middot; Timothy Lillicrap (Google DeepMind) &middot; Nicolas Heess (DeepMind)</i></p>
      <p><b>Online Convex Optimization in Adversarial Markov Decision Processes</b><br><i>Aviv Rosenberg (Tell Aviv University) &middot; Yishay Mansour (Google and Tel Aviv University)</i></p>
      <p><b>On the Convergence and Robustness of Adversarial Training</b><br><i>Yisen Wang (Tsinghua University) &middot; Xingjun Ma (The University of Melbourne) &middot; James Bailey (The University of Melbourne) &middot; Jinfeng Yi (JD AI Research) &middot; Bowen Zhou (JD) &middot; Quanquan Gu (University of California, Los Angeles)</i></p>
      <p><b>Safe Policy Improvement with Baseline Bootstrapping</b><br><i>Romain Laroche (Microsoft Research) &middot; Paul TRICHELAIR (Mila - Quebec AI Institute/McGill University) &middot; Remi Tachet des Combes (Microsoft Research Montreal)</i></p>
      <p><b>Variational Inference for sparse network reconstruction from count data</b><br><i>Julien Chiquet (INRA / AgroParisTech / Paris Saclay) &middot; Stephane Robin (INRA / AgroParisTech / Paris Saclay) &middot; Mahendra Mariadassou (INRA)</i></p>
      <p><b>Simplifying Graph Convolutional Networks</b><br><i>Felix Wu (Cornell University) &middot; Amauri Souza (Cornell University) &middot; Tianyi Zhang (Cornell University) &middot; Christopher Fifty (Cornell University) &middot; Tao Yu (Shanghai Jiao Tong University) &middot; Kilian Weinberger (Cornell University)</i></p>
      <p><b>Fairness without Harm: Decoupled Classifiers with Preference Guarantees</b><br><i>Berk Ustun (Harvard University) &middot; Yang Liu (UCSC) &middot; David Parkes (Harvard University)</i></p>
      <p><b>Non-Parametric Priors For Generative Adversarial Networks</b><br><i>Rajhans Singh (Arizona State University) &middot; Pavan Turaga (Arizona State University) &middot; Suren Jayasuriya (Arizona State University) &middot; Ravi Garg (Intel Corporation) &middot; Martin  Braun (Intel Corporation)</i></p>
      <p><b>Stochastic Blockmodels meet Graph Neural Networks</b><br><i>Nikhil Mehta (Duke University) &middot; Lawrence Carin (Duke) &middot; Piyush Rai (IIT Kanpur)</i></p>
      <p><b>Learning Generative Models across Incomparable Spaces</b><br><i>Charlotte Bunne (ETH) &middot; David Alvarez-Melis (MIT) &middot; Andreas Krause (ETH Zurich) &middot; Stefanie Jegelka (MIT)</i></p>
      <p><b>Rademacher Complexity for Adversarially Robust Generalization</b><br><i>Dong Yin (UC Berkeley) &middot; Kannan Ramchandran (UC Berkeley) &middot; Peter Bartlett (UC Berkeley)</i></p>
      <p><b>Accelerated Flow for Probability Distributions</b><br><i>Amirhossein Taghvaei (University of Illinois at Urbana-Champaign) &middot; Prashant Mehta (University of Illinois at Urbana-CHampaign)</i></p>
      <p><b>Generalized Majorization-Minimization</b><br><i>Sobhan Naderi Parizi (Google Inc.) &middot; Kun He (Facebook Reality Labs) &middot; Reza Aghajani (University of California San Diego) &middot; Stan Sclaroff (Boston University) &middot; Pedro Felzenszwalb (Brown University)</i></p>
      <p><b>Improved Zeroth-Order Variance Reduced Algorithms and Analysis for Nonconvex Optimization</b><br><i>Kaiyi Ji (The Ohio State University) &middot; Zhe Wang (Ohio State University) &middot; Yi Zhou (Duke University) &middot; Yingbin LIANG (The Ohio State University)</i></p>
      <p><b>Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization</b><br><i>Hesham Mostafa (Intel Corporation) &middot; Xin Wang (Cerebras Systems)</i></p>
      <p><b>Metropolis-Hastings Generative Adversarial Networks</b><br><i>Ryan Turner (Uber AI Labs) &middot; Jane Hung (Uber) &middot; Eric Frank (Uber AI Labs) &middot; Yunus Saatchi (Uber AI Labs) &middot; Jason Yosinski (Uber Labs)</i></p>
      <p><b>Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits</b><br><i>Branislav Kveton (Google Research) &middot; Csaba Szepesvari (DeepMind/University of Alberta) &middot; Sharan Vaswani (Mila, University of Montreal) &middot; Zheng Wen (Adobe Research) &middot; Tor Lattimore (DeepMind) &middot; Mohammad Ghavamzadeh (Facebook AI Research)</i></p>
      <p><b>Direct Uncertainty Prediction for Medical Second Opinions</b><br><i>Maithra Raghu (Cornell University / Google Brain) &middot; Katy Blumer (Google) &middot; Rory sayres (Google) &middot; Ziad Obermeyer (UC Berkeley School of Public Health) &middot; Bobby Kleinberg (Cornell) &middot; Sendhil Mullainathan (Harvard University) &middot; Jon Kleinberg (Cornell University)</i></p>
      <p><b>Contextual Multi-armed Bandit Algorithm for Semiparametric Reward Model</b><br><i>Gi-Soo Kim (Seoul National University) &middot; Myunghee Cho Paik (Seoul National University)</i></p>
      <p><b>On Symmetric Losses for Learning from Corrupted Labels</b><br><i>Nontawat Charoenphakdee (The University of Tokyo / RIKEN) &middot; Jongyeong Lee (The University of Tokyo/RIKEN) &middot; Masashi Sugiyama (RIKEN / The University of Tokyo)</i></p>
      <p><b>Lipschitz Generative Adversarial Nets</b><br><i>Zhiming Zhou (SJTU) &middot; Jiadong Liang (Peking University) &middot; Yuxuan Song (Shanghai Jiao Tong Univesity) &middot; Lantao Yu (Stanford University) &middot; Hongwei Wang (Shanghai Jiao Tong University) &middot; Weinan Zhang (Shanghai Jiao Tong University) &middot; Yong Yu (Shanghai Jiao Tong University) &middot; Zhihua Zhang (Peking University)</i></p>
      <p><b>Spectral Clustering of Signed Graphs via Matrix Power Means</b><br><i>Pedro Mercado (Saarland University / University of Tubingen) &middot; Matthias Hein (University of Tübingen) &middot; Francesco Tudisco (University of Strathclyde)</i></p>
      <p><b>Overparameterized Nonlinear Learning: Gradient Descent Takes the Shortest Path?</b><br><i>Samet Oymak (University of California, Riverside) &middot; Mahdi Soltanolkotabi (University of Southern California)</i></p>
      <p><b>POPCORN: Certifying Robustness of Recurrent Neural Networks</b><br><i>CHING-YUN KO (The University of Hong Kong) &middot; Zhaoyang Lyu (The Chinese University of Hong Kong) &middot; Tsui-Wei Weng (MIT) &middot; Luca Daniel (Massachusetts Institute of Technology) &middot; Ngai Wong (The University of Hong Kong) &middot; Dahua Lin (The Chinese University of Hong Kong)</i></p>
      <p><b>MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing</b><br><i>Sami Abu-El-Haija (USC Information Sciences Institute) &middot; Bryan Perozzi (Google AI) &middot; Amol Kapoor (Google Research) &middot; Nazanin Alipourfard (University of Southern California) &middot; Kristina Lerman (ISI, University of Southern California) &middot; Hrayr Harutyunyan (University of Southern California) &middot; Greg Ver Steeg (University of Southern California) &middot; Aram Galstyan (USC ISI)</i></p>
      <p><b>Static Automatic Batching In TensorFlow</b><br><i>Ashish Agarwal (Google Brain)</i></p>
      <p><b>State-Regularized Recurrent Neural Networks</b><br><i>Cheng Wang (NEC Laboratories Europe) &middot; Mathias Niepert (NEC Laboratories Europe)</i></p>
      <p><b>Online Adaptive Principal Component Analysis and Its extensions</b><br><i>Jianjun Yuan (University of Minnesota) &middot; Andrew Lamperski (University of Minnesota)</i></p>
      <p><b>Passed &amp; Spurious: analysing descent algorithms and local minima in spiked matrix-tensor model</b><br><i>Stefano Sarao Mannelli (Institut de Physique Théorique) &middot; Florent Krzakala () &middot; Pierfrancesco Urbani (Institut de Physique Théorique) &middot; Lenka Zdeborova (CEA Saclay)</i></p>
      <p><b>Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the Orthogonal and Unitary Group</b><br><i>Mario Lezcano Casado (Univeristy of Oxford) &middot; David Martínez-Rubio (University of Oxford)</i></p>
      <p><b>Towards Accurate Model Selection in Deep Unsupervised Domain Adaptation</b><br><i>Kaichao You (Tsinghua University) &middot; Ximei Wang (Tsinghua University) &middot; Mingsheng Long (Tsinghua University) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>RaFM: Rank-Aware Factorization Machines</b><br><i>Xiaoshuang Chen (Tsinghua Univerisity) &middot; Yin Zheng (Tencent AI Lab) &middot; Jiaxing Wang (Institute of Automation, Chinese Academy of Sciences) &middot; Wenye Ma (Tencent) &middot; Junzhou Huang (University of Texas at Arlington / Tencent AI Lab)</i></p>
      <p><b>Overcoming multi-model forgetting</b><br><i>Yassine Benyahia (IPROVA) &middot; Kaicheng Yu (EPFL) &middot; Kamil Bennani-Smires (Swisscom) &middot; Martin Jaggi (EPFL) &middot; Anthony C. Davison (EPFL) &middot; Mathieu Salzmann (EPFL) &middot; Claudiu Musat (Swisscom)</i></p>
      <p><b>Simple Stochastic Gradient Methods for Non-Smooth Non-Convex Regularized Optimization</b><br><i>Michael Metel (RIKEN Center for Advanced Intelligence Project) &middot; Akiko Takeda (The University of Tokyo / RIKEN)</i></p>
      <p><b>LegoNet: Efficient Convolutional Neural Networks with Lego Filters</b><br><i>Zhaohui Yang (Peking University) &middot; Yunhe Wang (Peking University) &middot; Chuanjian Liu (Huawei Noah's Ark Lab) &middot; Hanting Chen (Peking University) &middot; Chunjing Xu (Huawei Noah's Ark Lab) &middot; Boxin Shi (Peking University) &middot; Chao Xu (Peking University) &middot; Chang Xu (University of Sydney)</i></p>
      <p><b>Breaking Inter-Layer Co-Adaptation by Classifier Anonymization</b><br><i>Ikuro Sato (Denso IT Laboratory, Inc.) &middot; Kohta Ishikawa (DENSO IT Laboratory) &middot; Guoqing Liu (Denso IT Laboratory) &middot; Masayuki Tanaka (National Institute of Advanced Industrial Science and Technology, Japan)</i></p>
      <p><b>Model Comparison for Semantic Grouping</b><br><i>Francisco Vargas (Babylon Health) &middot; Kamen Brestnichki (Babylon Health) &middot; Nils Hammerla (Babylon Health)</i></p>
      <p><b>Global Convergence of Block Coordinate Descent in Deep Learning</b><br><i>Jinshan ZENG (Hongkong University of Science and Technology) &middot; Tsz Kit Lau (Northwestern University) &middot; Shaobo Lin (Wenzhou University) &middot; Yuan Yao (HongKong University of Science and Technology)</i></p>
      <p><b>Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks</b><br><i>Juho Lee (AITRICS, University of Oxford) &middot; Yoonho Lee (Kakao Corporation) &middot; Jungtaek Kim (POSTECH) &middot; Adam Kosiorek (University of Oxford) &middot; Seungjin Choi (POSTECH) &middot; Yee Whye Teh (Oxford and DeepMind)</i></p>
      <p><b>Doubly Robust Joint Learning for Recommendation on Data Missing Not at Random</b><br><i>Xiaojie Wang (University of Melbourne) &middot; Rui Zhang (" University of Melbourne, Australia") &middot; Yu Sun (Twitter Inc.) &middot; Jianzhong Qi (The University of Melbourne)</i></p>
      <p><b>Breaking the gridlock in Mixture-of-Experts: Consistent and Efficient Algorithms</b><br><i>Ashok Makkuva (UIUC) &middot; Pramod Viswanath (UIUC) &middot; Sreeram Kannan (University of Washington) &middot; Sewoong Oh (University of Washington)</i></p>
      <p><b>Invariant-Equivariant Representation Learning for Multi-Class Data</b><br><i>Ilya Feige (ASI Data Science)</i></p>
      <p><b>On The Power of Curriculum Learning in Training Deep Networks</b><br><i>Guy Hacohen (Hebrew University of Jerusalem) &middot; Daphna Weinshall (Hebrew University of Jerusalem, Israel)</i></p>
      <p><b>Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces</b><br><i>Philipp Becker (TU Darmstadt ) &middot; Harit Pandya (University of Lincoln) &middot; Gregor Gebhardt (TU Darmstadt) &middot; Cheng  Zhao (Birmingham University) &middot; C. James  Taylor (Lancaster University) &middot; Gerhard Neumann (Lincoln University)</i></p>
      <p><b>CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning</b><br><i>Cédric Colas (Inria) &middot; Pierre-Yves Oudeyer (Inria) &middot; Olivier Sigaud (Sorbonne University) &middot; Pierre Fournier (UPMC) &middot; Mohamed Chetouani (UPMC)</i></p>
      <p><b>Beyond Adaptive Submodularity: Approximation Guarantees of Greedy Policy with Adaptive Submodularity Ratio</b><br><i>Kaito Fujii (University of Tokyo) &middot; Shinsaku Sakaue (NTT)</i></p>
      <p><b>Approximation and non-parametric estimation of ResNet-type convolutional neural networks</b><br><i>Kenta Oono (University of Tokyo / Preferred Networks) &middot; Taiji Suzuki (The University of Tokyo / RIKEN)</i></p>
      <p><b>A Persistent Weisfeiler--Lehman Procedure for Graph Classification</b><br><i>Bastian Rieck (ETH Zurich) &middot; Christian Bock (ETH Zurich) &middot; Karsten Borgwardt (ETH Zurich)</i></p>
      <p><b>Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning</b><br><i>Jakob Foerster (Facebook AI Research) &middot; Francis Song (DeepMind) &middot; Edward Hughes (DeepMind) &middot; Neil Burch (DeepMind) &middot; Iain Dunning (DeepMind) &middot; Shimon Whiteson (University of Oxford) &middot; Matthew Botvinick (DeepMind) &middot; Michael Bowling (DeepMind)</i></p>
      <p><b>Finite-Time Analysis of Distributed TD(0) with Linear Function Approximation on Multi-Agent Reinforcement Learning</b><br><i>Thinh Doan (Georgia Institute of Technology) &middot; Siva Maguluri (Georgia Tech) &middot; Justin Romberg (Georgia Tech)</i></p>
      <p><b>Fairness risk measures</b><br><i>Robert C Williamson (ANU) &middot; Aditya Menon (Google)</i></p>
      <p><b>Cross-Domain 3D Equivariant Image Embeddings</b><br><i>Carlos Esteves (University of Pennsylvania) &middot; Avneesh Sud (Google) &middot; Zhengyi Luo (University of Pennsylvania) &middot; Kostas Daniilidis (University of Pennsylvania) &middot; Ameesh Makadia (Google Research)</i></p>
      <p><b>Stein Point Markov Chain Monte Carlo</b><br><i>Wilson Ye Chen (University of Technology Sydney) &middot; Alessandro Barp (Imperial College London) &middot; Francois-Xavier Briol (Imperial College London) &middot; Jackson Gorham (OPENDOOR) &middot; Mark Girolami (Imperial College London) &middot; Lester Mackey (Microsoft Research) &middot; Chris Oates (Newcastle University)</i></p>
      <p><b>Optimal Minimal Margin Maximization with Boosting</b><br><i>Alexander Mathiasen (Aarhus University) &middot; Kasper Green Larsen (Aarhus University, MADALGO) &middot; Allan Grønlund (Aarhus University, MADALGO)</i></p>
      <p><b>Benefits and Pitfalls of the Exponential Mechanism with Applications to Hilbert Spaces and Functional PCA</b><br><i>Jordan Awan (Pennsylvania State University) &middot; Ana Kenney (Penn State University) &middot; Matthew Reimherr (Penn State University) &middot; Aleksandra Slavković (Pennsylvania State University)</i></p>
      <p><b>Learning and Data Selection in Big Datasets</b><br><i>Hossein Shokri Ghadikolaei (KTH Royal Institute of Technology) &middot; Hadi Ghauch (Royal Institute of Technology, KTH) &middot; Inst. of Technology Carlo Fischione (Royal Inst. of Technology, KTH) &middot; Mikael Skoglund (KTH Royal Institute of Technology)</i></p>
      <p><b>Transferability vs. Discriminability: Batch Spectral Penalization for Adversarial Domain Adaptation</b><br><i>Xinyang Chen (Tsinghua University) &middot; Sinan Wang (Tsinghua University) &middot; Mingsheng Long (Tsinghua University) &middot; Jianmin Wang (Tsinghua University)</i></p>
      <p><b>Ladder Capsule Network</b><br><i>Tae Won Jeong (KAIST) &middot; Youngmin Lee (KAIST) &middot; Heeyoung Kim (KAIST)</i></p>
      <p><b>Discriminative Regularization for Generative Models</b><br><i>Andrew Miller (Columbia University) &middot; Ziad Obermeyer (UC Berkeley) &middot; John Cunningham (Columbia) &middot; Sendhil Mullainathan (University of Chicago)</i></p>
      <p><b>Rates of Convergence for Sparse Variational Gaussian Process Regression</b><br><i>David Burt (University of Cambridge) &middot; Carl E Rasmussen (Cambridge University) &middot; Mark van der Wilk (PROWLER.io)</i></p>
      <p><b>Unsupervised label noise modeling and loss correction</b><br><i>Eric Arazo (Insight Centre for Data Analytics (DCU)) &middot; Diego Ortego (Insight Centre for Data Analytics (DCU)) &middot; Paul Albert (Insight Centre for Data Analytics (DCU)) &middot; Noel O'Connor (Dublin City University (DCU)) &middot; Kevin McGuinness (Insight Centre for Data Analytics)</i></p>
      <p><b>Online Variance Reduction with Mixtures</b><br><i>Zalán Borsos (ETH Zurich) &middot; Sebastian Curi (ETH) &middot; Yehuda Levy (ETH Zurich) &middot; Andreas Krause (ETH Zurich)</i></p>
      <p><b>Random Matrix Improved Covariance Estimation for a Large Class of Metrics</b><br><i>Malik TIOMOKO A (Université Paris Sud) &middot; Romain Couillet (CentralSupélec) &middot; Florent BOUCHARD (LISTIC, Université Savoie Mont-Blanc) &middot; Guillaume GINOLHAC (Université Savoie Mont-Blanc)</i></p>
      <p><b>Homomorphic Sensing</b><br><i>Manolis Tsakiris (Johns Hopkins University) &middot; Liangzu Peng (ShanghaiTech University)</i></p>
      <p><b>Quantifying Generalization in Reinforcement Learning</b><br><i>Karl Cobbe (OpenAI) &middot; Oleg Klimov (OpenAI) &middot; Chris Hesse (OpenAI) &middot; Taehoon Kim (OpenAI) &middot; John Schulman (OpenAI)</i></p>
      <p><b>Fingerprint Policy Optimisation for Robust Reinforcement Learning</b><br><i>Supratik Paul (University of Oxford) &middot; Michael A Osborne (U Oxford) &middot; Shimon Whiteson (University of Oxford)</i></p>
      <p><b>Area Attention</b><br><i>Yang Li (Google Research) &middot; Lukasz Kaiser (Google) &middot; Samy Bengio (Google Research, Brain Team) &middot; Si Si (Google Research)</i></p>
      <p><b>Alternating Minimizations Converge to Second-Order Optimal Solutions</b><br><i>Qiuwei Li (Colorado School of Mines) &middot; Zhihui Zhu (Johns Hopkins University) &middot; Gongguo Tang (Colorado School of Mines)</i></p>
      <p><b>Scalable Training of Inference Networks for Gaussian-Process Models</b><br><i>Jiaxin Shi (Tsinghua University) &middot; Mohammad Emtiyaz Khan (RIKEN) &middot; Jun Zhu (Tsinghua University)</i></p>
      <p><b>Compressed Factorization: Fast and Accurate Low-Rank Factorization of Compressively-Sensed Data</b><br><i>Vatsal Sharan (Stanford University) &middot; Kai Sheng Tai (Stanford University) &middot; Peter Bailis (Stanford University) &middot; Gregory Valiant (Stanford University)</i></p>
      <p><b>Stochastic Deep Networks</b><br><i>Gwendoline De Bie (Ecole normale supérieure) &middot; Gabriel Peyré (CNRS and ENS) &middot; Marco Cuturi (ENSAE / CREST)</i></p>
      <p><b>Policy Certificates: Towards Accountable Reinforcement Learning</b><br><i>Christoph Dann (Carnegie Mellon University) &middot; Lihong Li (Google Inc.) &middot; Wei Wei (Google) &middot; Emma Brunskill (Stanford University)</i></p>
      <p><b>Coresets for Ordered Weighted Clustering</b><br><i>Vladimir Braverman (Johns Hopkins University) &middot; Shaofeng Jiang (Weizmann Institute of Science) &middot; Robert Krauthgamer (Weizmann Institute of Science) &middot; Xuan Wu (Johns Hopkins University)</i></p>
      <p><b>Deep Counterfactual Regret Minimization</b><br><i>Noam Brown (Facebook AI Research) &middot; Adam Lerer (Facebook AI Research) &middot; Sam Gross (Facebook AI Research) &middot; Tuomas Sandholm (Carnegie Mellon University)</i></p>
      <p><b>Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment</b><br><i>Yifan Wu (Carnegie Mellon University) &middot; Ezra Winston (CMU MLD) &middot; Divyansh  Kaushik (Carnegie Mellon University) &middot; Zachary Lipton (Carnegie Mellon University)</i></p>
      <p><b>POLITEX: Regret Bounds for Policy Iteration using Expert Prediction</b><br><i>Nevena Lazic (Google) &middot; Yasin Abbasi-Yadkori (Adobe Research) &middot; Kush Bhatia (UC Berkeley) &middot; Gellért Weisz (DeepMind) &middot; Peter Bartlett ("University of California, Berkeley") &middot; Csaba Szepesvari (DeepMind/University of Alberta)</i></p>
      <p><b>Simple Black-box Adversarial Attacks</b><br><i>Chuan Guo (Cornell University) &middot; Jacob Gardner (Uber AI Labs) &middot; Yurong You (Cornell University) &middot; Andrew Wilson (Cornell University) &middot; Kilian Weinberger (Cornell University)</i></p>
      <p><b>Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation</b><br><i>Sahil Singla (University of Maryland) &middot; Eric Wallace (Allen Institute for Artificial Intelligence) &middot; Shi Feng (University of Maryland) &middot; Soheil Feizi (University of Maryland)</i></p>
      <p><b>Learning Hawkes Processes Under Synchronization Noise</b><br><i>William Trouleau (EPFL) &middot; Jalal Etesami (Bosch Research Center for AI, Germany) &middot; Matthias Grossglauser (EPFL) &middot; Negar Kiyavash (Georgia Institute of Technology) &middot; Patrick Thiran (EPFL)</i></p>
      <p><b>Provably efficient RL with Rich Observations via Latent State Decoding</b><br><i>Simon Du (Carnegie Mellon University) &middot; Akshay Krishnamurthy (Microsoft Research) &middot; Nan Jiang (University of Illinois at Urbana-Champaign) &middot; Alekh Agarwal (Microsoft Research) &middot; Miroslav Dudik (Microsoft Research) &middot; John Langford (Microsoft Research)</i></p>
      <p><b>Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians</b><br><i>Vardan Papyan (Stanford University)</i></p>
      <p><b>Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</b><br><i>Jonathan Ho (UC Berkeley) &middot; Xi Chen (UC Berkeley) &middot; Aravind Srinivas (UC Berkeley) &middot; Rocky Duan (University of California, Berkeley) &middot; Pieter Abbeel (OpenAI / UC Berkeley)</i></p>
      <p><b>Learning Optimal Linear Regularizers</b><br><i>Matthew Streeter (Google)</i></p>
      <p><b>Learning to Convolve: A Generalized Weight-Tying Approach</b><br><i>Nichita Diaconu (University of Amsterdam) &middot; Daniel E Worrall (University of Amsterdam)</i></p>
      <p><b>Cognitive model priors for predicting human decisions</b><br><i>Joshua C Peterson (Princeton University) &middot; David Bourgin (UC Berkeley) &middot; Daniel Reichman (UC Berkeley) &middot; Thomas Griffiths (Princeton University) &middot; Stuart Russell (UC Berkeley)</i></p>
      <p><b>Scalable Learning in Reproducing Kernel Krein Spaces</b><br><i>Dino Oglic (King's College London) &middot; Thomas Gaertner (The University of Nottingham)</i></p>
      <p><b>Learning Latent Dynamics for Planning from Pixels</b><br><i>Danijar Hafner (Google Brain & University of Toronto) &middot; Timothy Lillicrap (Google DeepMind) &middot; Ian Fischer (Google) &middot; Ruben Villegas (University of Michigan) &middot; David Ha (Google) &middot; Honglak Lee (Google / U. Michigan) &middot; James Davidson (Google Brain)</i></p>
      <p><b>Rate Distortion For Model Compression:From Theory To Practice</b><br><i>Weihao Gao (University of Illinois at Urbana-Champaign) &middot; Yu-Han Liu (Google) &middot; Chong Wang (Google) &middot; Sewoong Oh (University of Washington)</i></p>
      <p><b>Replica Conditional Sequential Monte Carlo</b><br><i>Alex Shestopaloff (The Alan Turing Institute / University of Edinburgh) &middot; Arnaud Doucet (Oxford University)</i></p>
      <p><b>Robust estimation of tree structured Gaussian Graphical Model</b><br><i>Ashish Katiyar (The University of Texas at Austin) &middot; Jessica Hoffmann (University of Texas at Austin) &middot; Constantine Caramanis (University of Texas)</i></p>
      <p><b>A Baseline for Any Order Gradient Estimation in Stochastic Computation Graphs</b><br><i>Jingkai Mao (Man AHL) &middot; Jakob Foerster (Facebook AI Research) &middot; Tim Rocktäschel (University of Oxford) &middot; Maruan Al-Shedivat (Carnegie Mellon University) &middot; Gregory Farquhar (University of Oxford) &middot; Shimon Whiteson (University of Oxford)</i></p>
      <p><b>Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment</b><br><i>Chen Huang (Apple Inc.) &middot; Shuangfei Zhai (Apple) &middot; Walter Talbott (Apple) &middot; Miguel Bautista Martin (Apple Inc.) &middot; Shih-Yu Sun (Apple) &middot; Carlos Guestrin (Apple & Univesity of Washington) &middot; Joshua M Susskind (Apple, Inc.)</i></p>
      <p><b>Does Data Augmentation Lead to Positive Margin?</b><br><i>Shashank Rajput (University of Wisconsin - Madison) &middot; Zhili Feng (University of Wisconsin-Madison) &middot; Zachary Charles (University of Wisconsin-Madison) &middot; Dimitris Papailiopoulos (ECE at University of Wisconsin-Madison) &middot; Po-Ling Loh (UW-Madison)</i></p>
      <p><b>Robust influence maximization in hyperparametric domains</b><br><i>Dimitrios Kalimeris (Harvard University) &middot; Gal Kaplun (Harvard) &middot; Yaron Singer (Harvard)</i></p>
      <p><b>How does Disagreement Help Generalization against Label Corruption?</b><br><i>Xingrui Yu (University of Technology Sydney) &middot; Bo Han (RIKEN-AIP) &middot; Jiangchao Yao (University of Technology Sydney) &middot; Gang Niu (RIKEN) &middot; Ivor Tsang (University of Technology Sydney) &middot; Masashi Sugiyama (RIKEN / The University of Tokyo)</i></p>
      <p><b>Gaining Free or Low-Cost Interpretability with Interpretable Partial Substitute</b><br><i>Tong Wang (University of Iowa)</i></p>
      <p><b>Self-Attention Generative Adversarial Networks</b><br><i>Han Zhang (Google) &middot; Ian Goodfellow (Google Brain) &middot; Dimitris Metaxas (Rutgers) &middot; Augustus Odena (Google Brain)</i></p>
      <p><b>Learning Neurosymbolic Generative Models via Program Synthesis</b><br><i>Halley R Young (University of Pennsylvania) &middot; Osbert Bastani (University of Pennsylvania) &middot; Mayur Naik (University of Pennsylvania)</i></p>
      <p><b>Manifold Mixup: Better Representations by Interpolating Hidden States</b><br><i>Vikas Verma (Aalto University) &middot; Alex Lamb (Universite de Montreal) &middot; Christopher Beckham (MILA) &middot; Amir Najafi (Sharif University of Technology) &middot; Ioannis Mitliagkas (University of Montreal) &middot; David Lopez-Paz (Facebook AI Research) &middot; Yoshua Bengio (Mila / U. Montreal)</i></p>
      <p><b>COMIC: Multi-view Clustering Without Parameter Selection</b><br><i>Xi Peng (Sichuan University) &middot; Zhenyu Huang (Sichuan University) &middot; Jiancheng Lv (Sichuan University) &middot; Hongyuan Zhu (Institute for Infocomm, Research Agency for Science, Technology and Research (A*STAR) Singapore) &middot; Joey Tianyi Zhou (A*STAR)</i></p>
      <p><b>Interpreting Adversarially Trained Convolutional Neural Networks</b><br><i>Tianyuan Zhang (Peking University) &middot; Zhanxing Zhu (Peking University)</i></p>
      <p><b>On the Linear Speedup Analysis of Communication Efficient Momentum SGD for Distributed Non-Convex Optimization</b><br><i>Hao Yu (Alibaba Group (US) Inc ) &middot; rong jin (alibaba group) &middot; Sen Yang ()</i></p>
      <p><b>Bilinear Bandits with Low-rank Structure </b><br><i>Kwang-Sung Jun (Boston University) &middot; Rebecca Willett (U Chicago) &middot; Stephen Wright (University of Wisconsin-Madison) &middot; Robert Nowak (University of Wisconsion-Madison)</i></p>
      <p><b>On the Computation and Communication Complexity of Parallel SGD with Dynamic Batch Sizes for Stochastic Non-Convex Optimization</b><br><i>Hao Yu (Alibaba Group (US) Inc ) &middot; rong jin (alibaba group)</i></p>
      <p><b>Online Learning to Rank with Features</b><br><i>Shuai Li (The Chinese University of Hong Kong) &middot; Tor Lattimore (DeepMind) &middot; Csaba Szepesvari (DeepMind/University of Alberta)</i></p>
      <p><b>Zeno: Distributed Stochastic Gradient Descent with Suspicion-based Fault-tolerance</b><br><i>Cong Xie (UIUC) &middot; Sanmi Koyejo (University of Illinois at Urbana-Champaign) &middot; Indranil Gupta (UIUC)</i></p>
      <p><b>Automated Model Selection with Bayesian Quadrature</b><br><i>Henry Chai (Washington University in St. Louis) &middot; Jean-Francois Ton (University of Oxford) &middot; Michael A Osborne (U Oxford) &middot; Roman Garnett (Washington University in St. Louis)</i></p>
      <p><b>The Kernel Interaction Trick: Fast Bayesian Discovery of Multi-Way Interactions in High Dimensions</b><br><i>Raj Agrawal (MIT) &middot; Brian Trippe (MIT) &middot; Jonathan Huggins (Harvard) &middot; Tamara Broderick (MIT)</i></p>
      <p><b>Gradient Descent Finds Global Minima of Deep Neural Networks</b><br><i>Simon Du (Carnegie Mellon University) &middot; Jason Lee (University of Southern California) &middot; Haochuan Li (Peking University) &middot; Liwei Wang (Peking University) &middot; Xiyu Zhai (Massachusetts Institute of Technology)</i></p>
      <p><b>Distributed Learning with Sublinear Communication</b><br><i>Jayadev Acharya (Cornell University) &middot; Chris De Sa (Cornell) &middot; Dylan Foster (Cornell University) &middot; Karthik Sridharan (Cornell University)</i></p>
      <p><b>Boosted Density Estimation Remastered</b><br><i>Zac Cranko (ANU) &middot; Richard Nock (Data61, The Australian National University and the University of Sydney)</i></p>
      <p><b>Efficient Dictionary Learning with Gradient Descent</b><br><i>Dar Gilboa (Columbia University) &middot; Sam Buchanan (Columbia University) &middot; John Wright (Columbia University, USA)</i></p>
      <p><b>Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations</b><br><i>Quanming Yao (4Paradigm) &middot; James Kwok (Hong Kong University of Science and Technology) &middot; Bo Han (RIKEN-AIP)</i></p>
      <p><b>Approximating Orthogonal Matrices with Effective Givens Factorization</b><br><i>Thomas Frerix (Technical University of Munich) &middot; Joan Bruna (New York University)</i></p>
      <p><b>The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects</b><br><i>Zhanxing Zhu (Peking University) &middot; Jingfeng Wu (Peking University) &middot; Bing Yu (Peking University) &middot; Lei Wu (Peking University) &middot; Jinwen Ma (Peking University)</i></p>
      <p><b>Large-Scale Sparse Kernel Canonical Correlation Analysis</b><br><i>Viivi Uurtio (Aalto University) &middot; Sahely Bhadra (Indian Institute of Technology Palakkad) &middot; Juho Rousu (Aalto University)</i></p>
      <p><b>Efficient On-Device Models using Neural Projections</b><br><i>Sujith Ravi (Google Research)</i></p>
      <p><b>A Differentiable Gaussian-like Distribution on Hyperbolic Space for Gradient-Based Learning</b><br><i>Yoshihiro Nagano (The University of Tokyo) &middot; Shoichiro Yamaguchi (Preferred Networks) &middot; Yasuhiro Fujita (Preferred Networks, Inc.) &middot; Masanori Koyama (Preferred Networks Inc. )</i></p>
      <p><b>Quantile Stein Bayesian Optimization</b><br><i>Chengyue Gong (university of texas at austin) &middot; Jian Peng (UIUC) &middot; Qiang Liu (UT Austin)</i></p>
      <p><b>Learning to select for a predefined ranking</b><br><i>Aleksandr Vorobev (Yandex) &middot; Aleksei Ustimenko (Yandex) &middot; Gleb G. Gusev (Yandex LLC) &middot; Pavel Serdyukov (Yandex)</i></p>
      <p><b>Optimal Algorithms for Lipschitz Bandits with Heavy-tailed Rewards</b><br><i>Shiyin Lu (Nanjing University) &middot; Guanghui  Wang (Nanjing University) &middot; Yao Hu (Alibaba Youku Cognitive and Intelligent Lab) &middot; Lijun Zhang (Nanjing University)</i></p>
      <p><b>Fast and Simple Natural-Gradient Variational Inference with Mixture of Exponential-family Approximations</b><br><i>Wu Lin (University of British Columbia) &middot; Mohammad Emtiyaz Khan (RIKEN) &middot; Mark Schmidt (University of British Columbia)</i></p>
      <p><b>On Efficient Optimal Transport:  An Analysis of Greedy and Accelerated Mirror Descent Algorithms</b><br><i>Tianyi Lin (UC Berkeley) &middot; Nhat Ho (University of California, Berkeley) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>Low Latency Privacy Preserving Inference</b><br><i>Alon Brutzkus (Tel Aviv University) &middot; Ran Gilad-Bachrach (Microsoft Research) &middot; Oren Elisha (Microsoft)</i></p>
      <p><b>MASS: Masked Sequence to Sequence Pre-training for Language Generation</b><br><i>Kaitao Song (Nanjing University of Science and Technology) &middot; Xu Tan (Microsoft Research) &middot; Tao Qin (Microsoft Research Asia) &middot; Jianfeng Lu (Nanjing University of Science and Technology) &middot; Tie-Yan Liu (Microsoft)</i></p>
      <p><b>Learning Linear-Quadratic Regulators Efficiently with only $\sqrt{T}$ Regret</b><br><i>Alon Cohen (Technion and Google) &middot; Tomer Koren (Google Brain) &middot; Yishay Mansour (Google and Tel Aviv University)</i></p>
      <p><b>Inferring Heterogeneous Causal Effects in Presence of Spatial Confounding</b><br><i>Muhammad Osama (Uppsala University) &middot; Dave Zachariah (Uppsala University) &middot; Thomas Schön (Uppsala University)</i></p>
      <p><b>Rotation Invariant Householder Parameterization for Bayesian PCA</b><br><i>Rajbir-Singh Nirwan (Frankfurt Institute for Advanced Studies) &middot; Nils Bertschinger (Frankfurt Institute for Advanced Studies )</i></p>
      <p><b>Sparse Multilabel Learning with Oracle Property</b><br><i>Weiwei Liu (Wuhan University) &middot; Xiaobo Shen (Nanjing University of Science and Technology)</i></p>
      <p><b>Distributed, Egocentric Representations of Graphs for Detecting Critical Structures</b><br><i>Ruo-Chun Tzeng (Microsoft Inc.) &middot; Shan-Hung Wu (National Tsing Hua University)</i></p>
      <p><b>LGM-Net: Learning to Generate Matching Networks for Few shot Learning</b><br><i>HUAIYU LI (Institute of Automation, Chinese Academy of Sciences) &middot; Weiming Dong (NLPR, Institute of Automation, Chinese Academy of Sciences) &middot; Xing Mei (Snap Inc.) &middot; Chongyang Ma (Kwai Inc.) &middot; Feiyue Huang (Tencent) &middot; Bao-Gang Hu (Institute of Automation, Chinese Academy of Sciences)</i></p>
      <p><b>An investigation of model-free planning</b><br><i>Arthur Guez (Google DeepMind) &middot; Mehdi Mirza (DeepMind) &middot; Karol Gregor (DeepMind) &middot; Rishabh Kabra (DeepMind) &middot; Sebastien Racaniere (DeepMind) &middot; Theophane Weber (DeepMind) &middot; David Raposo (DeepMind) &middot; Adam Santoro (DeepMind) &middot; Laurent Orseau (DeepMind) &middot; Tom Eccles (DeepMind) &middot; Greg Wayne (DeepMind) &middot; David Silver (Google DeepMind) &middot; Timothy Lillicrap (Google DeepMind)</i></p>
      <p><b>Beating Stochastic and Adversarial Semi-bandits Optimally and Simultaneously</b><br><i>Julian Zimmert (University of Copenhagen) &middot; Haipeng Luo (University of Southern California) &middot; Chen-Yu Wei (University of Southern California)</i></p>
      <p><b>Co-Representation Network for Generalized Zero-Shot Learning</b><br><i>Fei Zhang (Xidian University) &middot; Guangming Shi (Xidian University)</i></p>
      <p><b>Safe Grid Search with Optimal Complexity</b><br><i>Eugene Ndiaye (Telecom ParisTech) &middot; Tam Le (RIKEN AIP) &middot; Olivier Fercoq (Télécom ParisTech, Université Paris-Saclay) &middot; Joseph Salmon (Université de Montpellier) &middot; Ichiro Takeuchi (Nagoya Institute of Technology / RIKEN)</i></p>
      <p><b>On the Universality of Invariant Networks</b><br><i>Haggai Maron (Weizmann Institute of Science) &middot; Ethan Fetaya (University of Toronto) &middot; Nimrod Segol (Weizmann Institute of Science) &middot; Yaron Lipman (Weizmann Institute of Science)</i></p>
      <p><b>SGD without Replacement: Sharper Rates for General Smooth Convex Functions</b><br><i>Dheeraj Nagaraj (Massachusetts Institute of Technology) &middot; Prateek Jain (Microsoft Research) &middot; Praneeth Netrapalli (Microsoft Research)</i></p>
      <p><b>Adaptive Regret of Convex and Smooth Functions</b><br><i>Lijun Zhang (Nanjing University) &middot; Tie-Yan Liu (Microsoft) &middot; Zhi-Hua Zhou (Nanjing University)</i></p>
      <p><b>Robust Learning from Untrusted Sources</b><br><i>Nikola Konstantinov (IST Austria) &middot; Christoph H. Lampert (IST Austria)</i></p>
      <p><b>Universal Multi-Party Poisoning Attacks</b><br><i>Saeed Mahloujifar (University of Virginia) &middot; Mohammad Mahmoody (University of Virginia) &middot; Ameer Mohammed (Kuwait University)</i></p>
      <p><b>Connectivity-Optimized Representation Learning via Persistent Homology</b><br><i>Christoph Hofer (University of Salzburg) &middot; Roland Kwitt (University of Salzburg) &middot; Marc Niethammer (UNC) &middot; Mandar Dixit (Microsoft)</i></p>
      <p><b>Efficient Training of BERT by Progressively Stacking</b><br><i>Linyuan Gong (Peking University) &middot; Di He (Peking University) &middot; Zhuohan Li (Peking University) &middot; Tao Qin (Microsoft Research Asia) &middot; Liwei Wang (Peking University) &middot; Tie-Yan Liu (Microsoft Research Asia)</i></p>
      <p><b>MetricGAN: Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement</b><br><i>Szu-Wei Fu (National Taiwan University) &middot; Chien-Feng Liao (Academia Sinica) &middot; Yu Tsao (Academia Sinica) &middot; Shou-De Lin (National Taiwan University)</i></p>
      <p><b>A Quantitative Analysis of the Effect of Batch Normalization on Gradient Descent</b><br><i>YongQiang Cai (National University of Singapore) &middot; Qianxiao Li (Institute of High Performance Computing, A*STAR, Singapore) &middot; Zuowei Shen (National University of Singapore)</i></p>
      <p><b>Understanding MCMC Dynamics as Flows on the Wasserstein Space</b><br><i>Chang Liu (Tsinghua University) &middot; Jingwei Zhuo (Tsinghua University) &middot; Jun Zhu (Tsinghua University)</i></p>
      <p><b>Understand and Accelerate Particle-based Variational Inference</b><br><i>Chang Liu (Tsinghua University) &middot; Jingwei Zhuo (Tsinghua University) &middot; Pengyu Cheng (Duke University) &middot; RUIYI (ROY) ZHANG (Duke University) &middot; Jun Zhu (Tsinghua University)</i></p>
      <p><b>Towards Understanding Knowledge Distillation</b><br><i>Mary Phuong (IST Austria) &middot; Christoph H. Lampert (IST Austria)</i></p>
      <p><b>Bayesian leave-one-out cross-validation for large data</b><br><i>Måns Magnusson (Aalto University) &middot; Michael Andersen (Aalto University) &middot; Johan Jonasson (Chalmers University of Technology) &middot; Aki Vehtari (Aalto University)</i></p>
      <p><b>Deep Generative Learning via Variational Gradient Flow</b><br><i>Yuan Gao (Xi'an Jiaotong University) &middot; Yuling Jiao (Zhongnan University of Ecomomics and Law) &middot; Yang Wang (HKUST) &middot; Yao Wang () &middot; Can Yang (HKUST) &middot; Shunkang Zhang (HKUST)</i></p>
      <p><b>Refined Complexity of PCA with Outliers</b><br><i>Kirill Simonov (University of Bergen) &middot; Fedor Fomin (University of Bergen) &middot; Petr Golovach (University of Bergen) &middot; Fahad Panolan (University of Bergen)</i></p>
      <p><b>A Personalized Affective Memory Model for Improving Emotion Recognition</b><br><i>Pablo Barros (University of Hamburg) &middot; German Parisi (University of Hamburg) &middot; Stefan Wermter (University of Hamburg)</i></p>
      <p><b>Curiosity-Bottleneck: Exploration By Distilling Task-Specific Novelty </b><br><i>Youngjin Kim (NALBI Inc.) &middot; Daniel Nam (KC Machine Learning Lab) &middot; Hyunwoo Kim (Seoul National University) &middot; Ji-Hoon Kim (Naver Corp.) &middot; Gunhee Kim (Seoul National University)</i></p>
      <p><b>Active Learning for Probabilistic Structured Prediction of Cuts and Matchings</b><br><i>Sima Behpour (University of Pennsylvania) &middot; Anqi Liu (Caltech) &middot; Brian Ziebart (University of Illinois at Chicago)</i></p>
      <p><b>Nonconvex Variance Reduced Optimization with Arbitrary Sampling</b><br><i>Samuel Horvath (KAUST) &middot; Peter Richtarik (KAUST)</i></p>
      <p><b>A Kernel Perspective for Regularizing Deep Neural Networks</b><br><i>Alberto Bietti (Inria) &middot; Gregoire Mialon (Inria) &middot; Dexiong Chen (Inria) &middot; Julien Mairal (Inria)</i></p>
      <p><b>Maximum Entropy-Regularized Multi-Goal Reinforcement Learning</b><br><i>Rui Zhao (Siemens & Ludwig Maximilian University of Munich) &middot; Xudong Sun (Ludwig Maximilian University of Munich) &middot; Volker Tresp (Siemens AG and University of Munich)</i></p>
      <p><b>Neural Logic Reinforcement Learning</b><br><i>zhengyao jiang (University of Liverpool) &middot; Shan Luo (University of Liverpool)</i></p>
      <p><b>Approximated Oracle Filter Pruning for Destructive CNN Width Optimization</b><br><i>XIAOHAN DING (Tsinghua University) &middot; guiguang ding (Tsinghua University, China) &middot; Yuchen Guo (Tsinghua University) &middot; Jungong Han (Lancaster University) &middot; Chenggang Yan (Hangzhou Dianzi University)</i></p>
      <p><b>Zero Shot Knowledge Distillation in Deep Networks</b><br><i>Gaurav Kumar Nayak (Indian Institute of Science) &middot; Konda Reddy Mopuri (University of Edinburgh) &middot; Vaisakh Shaj (University Of Lincoln) &middot; Venkatesh Babu Radhakrishnan (Indian Institute of Science) &middot; Anirban Chakraborty (Indian Institute of Science)</i></p>
      <p><b>Learning for New Visual Environments with Limited Labels</b><br><i>Pengkai Zhu (Boston University) &middot; Hanxiao Wang (Boston University) &middot; Venkatesh Saligrama (Boston University)</i></p>
      <p><b>Grid-Wise Control for Multi-Agent Reinforcement Learning in Video Game AI</b><br><i>Lei Han (Tencent AI Lab) &middot; Peng Sun (Tencent AI Lab) &middot; Yali Du (University of Technology Sydney) &middot; Jiechao Xiong (Tencent AI Lab) &middot; Qing Wang () &middot; Xinghai Sun (Tencent AI Lab) &middot; Han Liu (Northwestern) &middot; Tong Zhang (Tecent AI Lab)</i></p>
      <p><b>Stable-Predictive Optimistic Counterfactual Regret Minimization</b><br><i>Gabriele Farina (Carnegie Mellon University) &middot; Christian Kroer (Columbia University) &middot; Noam Brown (CMU) &middot; Tuomas Sandholm (Carnegie Mellon University)</i></p>
      <p><b>Shallow-Deep Networks: Understanding and Mitigating Network Overthinking</b><br><i>Yigitcan Kaya (UMD) &middot; Sanghyun Hong (University of Maryland College Park) &middot; Tudor Dumitras (University of Maryland)</i></p>
      <p><b>Causal Identification under Markov Equivalence: Completeness Results</b><br><i>Amin Jaber (Purdue University) &middot; Jiji Zhang (Lingnan U) &middot; Elias Bareinboim (Purdue)</i></p>
      <p><b>Learn to Grow: A Continual Structure Learning Framework for Catastrophic Forgetting</b><br><i>Xilai Li (Salesforce Research NC State University) &middot; Yingbo Zhou (Salesforce Research) &middot; Tianfu Wu (NC State University) &middot; Richard Socher (Salesforce) &middot; Caiming Xiong (Salesforce)</i></p>
      <p><b>Characterization of Convex Objective Functions and Optimal Expected Convergence Rates for SGD</b><br><i>Marten van Dijk (University of Connecticut) &middot; Lam Nguyen (IBM Research, Thomas J. Watson Research Center) &middot; PHUONG_HA NGUYEN (University of Connecticut) &middot; Dzung Phan (IBM T.J. Watson Research Center)</i></p>
      <p><b>Geometric Scattering for Graph Data Analysis</b><br><i>Feng Gao (Michigan State University) &middot; Guy Wolf (Université de Montréal) &middot; Matthew Hirn (Michigan State University)</i></p>
      <p><b>Gromov-Wasserstein Learning for Graph Matching and Node Embedding</b><br><i>Hongteng Xu (InfiniaML, Inc.) &middot; Dixin Luo (Duke University) &middot; Hongyuan Zha (Georgia Institute of Technology) &middot; Lawrence Carin (Duke)</i></p>
      <p><b>Meta-Learning Neural Bloom Filters</b><br><i>Jack Rae (DeepMind) &middot; Sergey Bartunov (DeepMind) &middot; Timothy Lillicrap (Google DeepMind)</i></p>
      <p><b>Good Initializations of Variational Bayes for Deep Models</b><br><i>Simone Rossi (EURECOM) &middot; Pietro Michiardi (EURECOM) &middot; Maurizio Filippone (Eurecom)</i></p>
      <p><b>Distributional Multivariate Policy Evaluation and Exploration with the Bellman GAN</b><br><i>dror freirich (Technion) &middot; Tzahi Shimkin (Technion Israeli Institute of Technology) &middot; Ron Meir (Technion Israeli Institute of Technology) &middot; Aviv Tamar (Technion Israeli Institute of Technology)</i></p>
      <p><b>Almost Unsupervised Text to Speech and Automatic Speech Recognition</b><br><i>Yi Ren (Zhejiang University) &middot; Xu Tan (Microsoft Research) &middot; Tao Qin (Microsoft Research Asia) &middot; Sheng Zhao (Microsoft) &middot; Zhou Zhao (Zhejiang University) &middot; Tie-Yan Liu (Microsoft)</i></p>
      <p><b>Exploiting structure of uncertainty for efficient combinatorial semi-bandits</b><br><i>Pierre Perrault (Inria Lille - Nord Europe) &middot; Vianney Perchet (ENS Paris Saclay & Criteo AI Lab) &middot; Michal Valko (DeepMind)</i></p>
      <p><b>Fast Rates for a kNN Classifier Robust to Unknown Asymmetric Label Noise</b><br><i>Henry Reeve (University of Birmingham) &middot; Ata Kaban (University of Birmingham)</i></p>
      <p><b>Efficient optimization of loops and limits with randomized telescoping sums</b><br><i>Alex Beatson (Princeton University) &middot; Ryan P Adams (Princeton University)</i></p>
      <p><b>Analyzing Federated Learning through an Adversarial Lens</b><br><i>Arjun Nitin Bhagoji (Princeton University) &middot; Supriyo Chakraborty (IBM T. J. Watson Research Center) &middot; Prateek Mittal (Princeton University) &middot; Seraphin Calo  (IBM Research)</i></p>
      <p><b>A Contrastive Divergence for Combining Variational Inference and MCMC</b><br><i>Francisco Ruiz (University of Cambridge / Columbia University) &middot; Michalis Titsias (DeepMind)</i></p>
      <p><b>Disentangling Disentanglement in Variational Auto-Encoders</b><br><i>Emile Mathieu (University of Oxford) &middot; Tom Rainforth (University of Oxford) &middot; N Siddharth (Unversity of Oxford) &middot; Yee Whye Teh (Oxford and DeepMind)</i></p>
      <p><b>Regret Circuits: Composability of Regret Minimizers</b><br><i>Gabriele Farina (Carnegie Mellon University) &middot; Christian Kroer (Columbia University) &middot; Tuomas Sandholm (Carnegie Mellon University)</i></p>
      <p><b>AReS and MaRS - Adversarial and MMD-Minimizing Regression for SDEs</b><br><i>Gabriele Abbati (University of Oxford) &middot; Philippe Wenk (ETH Zurich) &middot; Stefan Bauer (MPI for Intelligent Systems) &middot; Michael A Osborne (U Oxford) &middot; Andreas Krause (ETH Zurich) &middot; Bernhard Schölkopf (Max Planck Institute for Intelligent Systems)</i></p>
      <p><b>MMI-ALI: Multivariate-Information Adversarial Ensemble for Scalable Joint Distribution Matching</b><br><i>Ziliang Chen (Sun Yat-sen University) &middot; ZHANFU YANG (Purdue University) &middot; Xiaoxi Wang (Sun Yat-sen University) &middot; Xiaodan Liang (Sun Yat-sen University) &middot; xiaopeng yan (SYSU) &middot; Guanbin Li (Sun Yat-sen University) &middot; Liang Lin (Sun Yat-sen University)</i></p>
      <p><b>Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation</b><br><i>Shani Gamrian (Bar-Ilan University) &middot; Yoav Goldberg ()</i></p>
      <p><b>Switching Linear Dynamics for Variational Bayes Filtering</b><br><i>Philip Becker-Ehmck (Volkswagen Group) &middot; Jan Peters (TU Darmstadt) &middot; Patrick van der Smagt (Volkswagen Group)</i></p>
      <p><b>IMEXnet - A Forward Stable Deep Neural Network</b><br><i>Eldad Haber (University of British Columbia) &middot; Keegan Lensink (UBC) &middot; Eran Treister () &middot; Lars Ruthotto (Emory University)</i></p>
      <p><b>LR-GLM: High-Dimensional Bayesian Inference Using Low-Rank Data Approximations</b><br><i>Brian Trippe (MIT) &middot; Jonathan Huggins (Harvard) &middot; Raj Agrawal (MIT) &middot; Tamara Broderick (MIT)</i></p>
      <p><b>Differentially Private Learning of Geometric Concepts</b><br><i>Haim Kaplan (Tel Aviv University and Google) &middot; Yishay Mansour (Google and Tel Aviv University) &middot; Yossi Matias (Google) &middot; Uri Stemmer (Ben-Gurion University)</i></p>
      <p><b>CHiVE: Varying Prosody in Speech Synthesis with a Linguistically Driven Dynamic Hierarchical Conditional Variational Network</b><br><i>Tom Kenter (Google UK) &middot; Vincent Wan (Google) &middot; Chun-an Chan (Google) &middot; Robert Clark (Google UK) &middot; Jakub Vit (University of West Bohemia)</i></p>
      <p><b>Per-Decision Option Discounting</b><br><i>Anna Harutyunyan (DeepMind) &middot; Peter Vrancx (PROWLER.io) &middot; Philippe Hamel (Deepmind) &middot; Ann Nowe (VU Brussel) &middot; Doina Precup (DeepMind)</i></p>
      <p><b>Competing Against Nash Equilibria in Adversarially Changing Zero-Sum Games</b><br><i>Adrian Rivera Cardoso (Georgia Tech) &middot; Jacob Abernethy (Georgia Institute of Technology) &middot; He Wang (Georgia Institute of Technology) &middot; Huan Xu (Georgia Tech)</i></p>
      <p><b>Sublinear Space Private Algorithms Under the Sliding Window Model</b><br><i>Jalaj Upadhyay (Johns Hopkins University) &middot; Raman Arora (Johns Hopkins University)</i></p>
      <p><b>Understanding and correcting pathologies in the training of learned optimizers</b><br><i>Luke Metz (Google Brain) &middot; Niru Maheswaranathan (Google Brain) &middot; Jeremy Nixon (Google Brain) &middot; Daniel Freeman (Google Brain) &middot; Jascha Sohl-Dickstein (Google Brain)</i></p>
      <p><b>Amortized Monte Carlo Integration</b><br><i>Adam Golinski (University of Oxford) &middot; Frank Wood (University of British Columbia) &middot; Tom Rainforth (University of Oxford)</i></p>
      <p><b>Correlated bandits or: How to minimize mean-squared error online</b><br><i>Vinay Praneeth Boda (LinkedIn Corp.) &middot; Prashanth L.A. (IIT Madras)</i></p>
      <p><b>Autoregressive Energy Machines</b><br><i>Conor Durkan (University of Edinburgh) &middot; Charlie Nash (The University of Edinburgh)</i></p>
      <p><b>Gauge Equivariant Convolutional Networks and the Icosahedral CNN</b><br><i>Taco Cohen (Qualcomm AI Research) &middot; Maurice Weiler (University of Amsterdam) &middot; Berkay Kicanaoglu (University of Amsterdam) &middot; Max Welling (University of Amsterdam & Qualcomm)</i></p>
      <p><b>The Natural Language of Actions</b><br><i>Guy Tennenholtz (Technion) &middot; Shie Mannor (Technion)</i></p>
      <p><b>MONK --  Outlier-Robust Mean Embedding Estimation by Median-of-Means</b><br><i>Matthieu Lerasle (Laboratoire de Mathématiques d'Orsay, Univ. Paris-Sud; CNRS, Université Paris Saclay, France) &middot; Zoltan Szabo (Ecole Polytechnique) &middot; Timothée Mathieu (Laboratoire de Mathématiques d'Orsay, Univ. Paris-Sud, France) &middot; Guillaume Lecue (CREST)</i></p>
      <p><b>A Composite Randomized Incremental Gradient Method</b><br><i>Junyu Zhang (University of Minnesota, Twin Cities) &middot; Lin Xiao (Microsoft Research)</i></p>
      <p><b>Bayesian Counterfactual Risk Minimization</b><br><i>Ben London (Amazon) &middot; Ted Sandler (Amazon.com)</i></p>
      <p><b>Learning to Optimize Multigrid PDE Solvers</b><br><i>Daniel Greenfeld (Weizmann Institute of Science) &middot; Meirav Galun (Weizmann Institute of Science) &middot; Ronen Basri (Weizmann Institute of Science) &middot; Irad Yavneh (Technion) &middot; Ron Kimmel (Technion)</i></p>
      <p><b>Stochastic Beams and Where To Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement</b><br><i>Wouter Kool (University of Amsterdam) &middot; Herke van Hoof (University of Amsterdam) &middot; Max Welling (University of Amsterdam)</i></p>
      <p><b>Nonparametric Bayesian Deep Networks with Local Competition</b><br><i>Konstantinos Panousis (National and Kapodistrian University of Athens) &middot; Sotirios Chatzis (Cyprus University of Technology) &middot; Sergios Theodoridis (National and Kapodistrian University of Athens)</i></p>
      <p><b>Optimal Kronecker-Sum Approximation of Real Time Recurrent Learning</b><br><i>Frederik Benzing (ETH Zurich) &middot; Marcelo Matheus Gauy (ETH Zurich) &middot; Asier Mujika (ETH Zurich) &middot; Anders Martinsson (ETH Zurich) &middot; Angelika Steger (ETH Zurich)</i></p>
      <p><b>Deep Factors for Forecasting</b><br><i>Yuyang Wang (AWS AI Labs) &middot; Alex Smola (Amazon) &middot; Danielle Robinson (Amazon Web Services) &middot; Jan Gasthaus (Amazon Research) &middot; Dean Foster (Amazon) &middot; Tim  Januschowski (Amazon Research)</i></p>
      <p><b>Validating Causal Inference Models via Influence Functions</b><br><i>Ahmed Alaa (UCLA) &middot; M van der Schaar (UCLA)</i></p>
      <p><b>ELF OpenGo: an analysis and open reimplementation of AlphaZero</b><br><i>Yuandong Tian (Facebook AI Research) &middot; Jerry Ma (Facebook AI Research) &middot; Qucheng Gong (Facebook AI Research) &middot; Shubho Sengupta (Facebook AI Research) &middot; Zhuoyuan Chen (Facebook) &middot; James Pinkerton (Facebook AI Research) &middot; Larry Zitnick (Facebook AI Research)</i></p>
      <p><b>Why do Larger Models Generalize Better? A Theoretical Perspective via the XOR Problem</b><br><i>Alon Brutzkus (Tel Aviv University) &middot; Amir Globerson (Tel Aviv University, Google)</i></p>
      <p><b>Improved Training of Sequence Generative Models</b><br><i>Sidi Lu (Shanghai Jiao Tong University) &middot; Lantao Yu (Stanford University) &middot; Siyuan Feng (Apex Data & Knowledge Management Lab, Shanghai Jiao Tong University) &middot; Yaoming Zhu (Apex Data & Knowledge Management Lab, Shanghai Jiao Tong University) &middot; Weinan Zhang (Apex Data & Knowledge Management Lab, Shanghai Jiao Tong University)</i></p>
      <p><b>Nonlinear Stein Variational Gradient Descent for Learning Diversified Mixture Models</b><br><i>Dilin Wang (UT Austin) &middot; Qiang Liu (UT Austin)</i></p>
      <p><b>Provable Guarantees for Gradient-Based Meta-Learning</b><br><i>Nina Balcan (Carnegie Mellon University) &middot; Mikhail Khodak (CMU) &middot; Ameet Talwalkar (Carnegie Mellon University)</i></p>
      <p><b>Improving Neural Language Modeling via Adversarial Training</b><br><i>Dilin Wang (UT Austin) &middot; Chengyue Gong (university of texas at austin) &middot; Qiang Liu (UT Austin)</i></p>
      <p><b>Stochastic Iterative Hard Thresholding for Graph-structured  Sparsity Optimization</b><br><i>Baojian Zhou (University at Albany, SUNY) &middot; Feng Chen (University at albany SUNY) &middot; Yiming Ying (SUNY Albany)</i></p>
      <p><b>Non-monotone Submodular Maximization with Nearly Optimal Adaptivity and Query Complexity</b><br><i>Matthew Fahrbach (Georgia Institute of Technology) &middot; Vahab Mirrokni (Google Research) &middot; Morteza Zadimoghaddam (Google)</i></p>
      <p><b>MeanSum: A Model for Unsupervised Neural Multi-Document Abstractive Summarization</b><br><i>Eric Chu (Massachusetts Institute of Technology) &middot; Peter Liu (Google Brain)</i></p>
      <p><b>Bayesian Nonparametric Federated Learning of Neural Networks</b><br><i>Mikhail Yurochkin (IBM Research AI) &middot; Mayank Agarwal (IBM Research) &middot; Soumya Ghosh (IBM Research) &middot; Kristjan Greenewald (IBM) &middot; Nghia Hoang (MIT-IBM Watson AI Lab, IBM Research) &middot; Yasaman Khazaeni (IBM Research)</i></p>
      <p><b>Multi-Frequency Phase Synchronization</b><br><i>Tingran Gao (University of Chicago) &middot; Zhizhen Zhao (University of Illinois at Urbana Champaign)</i></p>
      <p><b>Phaseless PCA: Low-Rank Matrix Recovery from Column-wise Phaseless Measurements</b><br><i>Seyedehsara Nayer (Iowa State University) &middot; Praneeth Narayanamurthy (Iowa State University) &middot; Namrata Vaswani (Iowa State University)</i></p>
      <p><b>PAC Identification of Many Good Arms in Stochastic Multi-Armed Bandits</b><br><i>Arghya Roy Chaudhuri (Indian Institute of Technology Bombay) &middot; Shivaram Kalyanakrishnan (IIT Bombay)</i></p>
      <p><b>Dimensionality Reduction for Tukey Regression</b><br><i>Kenneth  Clarkson (IBM Research) &middot; Ruosong Wang (Carnegie Mellon University) &middot; David Woodruff (Carnegie Mellon University)</i></p>
      <p><b>Are Generative Classifiers More Robust to Adversarial Attacks?</b><br><i>Yingzhen Li (Microsoft Research Cambridge) &middot; John Bradshaw (University of Cambridge) &middot; Yash Sharma (Max Planck Institute for Intelligent Systems)</i></p>
      <p><b>Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions</b><br><i>Hao Wang (Harvard University) &middot; Berk Ustun (Harvard University) &middot; Flavio Calmon (Harvard University)</i></p>
      <p><b>Stochastic Gradient Push for Distributed Deep Learning</b><br><i>Mahmoud Assran (McGill University/Facebook FAIR) &middot; Nicolas Loizou (The University of Edinburgh) &middot; Nicolas Ballas (Facebook FAIR) &middot; Michael Rabbat (Facebook)</i></p>
      <p><b>Dropout as a Structured Shrinkage Prior</b><br><i>Eric Nalisnick (University of California, Irvine) &middot; Jose Hernandez-Lobato (University of Cambridge) &middot; Padhraic Smyth (UC Irvine)</i></p>
      <p><b>Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Value Approximation</b><br><i>Marco Ancona (ETH Zurich) &middot; Cengiz Oztireli (Disney Research) &middot; Markus Gross (ETH Zurich)</i></p>
      <p><b>Understanding and Controlling Memory in Recurrent Neural Networks</b><br><i>Doron Haviv (Technion) &middot; Alexander Rivkind (Weizmann Institute of Science) &middot; Omri Barak ()</i></p>
      <p><b>Differential Inclusions for Modeling Nonsmooth ADMM Variants: A Continuous Limit Theory</b><br><i>Huizhuo Yuan (Peking University) &middot; Yuren Zhou (Duke University) &middot; Chris Junchi Li (Tencent AI Lab) &middot; Qingyun Sun (Stanford University)</i></p>
      <p><b>Jumpout : Improved Dropout for Deep Neural Networks with ReLUs</b><br><i>Shengjie Wang ("University of Washington, Seattle") &middot; Tianyi Zhou (University of Washington) &middot; Jeff Bilmes (UW)</i></p>
      <p><b>Bias Also Matters: Bias Attribution for Deep Neural Network Explanation</b><br><i>Shengjie Wang ("University of Washington, Seattle") &middot; Tianyi Zhou (University of Washington) &middot; Jeff Bilmes (UW)</i></p>
      <p><b>HOList: An Environment for Machine Learning of Higher Order Logic Theorem Proving</b><br><i>Kshitij Bansal (Google Research) &middot; Sarah Loos (Google) &middot; Markus Rabe (Google) &middot; Christian Szegedy (Google) &middot; Stewart Wilcox (Googl)</i></p>
      <p><b>Certified Adversarial Robustness via Randomized Smoothing</b><br><i>Jeremy Cohen (Carnegie Mellon University) &middot; Elan Rosenfeld (Carnegie Mellon University) &middot; Zico Kolter (Carnegie Mellon University / Bosch Center for AI)</i></p>
      <p><b>Equivariant Transformer Networks</b><br><i>Kai Sheng Tai (Stanford University) &middot; Peter Bailis (Stanford University) &middot; Gregory Valiant (Stanford University)</i></p>
      <p><b>A Statistical Approach to Regularized Wasserstein GANs</b><br><i>Yogesh Balaji (University of Maryland) &middot; Hamed Hassani (University of Pennsylvania) &middot; Rama Chellappa (University of Maryland) &middot; Soheil Feizi (University of Maryland)</i></p>
      <p><b>Tractable n-metrics for multiple graphs</b><br><i>Sam Safavi (Boston College) &middot; Jose Bento (Boston College)</i></p>
      <p><b>On the Impact of the Activation function on Deep Neural Networks Training</b><br><i>Soufiane Hayou (University of Oxford) &middot; Arnaud Doucet (Oxford University) &middot; Judith Rousseau (University of Oxford)</i></p>
      <p><b>Pareto Optimal Streaming Unsupervised Classification</b><br><i>Soumya Basu (University of Texas at Austin) &middot; Steven Gutstein (ARL) &middot; Brent  Lance (Army Research Laboratory ) &middot; Sanjay Shakkottai (University of Texas at Austin)</i></p>
      <p><b>Mallows ranking models: maximum likelihood estimate and regeneration</b><br><i>Wenpin Tang (UCLA)</i></p>
      <p><b>Lorentzian Distance Learning</b><br><i>Marc Law (University of Toronto) &middot; Renjie Liao (University of Toronto) &middot; Jake Snell (University of Toronto) &middot; Richard Zemel (Vector Institute)</i></p>
      <p><b>Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops</b><br><i>Limor Gultchin (University of Oxford) &middot; Genevieve Patterson (TRASH) &middot; Nancy Baym (Micr) &middot; Nathaniel Swinger (Lexington High School) &middot; Adam Kalai (Microsoft Research)</i></p>
      <p><b>Natural Analysts in Adaptive Data Analysis</b><br><i>Tijana Zrnic (University of California, Berkeley) &middot; University of California Moritz Hardt (University of California, Berkeley)</i></p>
      <p><b>Adversarial Examples Are a Natural Consequence of Test Error in Noise</b><br><i>Justin Gilmer (Google Brain) &middot; Nicolas Ford (Google Brain) &middot; Nicholas Carlini (Google) &middot; Ekin Cubuk (Google Brain)</i></p>
      <p><b>On Scalable and Efficient Computation of Large Scale Optimal Transport</b><br><i>Yujia Xie (Georgia Institute of Technology) &middot; Minshuo Chen (Georgia Tech) &middot; Haoming Jiang (Georgia Tech) &middot; Tuo Zhao (Georgia Institute of Technology) &middot; Hongyuan Zha (Georgia Institute of Technology)</i></p>
      <p><b>Bayesian Optimization Meets Bayesian Optimal Stopping</b><br><i>Zhongxiang Dai (National University of Singapore) &middot; Haibin Yu (National University of Singapore) &middot; Bryan Kian Hsiang Low (National University of Singapore) &middot; Patrick Jaillet  (MIT)</i></p>
      <p><b>A Control-Theoretic Perspective on Nesterov&#39;s Accelerated Gradient Method</b><br><i>Michael Muehlebach (UC Berkeley) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>Learning from Delayed Outcomes via Proxies with Applications to Recommender Systems</b><br><i>Timothy Mann (DeepMind) &middot; Sven Gowal (DeepMind) &middot; Huiyi Hu (DeepMind) &middot; Ray Jiang (Google Deepmind) &middot; Balaji Lakshminarayanan (Google DeepMind) &middot; Andras Gyorgy (DeepMind) &middot; Prav Srinivasan (DeepMind)</i></p>
      <p><b>Incremental Randomized Sketching for Online Kernel Learning</b><br><i>Xiao Zhang (Tianjin University) &middot; Shizhong Liao (Tianjin University)</i></p>
      <p><b>HyperGAN: A Generative Model for Diverse, Performant Neural Networks</b><br><i>Neale Ratzlaff (Oregon State University) &middot; Fuxin Li (Oregon State University)</i></p>
      <p><b>EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE</b><br><i>Chao Ma (University of Cambridge) &middot; Sebastian Tschiatschek (Microsoft Research) &middot; Konstantina Palla (Microsoft Research Cambridge) &middot; Jose Hernandez-Lobato (University of Cambridge) &middot; Sebastian Nowozin (MSR Cambridge) &middot; Cheng Zhang (Microsoft Research, Cambridge)</i></p>
      <p><b>Submodular Streaming in All Its Glory: Tight Approximation, Minimum Memory and Low Adaptive Complexity</b><br><i>Ehsan Kazemi (Yale) &middot; Marko Mitrovic (Yale University) &middot; Morteza Zadimoghaddam (Google) &middot; Silvio Lattanzi (Google Zurich) &middot; Amin Karbasi (Yale)</i></p>
      <p><b>Detecting Overlapping and Correlated Communities: Identifiability and Algorithm</b><br><i>Kejun Huang (University of Florida) &middot; Xiao Fu (Oregon State University)</i></p>
      <p><b>Provably Efficient Imitation Learning from Observation Alone</b><br><i>Wen Sun (Carnegie Mellon University) &middot; Anirudh Vemula (CMU) &middot; Byron Boots (Georgia Tech) &middot; Drew Bagnell (Carnegie Mellon University)</i></p>
      <p><b>Stay With Me: Lifetime Maximization Through Heteroscedastic Linear Bandits With Reneging</b><br><i>Ping-Chun Hsieh (Texas A&M University) &middot; Xi Liu (Texas A&M University) &middot; Anirban  Bhattacharya (Texas A&M University) &middot; P R Kumar (Texas A & M University)</i></p>
      <p><b>Doubly-Competitive Distribution Estimation</b><br><i>Yi Hao (University of California, San Diego) &middot; Alon Orlitsky (UCSD)</i></p>
      <p><b>Regularization in directable environments with application to Tetris</b><br><i>Jan Malte Lichtenberg (University of Bath) &middot; Ozgur Simsek (University of Bath)</i></p>
      <p><b>Learning to Groove with Inverse Sequence Transformations</b><br><i>Jon Gillick (UC Berkeley) &middot; Adam Roberts (Google Brain) &middot; Jesse Engel (Google Brain) &middot; Douglas Eck (Google Brain) &middot; David Bamman (UC Berkeley)</i></p>
      <p><b>Metric-Optimized Example Weights</b><br><i>Sen Zhao (Google AI) &middot; Mahdi Milani Fard (Google) &middot; Harikrishna Narasimhan (Google Research) &middot; Maya Gupta (Google)</i></p>
      <p><b>Generalized Linear Rule Models</b><br><i>Sanjeeb Dash (IBM Research) &middot; Tian Gao (IBM Research) &middot; Oktay Gunluk (IBM Research) &middot; Dennis Wei (IBM Research)</i></p>
      <p><b>Recursive Optimization</b><br><i>Ashok Cutkosky (Google) &middot; Tamas Sarlos (Google)</i></p>
      <p><b>Surrogate Losses for Online Learning of Stepsizes in Stochastic Non-Convex Optimization</b><br><i>zhenxun zhuang (Boston University) &middot; Ashok Cutkosky (Google) &middot; Francesco Orabona (Stony Brook University)</i></p>
      <p><b>Compositional Invariance Constraints for Graph Embeddings</b><br><i>Avishek Bose (McGill/Mila) &middot; William Hamilton (McGill University)</i></p>
      <p><b>A Statistical Investigation of Long Memory in Language and Music</b><br><i>Alexander Greaves-Tunnell (University of Washington) &middot; Zaid Harchaoui (University of Washington)</i></p>
      <p><b>Topological Data Analysis of Decision Boundaries with Application to Model Selection</b><br><i>Karthikeyan Ramamurthy (IBM Research) &middot; Kush Varshney (IBM Research AI) &middot; Krishnan Mody (New York University)</i></p>
      <p><b>Look Ma, No Latent Variables: Accurate Cutset Networks via Compilation</b><br><i>Tahrima Rahman (University of Texas at Dallas) &middot; Shasha Jin (The University of Texas at Dallas) &middot; Vibhav Gogate (The University of Texas at Dallas)</i></p>
      <p><b>Sorting Out Lipschitz Function Approximation</b><br><i>Cem Anil (University of Toronto) &middot; James Lucas (University of Toronto) &middot; Roger Grosse (University of Toronto and Vector Institute)</i></p>
      <p><b>Neural Joint-Source Channel Coding</b><br><i>Kristy Choi (Stanford University) &middot; Kedar Tatwawadi (Stanford University) &middot; Aditya Grover (Stanford University) &middot; Tsachy Weissman (Stanford University) &middot; Stefano Ermon (Stanford University)</i></p>
      <p><b>Theoretically Principled Trade-off between Robustness and Accuracy</b><br><i>Hongyang Zhang (CMU & TTIC) &middot; Yaodong Yu (University of Virginia) &middot; Jiantao Jiao (University of California, Berkeley) &middot; Eric Xing (Petuum Inc. and CMU) &middot; Laurent El Ghaoui (UC Berkeley) &middot; Michael Jordan (UC Berkeley)</i></p>
      <p><b>Dirichlet Simplex Nest and Geometric Inference</b><br><i>Mikhail Yurochkin (IBM Research, MIT-IBM Watson AI Lab) &middot; Aritra Guha (U Michigan) &middot; Yuekai Sun (University of Michigan) &middot; XuanLong Nguyen (University of Michigan)</i></p>
      <p><b>Probability Functional Descent: A Unifying Perspective on GANs, Variational Inference, and Reinforcement Learning</b><br><i>Casey Chu (Stanford University) &middot; Jose Blanchet (Stanford University) &middot; Peter Glynn (Stanford University)</i></p>
      <p><b>Multi-Frequency Vector Diffusion Maps</b><br><i>Yifeng Fan (University of Illinois at Urbana-Champaign) &middot; Zhizhen Zhao (University of Illinois at Urbana Champaign)</i></p>
      <p><b>Co-manifold learning with missing data</b><br><i>Gal Mishne (Yale) &middot; Eric Chi (North Carolina State University) &middot; Ronald Coifman (Yale University)</i></p>
      <p><b>SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver</b><br><i>Po-Wei Wang (CMU) &middot; Priya Donti (Carnegie Mellon University) &middot; Bryan Wilder (University of Southern California) &middot; Zico Kolter (Carnegie Mellon University / Bosch Center for AI)</i></p>
      <p><b>Disentangled Graph Convolutional Networks</b><br><i>Jianxin Ma (Tsinghua University) &middot; Peng Cui (Tsinghua University) &middot; Kun Kuang (Tsinghua University) &middot; Xin Wang (Tsinghua University) &middot; wenwu zhu (Tsinghua University)</i></p>
      <p><b>State-Reification Networks: Improving Generalization by Modeling the Distribution of Hidden Representations</b><br><i>Alex Lamb (Universite de Montreal) &middot; Jonathan Binas (Mila, Montreal) &middot; Anirudh Goyal (Université de Montréal) &middot; Sandeep Subramanian (MILA) &middot; Ioannis Mitliagkas (MILA, UdeM) &middot; Yoshua Bengio (Mila / U. Montreal) &middot; Michael Mozer (Google Brain / University of Colorado)</i></p>
      <p><b>The Variational Predictive Natural Gradient</b><br><i>Da Tang (Columbia University) &middot; Rajesh Ranganath (New York University)</i></p>
      <p><b>Stochastic Optimization for DC Functions and Non-smooth Non-convex Regularizers with Non-asymptotic Convergence</b><br><i>Yi Xu (The University of Iowa) &middot; Qi Qi (The University of Iowa) &middot; Qihang Lin (Univ Iowa) &middot; rong jin (alibaba group) &middot; Tianbao Yang (The University of Iowa)</i></p>
      <p><b>Collective Model Fusion for Multiple Black-Box Experts</b><br><i>Minh Hoang (Carnegie Mellon University) &middot; Nghia Hoang (MIT-IBM Watson AI Lab, IBM Research) &middot; Bryan Kian Hsiang Low (National University of Singapore) &middot; Carleton Kingsford (Carnegie Mellon University)</i></p>
      <p><b>Correlated Variational Auto-Encoders</b><br><i>Da Tang (Columbia University) &middot; Dawen Liang (Netflix) &middot; Tony Jebara (Columbia and Netflix) &middot; Nicholas Ruozzi (UT Dallas)</i></p>
      <p><b>Dynamic Learning with Frequent New Product Launches: A Sequential Multinomial Logit Bandit Problem</b><br><i>Junyu Cao (University of California Berkeley) &middot; Wei Sun (IBM Research)</i></p>
      <p><b>Noisy Dual Principal Component Pursuit</b><br><i>Tianyu Ding (Johns Hopkins University) &middot; Zhihui Zhu (Johns Hopkins University) &middot; Tianjiao Ding (ShanghaiTech University) &middot; Yunchen Yang (ShanghaiTech) &middot; Daniel Robinson (Johns Hopkins University) &middot; Manolis Tsakiris (ShanghaiTech University) &middot; Rene Vidal (Johns Hopkins University, USA)</i></p>
      <p><b>Adversarial examples from computational constraints</b><br><i>Sebastien Bubeck (Microsoft Research) &middot; Yin Tat Lee (UW) &middot; Eric Price (UT-Austin) &middot; Ilya Razenshteyn (Microsoft Research Redmond)</i></p>
      <p><b>Composable Core-sets for Determinant Maximization: A Simple Near-Optimal Algorithm</b><br><i>Sepideh Mahabadi (Toyota Technological Institute at Chicago) &middot; Piotr Indyk (MIT) &middot; Shayan Oveis Gharan (University of Washington) &middot; Alireza Rezaei (University of Washington)</i></p>
      <p><b>Spectral Approximate Inference</b><br><i>Sejun Park (KAIST) &middot; Eunho Yang (KAIST,AITRICS) &middot; Se-Young Yun (KAIST) &middot; Jinwoo Shin (KAIST, AITRICS)</i></p>
      <p><b>Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search</b><br><i>Youhei Akimoto (University of Tsukuba / RIKEN AIP) &middot; Shinichi Shirakawa (Yokohama National University) &middot; Nozomu Yoshinari (Yokohama National University) &middot; Kento Uchida (Yokohama National University) &middot; Shota Saito (Yokohama National University) &middot; Kouhei Nishida (Shinshu University)</i></p>
      <p><b>Dual Entangled Polynomial Code: Three-Dimensional Coding for Distributed Matrix Multiplication</b><br><i>Pedro J Soto (Florida International University) &middot; Jun Li (Florida International University) &middot; Xiaodi Fan (Florida International University)</i></p>
      <p><b>Data Poisoning Attacks on Stochastic Bandits</b><br><i>Fang Liu (The Ohio State University) &middot; Ness Shroff (The Ohio State University)</i></p>
      <p><b>Scalable Fair Clustering</b><br><i>Arturs Backurs (Toyota Technological Institute at Chicago (TTIC)) &middot; Piotr Indyk (MIT) &middot; Krzysztof Onak (IBM Research) &middot; Baruch Schieber (New Jersey Institute of Technology) &middot; Ali Vakilian (Massachusetts Institute of Technology) &middot; Tal Wagner (MIT)</i></p>
      <p><b>Bayesian Optimization of Composite Functions</b><br><i>Raul Astudillo (Cornell University) &middot; Peter Frazier (Cornell University / Uber)</i></p>
      <p><b>Teaching a black-box learner</b><br><i>Sanjoy Dasgupta (UC San Diego) &middot; Daniel Hsu (Columbia University) &middot; Stefanos Poulis (UCSD) &middot; Jerry Zhu (University of Wisconsin-Madison)</i></p>
      <p><b>Self-Attention Graph Pooling</b><br><i>Junhyun Lee (Korea University) &middot; Inyeop Lee (Korea University) &middot; Jaewoo Kang (Korea University)</i></p>
      <p><b>An Instability in Variational Inference for Topic Models</b><br><i>Behrooz Ghorbani (Stanford University) &middot; Hamidreza Hakim Javadi (Rice University) &middot; Andrea Montanari (Stanford University)</i></p>
      <p><b>Optimal Auctions through Deep Learning</b><br><i>Paul Duetting (London School of Economics) &middot; Zhe Feng (Harvard University) &middot; Harikrishna Narasimhan (Google Research) &middot; David Parkes (Harvard University) &middot; Sai Srivatsa Ravindranath (Harvard University)</i></p>
      <p><b>Robust Inference via Generative Classifiers for Handling Noisy Labels</b><br><i>Kimin Lee (KAIST) &middot; Sukmin Yun (KAIST) &middot; Kibok Lee (University of Michigan) &middot; Honglak Lee (Google / U. Michigan) &middot; Bo Li (UIUC) &middot; Jinwoo Shin (KAIST, AITRICS)</i></p>
      <p><b>SAGA with Arbitrary Sampling</b><br><i>Xun Qian (KAUST) &middot; Peter Richtarik (KAUST) &middot; Zheng Qu (The University of Hong Kong)</i></p>
      <p><b>Predictor-Corrector Policy Optimization</b><br><i>Ching-An Cheng (Georgia Tech) &middot; Xinyan Yan (Georgia Tech) &middot; Nathan Ratliff (NVIDIA) &middot; Byron Boots (Georgia Tech)</i></p>
      <p><b>Imitating Latent Policies from Observation</b><br><i>Ashley Edwards (Georgia Institute of Technology) &middot; Himanshu Sahni (Georgia Institute of Technology) &middot; Yannick Schroecker (Georgia Institute of Technology) &middot; Charles Isbell (Georgia Institute of Technology)</i></p>
      <p><b>Predicate Exchange: Inference with Declarative Knowledge</b><br><i>Zenna Tavares (MIT) &middot; Rajesh Ranganath (New York University) &middot; Javier Burroni (UMass Amherst) &middot; Armando Solar-Lezama (MIT) &middot; Edgar Minasyan (Princeton University)</i></p>
      <p><b>Training CNNs with Selective Allocation of Channels</b><br><i>Jongheon Jeong (KAIST) &middot; Jinwoo Shin (KAIST, AITRICS)</i></p>
      <p><b>Learning Action Representations for Reinforcement Learning</b><br><i>Yash Chandak (University of Massachusetts Amherst) &middot; Georgios Theocharous (Adobe Research) &middot; James Kostas (UMass Amherst) &middot; Scott Jordan (University of Massachusetts Amherst) &middot; Philip Thomas (University of Massachusetts Amherst)</i></p>
      <p><b>Guided evolutionary strategies: augmenting random search with surrogate gradients</b><br><i>Niru Maheswaranathan (Google Brain) &middot; Luke Metz (Google Brain) &middot; George Tucker (Google Brain) &middot; Dami Choi (Google Brain) &middot; Jascha Sohl-Dickstein (Google Brain)</i></p>
      <p><b>Multiplicative Weights Updates as a distributed constrained optimization algorithm: Convergence to second-order stationary points almost always</b><br><i>Ioannis Panageas (SUTD) &middot; Georgios Piliouras (Singapore University of Technology and Design) &middot; xiao wang (Singapore university of technology and design)</i></p>
      <p><b>Sublinear quantum algorithms for training linear and kernel-based classifiers</b><br><i>Tongyang Li (University of Maryland) &middot; Shouvanik Chakrabarti (University of Maryland College Park) &middot; Xiaodi Wu (University of Maryland)</i></p>
      <p><b>DBSCAN++: Towards fast and scalable density clustering</b><br><i>Jennifer Jang (Uber) &middot; Heinrich Jiang (Google)</i></p>
      <p><b>Graph Element Networks: adaptive, structured computation and memory</b><br><i>Ferran Alet (MIT) &middot; Adarsh Keshav Jeewajee (Massachusetts Institute of Technology) &middot; Maria Bauza Villalonga (MIT) &middot; Alberto Rodriguez (MIT) &middot; Tomas Lozano-Perez (MIT) &middot; Leslie Kaelbling ((organization))</i></p>
      <p><b>Learning a Compressed Sensing Measurement Matrix via Gradient Unrolling</b><br><i>Shanshan Wu (University of Texas at Austin) &middot; Alexandros Dimakis (UT Austin) &middot; Sujay Sanghavi (UT Austin) &middot; Felix Xinnan Yu (Google AI) &middot; Daniel Holtmann-Rice (Google Inc) &middot; Dmitry Storcheus (Google Research) &middot; Afshin Rostamizadeh (Google) &middot; Sanjiv Kumar (Google Research, NY)</i></p>
      <p><b>Improving Neural Network Quantization without Retraining using Outlier Channel Splitting</b><br><i>Ritchie Zhao (Cornell University) &middot; Yuwei Hu (Cornell University) &middot; Jordan A Dotzel (Cornell University) &middot; Chris De Sa (Cornell) &middot; Zhiru Zhang (Cornell Univeristy)</i></p>
      <p><b>A Polynomial Time MCMC Method for  Sampling from Continuous Determinantal Point Processes</b><br><i>Alireza Rezaei (University of Washington) &middot; Shayan Oveis Gharan (University of Washington)</i></p>
      <p><b>Bayesian Deconditional Kernel Mean Embeddings</b><br><i>Kelvin Hsu (University of Sydney, CSIRO) &middot; Fabio Ramos (NVIDIA, University of Sydney)</i></p>
      <p><b>Kernel-Based Reinforcement Learning in Robust Markov Decision Processes</b><br><i>Shiau Hong Lim (IBM Research) &middot; Arnaud Autef (Ecole Polytechnique)</i></p>
      <p><b>Learning What and Where to Transfer</b><br><i>Yunhun Jang (OMNIOUS) &middot; Hankook Lee (KAIST) &middot; Sung Ju Hwang (KAIST, AITRICS) &middot; Jinwoo Shin (KAIST, AITRICS)</i></p>
      <p><b>Traditional and Heavy Tailed Self Regularization in Neural Network Models</b><br><i>Michael Mahoney (UC Berkeley) &middot; Charles Martin (Calculation Consulting)</i></p>
      <p><b>QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning</b><br><i>Kyunghwan Son (KAIST) &middot; Daewoo Kim (KAIST) &middot; Wan Ju Kang (KAIST) &middot; David Earl Hostallero (KAIST) &middot; Yung Yi (KAIST)</i></p>
      <p><b>Collaborative Channel Pruning for Deep Networks</b><br><i>Hanyu Peng (Shenzhen Institutes of Advanced Technology,Chinese Academy of Sciences) &middot; Jiaxiang Wu (Tencent AI Lab) &middot; Shifeng Chen (SIAT) &middot; Junzhou Huang (University of Texas at Arlington / Tencent AI Lab)</i></p>
      <p><b>Adaptive stochastic gradient algorithms on Riemannian manifolds</b><br><i>Hiroyuki Kasai (The University of Electro-Communications) &middot; Pratik Kumar Jawanpuria (Microsoft) &middot; Bamdev Mishra (Microsoft)</i></p>
      <p><b>On the statistical rate of nonlinear recovery in generative models with heavy-tailed data</b><br><i>Xiaohan Wei (University of Southern California) &middot; Zhuoran Yang (Princeton University) &middot; Zhaoran Wang (Northwestern U)</i></p>
      <p><b>Sample-Optimal Parametric Q-Learning with Linear Transition Models</b><br><i>Lin Yang (Princeton) &middot; Mengdi Wang (Princeton University)</i></p>
      <p><b>Collaborative Evolutionary Reinforcement Learning</b><br><i>Shauharda Khadka (Intel AI) &middot; Somdeb Majumdar (Intel AI Lab) &middot; Tarek Nassar (Intel AI Lab) &middot; Zach Dwiel (Intel AI Lab) &middot; Evren Tumer (Intel Corporation) &middot; Santiago Miret (Intel AI Products Group) &middot; Yinyin Liu (Intel AI Lab) &middot; Kagan Tumer (Oregon State University US)</i></p>
      <p><b>Composing Value Functions in Reinforcement Learning</b><br><i>Benjamin van Niekerk (University of the Witwatersrand) &middot; Steven James (University of the Witwatersrand) &middot; Adam Earle (University of the Witwatersrand) &middot; Benjamin Rosman (Council for Scientific and Industrial Research)</i></p>
      <p><b>The Effect of Network Width on Stochastic Gradient Descent: an Empirical Study</b><br><i>Daniel Park (Google Brain) &middot; Jascha Sohl-Dickstein (Google Brain) &middot; Quoc Le (Google Brain) &middot; Samuel L Smith (DeepMind)</i></p>
      <p><b>Few-Shot Intent Inference via Meta-Inverse Reinforcement Learning</b><br><i>Kelvin Xu (University of California, Berkeley) &middot; Ellis Ratner (University of California, Berkeley) &middot; EECS Anca Dragan (EECS Department, University of California, Berkeley) &middot; Sergey Levine (Berkeley) &middot; Chelsea Finn (Stanford, Google, UC Berkeley)</i></p>
      <p><b>Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks</b><br><i>Sanjeev Arora ( Princeton University and Institute for Advanced Study) &middot; Simon Du (Carnegie Mellon University) &middot; Wei Hu (Princeton University) &middot; Zhiyuan Li (Princeton University) &middot; Ruosong Wang (Carnegie Mellon University)</i></p>
      <p><b>Calibrated Model-Based Deep Reinforcement Learning</b><br><i>Ali Malik (Stanford Universtiy) &middot; Volodymyr Kuleshov (Stanford University) &middot; Jiaming Song (Stanford) &middot; Danny Nemer (Afresh Technologies) &middot; Harlan Seymour (Afresh Technologies) &middot; Stefano Ermon (Stanford University)</i></p>
      <p><b>On the Long-term Impact of Algorithmic Decision Policies: Effort Unfairness and Feature Segregation through Social Learning</b><br><i>Hoda Heidari (ETHZ) &middot; Vedant Nanda (MPI-SWS) &middot; Krishna Gummadi (MPI-SWS)</i></p>
      <p><b>Towards A Deep and Unified Understanding of Deep Neural Models in NLP</b><br><i>Chaoyu Guan (Shanghai Jiao Tong University) &middot; Xiting Wang (Microsoft Research Asia) &middot; Quanshi Zhang (Shanghai Jiao Tong University) &middot; Runjin Chen (Shanghai Jiao Tong University) &middot; Di He (Peking University) &middot; Xing Xie (Microsoft Research Asia)</i></p>
      <p><b>Position-aware Graph Neural Networks</b><br><i>Jiaxuan You (Stanford University) &middot; Rex (Zhitao) Ying (Stanford University) &middot; Jure Leskovec (Stanford University)</i></p>
      <p><b>Width Provably Matters in Optimization for Deep Linear Neural Networks</b><br><i>Simon Du (Carnegie Mellon University) &middot; Wei Hu (Princeton University)</i></p>
      <p><b>Fast and Stable Maximum Likelihood Estimation for Incomplete Multinomial Data</b><br><i>Chenyang ZHANG (University of Hong Kong) &middot; Guosheng Yin (University of Hong Kong)</i></p>
      <p><b>Neural Network Attributions: A Causal Perspective</b><br><i>Aditya Chattopadhyay (Johns Hopkins University) &middot; Piyushi Manupriya (IIT Hyderabad) &middot; Anirban Sarkar (Indian Institute of Technology, Hyderabad) &middot; Vineeth N Balasubramanian (Indian Institute of Technology, Hyderabad)</i></p>
      <p><b>Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance</b><br><i>Dasaem Jeong (KAIST) &middot; Taegyun Kwon (KAIST) &middot; Yoojin Kim (KAIST) &middot; Juhan Nam (KAIST)</i></p>
      <p><b>Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication</b><br><i>Anastasiia Koloskova (EPFL) &middot; Sebastian Stich (EPFL) &middot; Martin Jaggi (EPFL)</i></p>
      <p><b>Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference</b><br><i>Yatao (An) Bian (ETH Zürich) &middot; Joachim Buhmann (ETH Zurich) &middot; Andreas Krause (ETH Zurich)</i></p>
      <p><b>Fast Algorithm for Generalized Multinomial Models with Ranking Data</b><br><i>Jiaqi Gu (The University of Hong Kong) &middot; Guosheng Yin (University of Hong Kong)</i></p>
      <p><b>Iterative Deep Generative Modeling of Large Graphs</b><br><i>Aditya Grover (Stanford University) &middot; Aaron Zweig (Stanford University) &middot; Stefano Ermon (Stanford University)</i></p>
      <p><b>NAS-Bench-101: Towards Reproducible Neural Architecture Search</b><br><i>Chris Ying (Google Brain) &middot; Aaron Klein (University of Freiburg) &middot; Eric Christiansen (Google) &middot; Esteban Real (Google Inc.) &middot; Kevin Murphy (Google Brain) &middot; Frank Hutter (University of Freiburg)</i></p>
      <p><b>Obtaining Fairness using Optimal Transport Theory</b><br><i>Paula Gordaliza (Institut de Mathématiques de Toulouse and IMUVA) &middot; Eustasio del Barrio (IMUVA) &middot; Gamboa Fabrice (Université Toulouse Paul Sabatier Institut de Mathématiques de Toulouse) &middot; Loubes Jean-Michel (Université Toulouse Paul Sabatier Institut de Mathématiques de Toulouse)</i></p>
      <p><b>Leveraging Low-Rank Relations Between Surrogate Tasks in Structured Prediction</b><br><i>Giulia Luise (University College London) &middot; Dimitrios Stamos (University College London) &middot; Massimiliano Pontil (Istituto Italiano di Tecnologia and University College London) &middot; Carlo Ciliberto ()</i></p>
      <p><b>Almost surely constrained convex optimization</b><br><i>Olivier Fercoq (Télécom ParisTech, Université Paris-Saclay) &middot; Ahmet Alacaoglu (EPFL) &middot; Ion Necoara (University Bucharest) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>Exploiting Worker Correlation for Label Aggregation in Crowdsourcing</b><br><i>Yuan Li (University of Melbourne) &middot; Benjamin Rubinstein (University​ of Melbourne) &middot; Trevor Cohn (University of Melbourne)</i></p>
      <p><b>Phase transition in PCA with missing data: Reduced signal-to-noise ratio, not sample size!</b><br><i>Niels Ipsen (Technical University of Denmark) &middot; Lars Kai Hansen (Technical University of Denmark)</i></p>
      <p><b>A Better k-means++ Algorithm via Local Search</b><br><i>Silvio Lattanzi (Google Zurich) &middot; Christian Sohler (Google)</i></p>
      <p><b>Adversarial Generation of Time-Frequency Features with application in audio synthesis</b><br><i>Andrés Marafioti (Austrian Academy of Sciences) &middot; Nathanaël Perraudin (Swiss Data Science Center) &middot; Nicki Holighaus (Acoustics Research Institute) &middot; Piotr Majdak (Acoustics Research Institute)</i></p>
      <p><b>First-Order Adversarial Vulnerability of Neural Networks and Input Dimension</b><br><i>Carl-Johann Simon-Gabriel (Max-Planck-Institute for Intelligent Systems) &middot; Yann Ollivier (Facebook Artificial Intelligence Research) &middot; Leon Bottou (Facebook) &middot; Bernhard Schölkopf (MPI for Intelligent Systems Tübingen, Germany) &middot; David Lopez-Paz (Facebook AI Research)</i></p>
      <p><b>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</b><br><i>Yujia Li (DeepMind) &middot; Chenjie Gu (DeepMind) &middot; Thomas Dullien (Google) &middot; Oriol Vinyals (DeepMind) &middot; Pushmeet Kohli (DeepMind)</i></p>
      <p><b>Graph Convolutional Gaussian Processes</b><br><i>Ian Walker (Imperial College London) &middot; Ben Glocker (Imperial College London)</i></p>
      <p><b>SelectiveNet: A Deep Neural Network with an Integrated Reject Option</b><br><i>Yonatan Geifman (Technion) &middot; Ran El-Yaniv (Technion)</i></p>
      <p><b>Certifying Robustness of Neural Networks with a Probabilistic Approach</b><br><i>Tsui-Wei Weng (MIT) &middot; Pin-Yu Chen (IBM Research AI) &middot; Lam Nguyen (IBM Research, Thomas J. Watson Research Center) &middot; Mark Squillante (IBM Research) &middot; Akhilan Boopathy (MIT) &middot; Ivan Oseledets (Skolkovo Institute of Science and Technology) &middot; Luca Daniel (Massachusetts Institute of Technology)</i></p>
      <p><b>Beyond the Chinese Restaurant and Pitman-Yor processes: Statistical Models with double power-law behavior</b><br><i>Fadhel Ayed (University of Oxford) &middot; Juho Lee (AITRICS, University of Oxford) &middot; Francois Caron (Oxford)</i></p>
      <p><b>Learning Discrete and Continuous Factors of Data via Alternating Disentanglement</b><br><i>Yeonwoo Jeong (Seoul National University) &middot; Hyun Oh Song (Seoul National University)</i></p>
      <p><b>TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning</b><br><i>Sung Whan Yoon (Korea Advanced Institute of Science and Technology (KAIST)) &middot; Jun Seo (Korea Advanced Institute of Science and Technology(KAIST)) &middot; Jaekyun Moon (KAIST)</i></p>
      <p><b>A Theory of Regularized Markov Decision Processes</b><br><i>Matthieu Geist (Google) &middot; Bruno Scherrer (INRIA) &middot; Olivier Pietquin (GOOGLE BRAIN)</i></p>
      <p><b>EMI: Exploration with Mutual Information</b><br><i>Hyoungseok Kim (Seoul National University) &middot; Jaekyeom Kim (Seoul National University) &middot; Yeonwoo Jeong (Seoul National University) &middot; Sergey Levine (Berkeley) &middot; Hyun Oh Song (Seoul National University)</i></p>
      <p><b>Deep Gaussian Processes with Importance-Weighted Variational Inference</b><br><i>Hugh Salimbeni (Imperial College) &middot; Vincent Dutordoir (PROWLER.io) &middot; James Hensman (PROWLER.io) &middot; Marc P Deisenroth (Imperial College London and PROWLER.io)</i></p>
      <p><b>A Deep Reinforcement Learning Perspective on Internet Congestion Control</b><br><i>Nathan Jay (University of Illinois Urbana-Champaign) &middot; Noga H. Rotman (Hebrew University of Jerusalem) &middot; Brighten  Godfrey (University of Illinois Urbana-Champaign) &middot; Michael Schapira (Hebrew University of Jerusalem) &middot; Aviv Tamar (Technion Israeli Institute of Technology)</i></p>
      <p><b>Model Function Based Conditional Gradient Method with Armijo-like Line Search</b><br><i>Peter Ochs (Saarland University) &middot; Yura Malitsky (University of Göttingen)</i></p>
      <p><b>End-to-End Probabilistic Inference for Nonstationary Audio Analysis</b><br><i>William Wilkinson (Queen Mary University of London) &middot; Michael Riis Andersen (Technical University of Denmark) &middot; Joshua D. Reiss (Queen Mary University of London) &middot; Dan Stowell (Queen Mary University of London) &middot; Arno Solin (Aalto University)</i></p>
      <p><b>Generalized Approximate Survey Propagation for High-Dimensional Estimation</b><br><i>Carlo Lucibello (Bocconi University) &middot; Luca Saglietti (Microsoft Research) &middot; Yue Lu (Harvard University, USA)</i></p>
      <p><b>Generative Modeling of Infinite Occluded Objects for Compositional Scene Representation</b><br><i>Jinyang Yuan (Fudan University) &middot; Bin Li (Fudan University) &middot; Xiangyang Xue (Fudan University)</i></p>
      <p><b>On Certifying Non-Uniform Bounds against Adversarial Attacks</b><br><i>Chen Liu (EPFL) &middot; Ryota Tomioka (Microsoft Research Cambridge) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>Hierarchical Decompositional Mixtures of Variational Autoencoders</b><br><i>Ping Liang Tan (University of Cambridge) &middot; Robert Peharz (University of Cambridge)</i></p>
      <p><b>CompILE: Compositional Imitation Learning and Execution</b><br><i>Thomas Kipf (University of Amsterdam) &middot; Yujia Li (DeepMind) &middot; Hanjun Dai (Georgia Tech) &middot; Vinicius Zambaldi (Deepmind) &middot; Alvaro Sanchez (DeepMind) &middot; Edward Grefenstette (Facebook AI Research / UCL) &middot; Pushmeet Kohli (DeepMind) &middot; Peter Battaglia (DeepMind)</i></p>
      <p><b>Heterogeneous Model Reuse via Optimizing Multiparty Multiclass Margin</b><br><i>Xi-Zhu Wu (Nanjing University) &middot; Song Liu (University of Bristol) &middot; Zhi-Hua Zhou (Nanjing University)</i></p>
      <p><b>Reinforcement Learning in Configurable Continuous Environments</b><br><i>Alberto Maria Metelli (Politecnico di Milano) &middot; Emanuele Ghelfi (Politecnico di Milano) &middot; Marcello Restelli (Politecnico di Milano)</i></p>
      <p><b>Random Expert Distillation: Imitation Learning via Expert Policy Support Estimation</b><br><i>Ruohan Wang (Imperial College London) &middot; Carlo Ciliberto () &middot; Pierluigi Vito Amadori (Imperial College London) &middot; Yiannis Demiris (Imperial College London)</i></p>
      <p><b>Context-Aware Zero-Shot Learning for Object Recognition</b><br><i>Eloi Zablocki (Sorbonne Université, LIP6) &middot; Patrick Bordes (Laboratoire d'Informatique de PARIS VI) &middot; Laure Soulier (Sorbonne Université) &middot; Benjamin Piwowarski (Sorbonne Université) &middot; Patrick Gallinari (LIP6, Sorbonne Universite)</i></p>
      <p><b>A Convergence Theory for Deep Learning via Over-Parameterization</b><br><i>Zeyuan Allen-Zhu (Microsoft Research AI) &middot; Yuanzhi Li (Stanford) &middot; Zhao Song (UT-Austin)</i></p>
      <p><b>Learning Context-dependent Label Permutations for Multi-label Classification</b><br><i>Jinseok Nam (Amazon) &middot; Young-Bum Kim (Amazon) &middot; Eneldo Loza Mencia (TU Darmstadt) &middot; Sunghyun Park (Aamzon) &middot; Ruhi Sarikaya (Amazon) &middot; Johannes Fürnkranz (TU Darmstadt)</i></p>
      <p><b>Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization</b><br><i>Seungyong Moon (Seoul National University) &middot; Hyun Oh Song (Seoul National University) &middot; Gaon An (Seoul National University)</i></p>
      <p><b>Hyperbolic Disk Embeddings for Directed Acyclic Graphs</b><br><i>Ryota Suzuki (scouty Inc.) &middot; Ryusuke Takahama (scouty Inc.) &middot; Shun Onoda (scouty Inc.)</i></p>
      <p><b>Kernel Normalized Cut: a Theoretical Revisit</b><br><i>Yoshikazu Terada (Osaka University / RIKEN) &middot; Michio Yamamoto (Okayama University / RIKEN)</i></p>
      <p><b>Causal Discovery and Forecasting in Nonstationary Environments with State-Space Models</b><br><i>Biwei Huang (Carnegie Mellon University) &middot; Kun Zhang (Carnegie Mellon University) &middot; Mingming Gong (University of Pittsburgh & CMU) &middot; Clark Glymour (Carnegie Mellon University)</i></p>
      <p><b>Complementary-Label Learning for Arbitrary Losses and Models</b><br><i>Takashi Ishida (The University of Tokyo / RIKEN) &middot; Gang Niu (RIKEN) &middot; Aditya Menon (Australian National University) &middot; Masashi Sugiyama (RIKEN / The University of Tokyo)</i></p>
      <p><b>Distribution calibration for regression</b><br><i>Hao Song (University of Bristol) &middot; Tom Diethe (Amazon) &middot; Meelis Kull (University of Tartu) &middot; Peter Flach (University of Bristol)</i></p>
      <p><b>Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces</b><br><i>Johannes Kirschner (ETH Zurich) &middot; Mojmir Mutny (ETH Zurich) &middot; Nicole Hiller (PSI) &middot; Rasmus Ischebeck (PSI) &middot; Andreas Krause (ETH Zurich)</i></p>
      <p><b>Optimistic Policy Optimization via Multiple Importance Sampling</b><br><i>Matteo Papini (Politecnico di Milano) &middot; Alberto Maria Metelli (Politecnico di Milano) &middot; Lorenzo Lupo (Politecnico di Milano) &middot; Marcello Restelli (Politecnico di Milano)</i></p>
      <p><b>Target Tracking for Contextual Bandits: Application to Demand Side Management</b><br><i>Margaux Brégère (CNRS Université Paris-Sud, Inria Paris, EDF R&D) &middot; Pierre Gaillard (INRIA Paris) &middot; Yannig Goude (EDF Lab Paris-Saclay) &middot; Gilles Stoltz (Université paris Sud)</i></p>
      <p><b>Analogies Explained: Towards Understanding Word Embeddings</b><br><i>Carl Allen (The University of Edinburgh) &middot; Timothy Hospedales (Samsung AI Centre / University of Edinburgh)</i></p>
      <p><b>Feature-Critic Networks for Heterogeneous Domain Generalization</b><br><i>Yiying Li (National University of Defense Technology) &middot; Yongxin Yang (University of Edinburgh ) &middot; Wei Zhou (National University of Defense Technology) &middot; Timothy Hospedales (Samsung AI Centre / University of Edinburgh)</i></p>
      <p><b>Non-Monotonic Sequential Text Generation</b><br><i>Sean Welleck (New York University) &middot; Kiante Brantley (The University of Maryland College Park) &middot; Hal Daume (Microsoft Research) &middot; Kyunghyun Cho (New York University)</i></p>
      <p><b>Partially Exchangeable Networks and Architectures for Learning Summary Statistics in Approximate Bayesian Computation</b><br><i>Samuel Wiqvist (Lund University) &middot; Pierre-Alexandre Mattei (IT University Copenhagen) &middot; Umberto Picchini (Department of Mathematical Sciences, Chalmers University of Technology and the University of Gothenburg) &middot; Jes Frellsen (IT University of Copenhagen)</i></p>
      <p><b>Robustly Disentangled Causal Mechanisms: Validating Deep Representations for Interventional Robustness</b><br><i>Raphael Suter (ETH Zurich) &middot; Djordje Miladinovic (ETH Zurich) &middot; Stefan Bauer (MPI for Intelligent Systems) &middot; Bernhard Schölkopf (MPI for Intelligent Systems Tübingen, Germany)</i></p>
      <p><b>Projections for Approximate Policy Iteration Algorithms</b><br><i>Riad Akrour (TU Darmstadt) &middot; Joni Pajarinen (TU Darmstadt) &middot; Jan Peters (TU Darmstadt + Max Planck Institute for Intelligent Systems) &middot; Gerhard Neumann (University of Lincoln)</i></p>
      <p><b>Ithemal: Accurate, Portable and Fast Basic Block Throughput Estimation using Deep Neural Networks</b><br><i>Charith Mendis (MIT) &middot; Alex Renda (MIT) &middot; Dr.Saman Amarasinghe (Massachusetts institute of technology) &middot; Michael Carbin (MIT)</i></p>
      <p><b>Scaling Up Ordinal Embedding: A Landmark Approach</b><br><i>Jesse Anderton (Northeastern University) &middot; Javed Aslam (Northeastern University)</i></p>
      <p><b>Escaping Saddle Points with Adaptive Gradient Methods</b><br><i>Matthew Staib (MIT) &middot; Sashank Jakkam Reddi (Google) &middot; Satyen Kale (Google) &middot; Sanjiv Kumar (Google Research, NY) &middot; Suvrit Sra (MIT)</i></p>
      <p><b>FloWaveNet : A Generative Flow for Raw Audio</b><br><i>Sungwon Kim (Seoul National University) &middot; Sang-gil Lee (Seoul National University) &middot; Jongyoon Song (Seoul National University) &middot; Jaehyeon Kim (Kakao Corp) &middot; Sungroh Yoon (Seoul National University)</i></p>
      <p><b>Demystifying Dropout</b><br><i>Hongchang Gao (University of Pittsburgh) &middot; Jian Pei (Simon Fraser University) &middot; Heng Huang (University of Pittsburgh)</i></p>
      <p><b>Estimate Sequences for Variance-Reduced Stochastic Composite Optimization</b><br><i>Andrei Kulunchakov (Inria) &middot; Julien Mairal (Inria)</i></p>
      <p><b>AdaGrad stepsizes: sharp convergence over nonconvex landscapes</b><br><i>Rachel Ward (University of Texas) &middot; Xiaoxia Wu (The University of Texas at Austin) &middot; Leon Bottou (Facebook)</i></p>
      <p><b>Analyzing Beam Search Performance Degradation in Neural Sequence Models</b><br><i>Eldan Cohen (University of Toronto) &middot; Christopher Beck (University of Toronto)</i></p>
      <p><b>Learning to Infer Program Sketches</b><br><i>Maxwell Nye (MIT) &middot; Luke Hewitt (Massachusetts Institute of Technology) &middot; Josh Tenenbaum (MIT) &middot; Armando Solar-Lezama (MIT)</i></p>
      <p><b>White-box vs Black-box: Bayes Optimal Strategies for Membership Inference</b><br><i>Alexandre Sablayrolles (Facebook AI Research) &middot; Douze Matthijs (Facebook AI Research) &middot; Cordelia Schmid (Inria/Google) &middot; Yann Ollivier (Facebook Artificial Intelligence Research) &middot; Herve Jegou (Facebook AI Research)</i></p>
      <p><b>Learning Models from Data with Measurement Error: Tackling Underreporting</b><br><i>Roy Adams (Johns Hopkins University) &middot; Yuelong Ji (Johns Hopkins University) &middot; Xiaobin Wang (Johns Hopkins University) &middot; Suchi Saria (Johns Hopkins University)</i></p>
      <p><b>Counterfactual Visual Explanations</b><br><i>Yash Goyal (Georgia Tech) &middot; Ziyan Wu (United Imaging Intelligence) &middot; Jan Ernst (Siemens Corporation) &middot; Dhruv Batra (Georgia Institute of Technology / Facebook AI Research) &middot; Devi Parikh (Georgia Tech & Facebook AI Research) &middot; Stefan Lee (Georgia Institute of Technology)</i></p>
      <p><b>Discovering Latent Covariance Structures for Multiple Time Series</b><br><i>Anh Tong (Ulsan National Institute of Science and Technology) &middot; Jaesik Choi (Ulsan National Institute of Science and Technology)</i></p>
      <p><b>BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning</b><br><i>Asa Cooper Stickland (University of Edinburgh) &middot; Iain Murray (University of Edinburgh)</i></p>
      <p><b>On the Complexity of Approximating Wasserstein Barycenter</b><br><i>Alexey Kroshnin (Institute for Information Transmission Problems) &middot; Nazarii Tupitsa (Institute for Information Transmission Problems) &middot; Darina Dvinskikh (Weierstrass Institute for Applied Analysis and Stochastics) &middot; Pavel Dvurechenskii (WIAS im Forschungsverbund Berlin e. V.) &middot; Alexander Gasnikov (Moscow Institute of Physics and Technology) &middot; Cesar Uribe (MIT)</i></p>
      <p><b>Adversarial Attacks on Node Embeddings</b><br><i>Aleksandar Bojchevski (Technical University of Munich) &middot; Stephan Günnemann (Technical University of Munich)</i></p>
      <p><b>Projection onto Minkowski Sums with Application to Constrained Learning</b><br><i>Kenneth Lange (UCLA) &middot; Joong-Ho Won (Seoul National University) &middot; Jason Xu (Duke University)</i></p>
      <p><b>Calibrated Approximate Bayesian Inference</b><br><i>Hanwen Xing (University of Oxford) &middot; Geoff Nicholls (University of Oxford) &middot; Jeong Lee (University of Auckland)</i></p>
      <p><b> Fair Regression: Quantitative Definitions and Reduction-Based Algorithms</b><br><i>Alekh Agarwal (Microsoft Research) &middot; Miroslav Dudik (Microsoft Research) &middot; Zhiwei Steven Wu (University of Minnesota)</i></p>
      <p><b>Processing Megapixel Images with Deep Attention-Sampling Models</b><br><i>Angelos Katharopoulos (Idiap & EPFL) &middot; Francois Fleuret (Idiap research institute)</i></p>
      <p><b>Learning from a Learner</b><br><i>alexis jacq (EPFL) &middot; Matthieu Geist (Google) &middot; Ana Paiva (INESC-ID U of Lisbon) &middot; Olivier Pietquin (GOOGLE BRAIN)</i></p>
      <p><b>Orthogonal Random Forest with Applications to Heterogeneous Treatment Effect Estimation </b><br><i>Miruna Oprescu (Microsoft Research) &middot; Vasilis Syrgkanis (Microsoft Research) &middot; Zhiwei Steven Wu (University of Minnesota)</i></p>
      <p><b>Structured agents for physical construction</b><br><i>Victor Bapst (Google DeepMind) &middot; Alvaro Sanchez (DeepMind) &middot; Carl Doersch (DeepMind) &middot; Kimberly Stachenfeld (Google) &middot; Pushmeet Kohli (DeepMind) &middot; Peter Battaglia (DeepMind) &middot; Jessica Hamrick (DeepMind)</i></p>
      <p><b>Exploring the Landscape of Spatial Robustness</b><br><i>Logan Engstrom (MIT) &middot; Brandon Tran (MIT) &middot; Dimitris Tsipras (MIT) &middot; Ludwig Schmidt (UC Berkeley) &middot; Aleksander Madry (MIT)</i></p>
      <p><b>Faster Attend-Infer-Repeat with Tractable Probabilistic Models</b><br><i>Karl Stelzner (TU Darmstadt) &middot; Robert Peharz (University of Cambridge) &middot; Kristian Kersting (TU Darmstadt)</i></p>
      <p><b>Adaptive Sensor Placement for Continuous Spaces</b><br><i>James Grant (Lancaster University) &middot; Alexis Boukouvalas (PROWLER.io) &middot; Ryan-Rhys Griffiths (University of Cambridge) &middot; David Leslie (Lancaster University) &middot; Sattar Vakili (Prowler.io) &middot; Enrique Munoz De Cote (PROWLER.io)</i></p>
      <p><b>Partially Linear Additive Gaussian Graphical Models</b><br><i>Sinong Geng (Princeton University) &middot; Minhao Yan (Cornell University) &middot; Mladen Kolar (University of Chicago Booth School of Business) &middot; Sanmi Koyejo (University of Illinois at Urbana-Champaign)</i></p>
      <p><b>Learning to Route in Similarity Graphs</b><br><i>Dmitry Baranchuk (Yandex) &middot; Dmitry Persiyanov (Yandex) &middot; Anton Sinitsin (HSE) &middot; Artem Babenko (Yandex)</i></p>
      <p><b>Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</b><br><i>Francesco Locatello (ETH Zurich - Max Planck Institute) &middot; Stefan Bauer (MPI for Intelligent Systems) &middot; Mario Lucic (Google Brain) &middot; Gunnar Raetsch (ETH Zurich) &middot; Sylvain Gelly (Google Brain) &middot; Bernhard Schölkopf (MPI for Intelligent Systems Tübingen, Germany) &middot; Olivier Bachem (Google Brain)</i></p>
      <p><b>Fast Context Adaptation via Meta-Learning</b><br><i>Luisa Zintgraf (University of Oxford) &middot; Kyriacos Shiarlis (University of Amsterdam) &middot; Vitaly Kurin (University of Oxford) &middot; Katja Hofmann (Microsoft) &middot; Shimon Whiteson (University of Oxford)</i></p>
      <p><b>Trimming the $\ell_1$ Regularizer: Statistical Analysis, Optimization, and Applications to Deep Learning</b><br><i>Jihun Yun (KAIST) &middot; Peng Zheng (University of Washington) &middot; Eunho Yang (KAIST,AITRICS) &middot; Aurelie Lozano (IBM) &middot; Aleksandr Aravkin (UW)</i></p>
      <p><b>Emerging Convolutions for Generative Normalizing Flows</b><br><i>Emiel Hoogeboom (University of Amsterdam) &middot; Rianne Van den Berg (University of Amsterdam) &middot; Max Welling (University of Amsterdam & Qualcomm)</i></p>
      <p><b>Learning interpretable continuous-time models of latent stochastic dynamical systems</b><br><i>Lea Duncker (Gatsby Unit, UCL) &middot; Gergo Bohner (Gatsby Unit, UCL) &middot; Julien Boussard (Stanford university) &middot; Maneesh Sahani (Gatsby Unit, UCL)</i></p>
      <p><b>Learning to bid in revenue-maximizing auctions</b><br><i>Thomas Nedelec (ENS Paris Saclay - Criteo AI Lab) &middot; Noureddine El Karoui (Criteo AI Lab and UC, Berkeley) &middot; Vianney Perchet (ENS Paris Saclay & Criteo AI Lab)</i></p>
      <p><b>Model-Based Active Exploration</b><br><i>Pranav Shyam (NNAISENSE) &middot; Wojciech Jaskowski (NNAISENSE) &middot; Faustino  Gomez (NNAISENSE SA)</i></p>
      <p><b>Target TD-Learning with Linear Function Approximation</b><br><i>Donghwan Lee (University of Illinois, Urbana-Champaign) &middot; Niao He (UIUC)</i></p>
      <p><b>Combining parametric and nonparametric models for off-policy evaluation</b><br><i>Omer Gottesman (Harvard University) &middot; Yao Liu (Stanford University) &middot; Scott Sussex (Harvard University) &middot; Emma Brunskill (Stanford University) &middot; Finale Doshi-Velez (Harvard University)</i></p>
      <p><b>Transfer of Samples in Policy Search via Multiple Importance Sampling</b><br><i>Andrea Tirinzoni (Politecnico di Milano) &middot; Mattia Salvini (Politecnico di Milano) &middot; Marcello Restelli (Politecnico di Milano)</i></p>
      <p><b>Understanding Geometry of Encoder-Decoder CNNs</b><br><i>Jong Chul Ye ("Department of Bio and Brain Engineering, KAIST, Korea") &middot; woonkyoung Sung (KAIST)</i></p>
      <p><b>The Value Function Polytope in Reinforcement Learning</b><br><i>Robert Dadashi (Google AI Residency Program) &middot; Marc Bellemare (Google Brain) &middot; Adrien Ali Taiga (Université de Montréal) &middot; Nicolas Le Roux (Google) &middot; Dale Schuurmans (Google / University of Alberta)</i></p>
      <p><b>DeepMDP: Learning Continuous Latent Space Models with Theoretical Guarantees</b><br><i>Carles Gelada (Google Brain) &middot; Saurabh Kumar (Google Brain) &middot; Jacob Buckman (Johns Hopkins University) &middot; Ofir Nachum (Google Brain) &middot; Marc Bellemare (Google Brain)</i></p>
      <p><b>On discriminative learning of prediction uncertainty</b><br><i>Vojtech Franc (Czech Technical University in Prague) &middot; Daniel Prusa (Czech technical university in Prague)</i></p>
      <p><b>Same, Same But Different: Recovering Neural Network Quantization Error Through Weight Factorization</b><br><i>Eldad Meller (Hailo) &middot; Alexander Finkelstein (Hailo Technologies) &middot; Uri Almog (Hailo Technologies) &middot; Mark Grobman (Hailo Technologies)</i></p>
      <p><b>Agnostic Federated Learning</b><br><i>Mehryar Mohri (Courant Institute and Google Research) &middot; Gary Sivek (Google) &middot; Ananda Suresh (Google)</i></p>
      <p><b>Efficient Amortised Bayesian Inference for Hierarchical and Nonlinear Dynamical Systems</b><br><i>Ted Meeds (Microsoft Research) &middot; Geoffrey Roeder (Princeton University) &middot; Paul Grant (Microsoft Research) &middot; Andrew Phillips (Microsoft Research) &middot; Neil Dalchau (Microsoft Research)</i></p>
      <p><b>Finding Mixed Nash Equilibria of Generative Adversarial Networks</b><br><i>Ya-Ping Hsieh (EPFL) &middot; Chen Liu (EPFL) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>When Samples Are Strategically Selected</b><br><i>Hanrui Zhang (Duke University) &middot; Yu Cheng (Duke University) &middot; Vincent Conitzer (Duke)</i></p>
      <p><b>Understanding the Impact of Entropy on Policy Optimization</b><br><i>Zafarali Ahmed (Mila - McGill University) &middot; Nicolas Le Roux (Google) &middot; Mohammad Norouzi (Google Brain) &middot; Dale Schuurmans (Google / University of Alberta)</i></p>
      <p><b>Differentiable Decoding of Sets of Sequences for Neural Sequence Models</b><br><i>Ashwin Kalyan (Georgia Tech) &middot; Peter Anderson (Georgia Tech) &middot; Stefan Lee (Georgia Institute of Technology) &middot; Dhruv Batra (Georgia Institute of Technology / Facebook AI Research)</i></p>
      <p><b>On the Limitations of Representing Functions on Sets</b><br><i>Edward Wagstaff (University of Oxford) &middot; Fabian Fuchs (Oxford Robotics Insitute) &middot; Martin Engelcke (University of Oxford) &middot; Herbert Ingmar Posner (University of Oxford) &middot; Michael A Osborne (U Oxford)</i></p>
      <p><b>Self-similar Epochs: Value in arrangement</b><br><i>Eliav Buchnik (Tel Aviv University) &middot; Edith Cohen (Google Research and Tel Aviv University) &middot; Avinatan Hasidim (Google) &middot; Yossi Matias (Google)</i></p>
      <p><b>Uniform Convergence Rate of the Kernel Density Estimator Adaptive to Intrinsic Volume Dimension</b><br><i>Jisu Kim (Inria Saclay) &middot; Jaehyeok Shin (Carnegie Mellon University) &middot; Alessandro Rinaldo (Carnegie Mellon University) &middot; Larry Wasserman (Carnegie Mellon University)</i></p>
      <p><b>Locally Private Bayesian Inference for Count Models</b><br><i>Aaron Schein (UMass Amherst) &middot; Zhiwei Steven Wu (University of Minnesota) &middot; Alexandra Schofield (Cornell University) &middot; Mingyuan Zhou (University of Texas at Austin) &middot; Hanna Wallach (Microsoft Research)</i></p>
      <p><b>Optimal Transport for structured data with application on graphs</b><br><i>Titouan Vayer (IRISA) &middot; Nicolas Courty (IRISA, Universite Bretagne-Sud) &middot; Romain Tavenard (LETG-Rennes /  IRISA-Obelix) &middot; Chapel Laetitia (IRISA) &middot; Remi Flamary (Université côte d'Azur)</i></p>
      <p><b>Differentially Private Fair Learning</b><br><i>Matthew Jagielski (Northeastern University) &middot; Michael Kearns (University of Pennsylvania) &middot; Jieming Mao (University of Pennsylvania) &middot; Alina Oprea (Northeastern University) &middot; Aaron Roth (University of Pennsylvania) &middot; Saeed Sharifi-Malvajerdi (University of Pennsylvania) &middot; Jonathan Ullman (Northeastern University)</i></p>
      <p><b>Making Deep Q-learning methods robust to time discretization</b><br><i>Corentin Tallec (Univ. Paris-Sud) &middot; Leonard Blier (Université Paris Sud and Facebook) &middot; Yann Ollivier (Facebook Artificial Intelligence Research)</i></p>
      <p><b>The Odds are Odd: A Statistical Test for Detecting Adversarial Examples</b><br><i>Kevin Roth (ETH Zurich) &middot; Yannic Kilcher (ETH Zurich) &middot; Thomas Hofmann (ETH Zurich)</i></p>
      <p><b>Multi-objective training of Generative Adversarial Networks with multiple discriminators</b><br><i>Isabela Albuquerque (Institut National de la Recherche Scientifique) &middot; Joao Monteiro (Institut National de la Recherche Scientifique (INRS)) &middot; Thang Doan (McGill University) &middot; Breandan Considine (Mila) &middot; Tiago Falk (INRS-EMT) &middot; Ioannis Mitliagkas (MILA, UdeM)</i></p>
      <p><b>Conditional Gradient Methods via Stochastic Path-Integrated Differential Estimator</b><br><i>Alp Yurtsever (EPFL) &middot; Suvrit Sra (MIT) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>Learning-to-Learn Stochastic Gradient Descent with Biased Regularization</b><br><i>Giulia Denevi (IIT) &middot; Carlo Ciliberto () &middot; Riccardo Grazzi (Istituto Italiano di Tecnologia) &middot; Massimiliano Pontil (University College London)</i></p>
      <p><b>Power k-Means Clustering</b><br><i>Jason Xu (Duke University) &middot; Kenneth Lange (UCLA)</i></p>
      <p><b>Variational Russian Roulette for Deep Bayesian Nonparametrics</b><br><i>Kai Xu (University of Edinburgh) &middot; Akash Srivastava (MIT-IBM, University Of Edinburgh) &middot; Charles Sutton (Google)</i></p>
      <p><b>Parameter-Efficient Transfer Learning for NLP</b><br><i>Neil Houlsby (Google) &middot; Andrei Giurgiu (Google) &middot; Stanislaw Jastrzebski (Jagiellonian University) &middot; Bruna Morrone (Google) &middot; Quentin de Laroussilhe (Google Brain) &middot; Andrea Gesmundo (Google) &middot; Mona Attariyan (Google) &middot; Sylvain Gelly (Google Brain)</i></p>
      <p><b>Graph Resistance and Learning from Pairwise Comparisons</b><br><i>Julien Hendrickx (University of Catholique de Louvain) &middot; Alexander Olshevsky () &middot; Venkatesh Saligrama (Boston University)</i></p>
      <p><b>GMNN: Graph Markov Neural Networks</b><br><i>Meng Qu (MILA) &middot; Yoshua Bengio (Mila / U. Montreal) &middot; Jian Tang (HEC Montreal & MILA)</i></p>
      <p><b>PAC Learnability of Node Functions in Networked Dynamical Systems</b><br><i>Abhijin Adiga (University of Virginia) &middot; Chris J Kuhlman (Biocomplexity Institute & Initiative, University of Virginia) &middot; Madhav Marathe (Biocomplexity Institute & Initiative, University of Virginia) &middot; S. S. Ravi (University of Virginia and University at Albany -- SUNY) &middot; Anil  Vullikanti (Biocomplexity Institute and Dept of Computer Science, University of Virginia)</i></p>
      <p><b>Variational Implicit Processes</b><br><i>Chao Ma (University of Cambridge) &middot; Yingzhen Li (Microsoft Research Cambridge) &middot; Jose Hernandez-Lobato (University of Cambridge)</i></p>
      <p><b>Wasserstein of Wasserstein Loss for Learning Generative Models</b><br><i>Yonatan Dukler (UCLA) &middot; Wuchen Li (UCLA) &middot; Alex Lin (University of California, Los Angeles) &middot; Guido Montufar (UCLA)</i></p>
      <p><b>Adaptive Antithetic Sampling for Variance Reduction</b><br><i>Hongyu Ren (Stanford University) &middot; Shengjia Zhao (Stanford University) &middot; Stefano Ermon (Stanford University)</i></p>
      <p><b>Random Shuffling Beats SGD after Finite Epochs</b><br><i>Jeff HaoChen (Tsinghua University) &middot; Suvrit Sra (MIT)</i></p>
      <p><b>Feature Grouping as a Stochastic Regularizer for High-Dimensional Structured Data</b><br><i>Sergul Aydore (Stevens Institute of Technology) &middot; Thirion Bertrand (inria) &middot; Gael Varoquaux (Inria)</i></p>
      <p><b>Estimating Information Flow in Deep Neural Networks</b><br><i>Ziv Goldfeld (MIT) &middot; Ewout van den Berg (IBM) &middot; Kristjan Greenewald (IBM) &middot; Igor Melnyk (IBM) &middot; Nam Nguyen (IBM Research AI) &middot; Brian Kingsbury (IBM Research) &middot; Yury Polyanskiy (MIT)</i></p>
      <p><b>A Conditional Gradient-Based Augmented Lagrangian Framework</b><br><i>Alp Yurtsever (EPFL) &middot; Olivier Fercoq (Télécom ParisTech, Université Paris-Saclay) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>Fairness-Aware Learning for Continuous Attributes and Treatments</b><br><i>Jeremie Mary (CRITEO) &middot; Clément Calauzènes (Criteo Research) &middot; Noureddine El Karoui (Criteo AI Lab and UC, Berkeley)</i></p>
      <p><b>Scalable Metropolis--Hastings for Exact Bayesian Inference with Large Datasets</b><br><i>Rob Cornish (Oxford) &middot; Paul Vanetti (Oxford) &middot; Alexandre Bouchard-Côté (UBC) &middot; George Deligiannidis (Oxford) &middot; Arnaud Doucet (Oxford University)</i></p>
      <p><b>Voronoi Classification: A High-Dimensional Geometric Approach via Weighted Monte Carlo Integration over Voronoi Boundaries</b><br><i>Vladislav Polianskii (KTH Royal Institute of Technology) &middot; Florian Pokorny (KTH Royal Institute of Technology)</i></p>
      <p><b>Geometric Losses for Distributional Learning</b><br><i>Arthur Mensch (ENS) &middot; Mathieu Blondel (NTT) &middot; Gabriel Peyré (CNRS and ENS)</i></p>
      <p><b>Overcoming Mean-Field Approximations in Recurrent Gaussian Process Models</b><br><i>Alessandro Davide Ialongo (University of Cambirdge; Max Planck Tübingen) &middot; Mark van der Wilk (PROWLER.io) &middot; James Hensman (PROWLER.io) &middot; Carl E Rasmussen (Cambridge University)</i></p>
      <p><b>Moment-Based Variational Inference for Markov Jump Processes</b><br><i>Christian Wildner (TU Darmstadt) &middot; Heinz Koeppl (TU Darmstadt)</i></p>
      <p><b>Task-Agnostic Dynamics Priors for Deep Reinforcement Learning</b><br><i>Yilun Du (MIT) &middot; Karthik Narasimhan (Princeton)</i></p>
      <p><b>Hessian Aided Policy Gradient</b><br><i>Zebang Shen (Zhejiang University) &middot; Alejandro Ribeiro (University of Pennsylvania) &middot; Hamed Hassani (University of Pennsylvania) &middot; Hui Qian (Zhejiang University) &middot; Chao Mi (Zhejiang University)</i></p>
      <p><b>PA-GD: On the Convergence of Perturbed Alternating Gradient Descent to Second-Order Stationary Points for Structured Nonconvex Optimization</b><br><i>Songtao Lu (University of Minnesota Twin Cities) &middot; Mingyi Hong (University of Minnesota) &middot; Zhengdao Wang (Iowa State University)</i></p>
      <p><b>TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing</b><br><i>Augustus Odena (Google Brain) &middot; Catherine Olsson (Open Philanthropy Project) &middot; David Andersen (Google) &middot; Ian Goodfellow (Google Brain)</i></p>
      <p><b>MIWAE: Deep Generative Modelling and Imputation of Incomplete Data Sets</b><br><i>Pierre-Alexandre Mattei (IT University Copenhagen) &middot; Jes Frellsen (IT University of Copenhagen)</i></p>
      <p><b>Combating Label Noise in Deep Learning using Abstention</b><br><i>Sunil Thulasidasan (Los Alamos National Laboratory & University of Washington) &middot; Tanmoy Bhattacharya (Los Alamos National Laboratory) &middot; Jeff Bilmes (UW) &middot; Gopinath Chennupati (Los Alamos National Laboratory) &middot; Jamal Mohd-Yusof (Los Alamos National Laboratory)</i></p>
      <p><b>Optimal Mini-Batch and Step Sizes for SAGA</b><br><i>Nidham Gazagnadou (Télécom ParisTech) &middot; Robert Gower (Telecom ParisTech) &middot; Joseph Salmon (Université de Montpellier)</i></p>
      <p><b>Efficient learning of smooth probability functions from Bernoulli tests with guarantees</b><br><i>Paul Rolland (Ecole Polytechnique Fédérale de Lausanne) &middot; Ali Kavis (EPFL) &middot; Alexander Niklaus Immer (RIKEN) &middot; Adish Singla (Max Planck Institute (MPI-SWS)) &middot; Volkan Cevher (EPFL)</i></p>
      <p><b>Scale-free adaptive planning for deterministic dynamics with discounted rewards</b><br><i>Peter Bartlett (UC Berkeley) &middot; Victor Gabillon (Huawei) &middot; Jennifer A Healey (Adobe) &middot; Michal Valko (DeepMind)</i></p>
      <p><b>Deep Residual Output Layers for Neural Language Generation</b><br><i>Nikolaos Pappas (Idiap Research Institute) &middot; James Henderson (IDIAP)</i></p>
      <p><b>A Large-Scale Study on Regularization and Normalization in GANs</b><br><i>Karol Kurach (Google Brain (Zurich)) &middot; Mario Lucic (Google Brain) &middot; Xiaohua Zhai (Google Research, Brain Team) &middot; Marcin Michalski (Google Brain) &middot; Sylvain Gelly (Google Brain)</i></p>
      <p><b>Anytime Online-to-Batch, Optimism and Acceleration</b><br><i>Ashok Cutkosky (Google)</i></p>
      <p><b>Policy Consolidation for Continual Reinforcement Learning</b><br><i>Christos Kaplanis (Imperial College London) &middot; Murray Shanahan (DeepMind / Imperial College London) &middot; Claudia Clopath (Imperial College London)</i></p>
      <p><b>Incorporating Grouping Information into Bayesian Decision Tree Ensembles</b><br><i>JUNLIANG DU (Florida State University) &middot; Antonio Linero (Florida State University)</i></p>
      <p><b>Scalable Nonparametric Sampling from Multimodal Posteriors with the Posterior Bootstrap</b><br><i>Edwin Fong (University of Oxford) &middot; Simon Lyddon (University of Oxford) &middot; Christopher Holmes (University of Oxford)</i></p>
      <p><b>Online Learning with Sleeping Experts and Feedback Graphs</b><br><i>Corinna Cortes (Google Research) &middot; Giulia DeSalvo (Google Research) &middot; Claudio Gentile (INRIA and Google) &middot; Mehryar Mohri (Courant Institute and Google Research) &middot; Scott Yang (D. E. Shaw & Co.)</i></p>
      <p><b>Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation</b><br><i>Ahsan Alvi (University of Oxford) &middot; Binxin Ru (University of Oxford) &middot; Jan-Peter Calliess (University of Oxford) &middot; Stephen Roberts (University of Oxford) &middot; Michael A Osborne (U Oxford)</i></p>
      <p><b>Faster Algorithms for Boolean Matrix Factorization</b><br><i>Ravi Kumar (Google) &middot; Rina Panigrahy (Google) &middot; Ali Rahimi (Google) &middot; David Woodruff (Carnegie Mellon University)</i></p>
      <p><b>Decomposing feature-level variation with Covariate Gaussian Process Latent Variable Models</b><br><i>Kaspar Märtens (University of Oxford) &middot; Kieran Campbell (University of British Columbia) &middot; Christopher Yau (University of Birmingham)</i></p>
      <p><b>SGD with Arbitrary Sampling:  General Analysis and Improved Rates</b><br><i>Xun Qian (KAUST) &middot; Peter Richtarik (KAUST) &middot; Robert M. Gower (Telecom Paristech) &middot; Alibek Sailanbayev (King Abdullah University of Science and Technology) &middot; Nicolas Loizou (The University of Edinburgh) &middot; Egor Shulgin (Moscow Institute of Physics and Technology)</i></p>
      <p><b>Game Theoretic Optimization via Gradient-based Nikaido-Isoda Function</b><br><i>Arvind Raghunathan (Mitsubishi Electric Research Laboratories) &middot; Anoop Cherian (MERL) &middot; Devesh Jha (Mitsubishi Electric Research Labs)</i></p>
      <p><b>Curvature-Exploiting Acceleration of Elastic Net Computations</b><br><i>Vien Van Mai (KTH Royal Institute of Technology) &middot; Mikael Johansson (KTH Royal Institute of Technology)</i></p>
      <p><b>Error Feedback Fixes SignSGD and other Gradient Compression Schemes</b><br><i>Sai Praneeth Reddy Karimireddy (EPFL) &middot; Quentin Rebjock (EPFL) &middot; Sebastian Stich (EPFL) &middot; Martin Jaggi (EPFL)</i></p>
      <p><b>Submodular Maximization beyond Non-negativity: Guarantees, Fast Algorithms, and Applications</b><br><i>Christopher Harshaw (Yale University) &middot; Moran Feldman (The Open University of Israel) &middot; Justin Ward () &middot; Amin Karbasi (Yale)</i></p>
      <p><b>Shape Constraints for Set Functions</b><br><i>Andrew Cotter (Google AI) &middot; Maya Gupta (Google) &middot; Heinrich Jiang (Google Research) &middot; Erez Louidor (Google, Inc.) &middot; James Muller (Google) &middot; Tamann Narayan (Google) &middot; Serena Wang (Google) &middot; Tao Zhu (Google)</i></p>
      <p><b>Open-ended learning in zero-sum games</b><br><i>David Balduzzi (DeepMind) &middot; Marta Garnelo (DeepMind) &middot; Yoram Bachrach () &middot; Wojciech Czarnecki (DeepMind) &middot; Julien Perolat (DeepMind) &middot; Max Jaderberg (DeepMind) &middot; Thore Graepel (DeepMind)</i></p>
      <p><b>Information-Theoretic Considerations in Batch Reinforcement Learning</b><br><i>Jinglin Chen (University of Illinois at Urbana-Champaign) &middot; Nan Jiang (University of Illinois at Urbana-Champaign)</i></p>
      <p><b>Sparse Multi-Channel Variational Autoencoder for the Joint Analysis of Heterogeneous Data</b><br><i>Luigi Antelmi (INRIA) &middot; Nicholas Ayache (INRIA) &middot; Philippe Robert (CMMR Nice) &middot; Marco Lorenzi (Inria Sophia Antipolis)</i></p>
      <p><b>kernelPSI: a Post-Selection Inference Framework for Nonlinear Variable Selection</b><br><i>Lotfi Slim (Mines ParisTech (ARMINES)) &middot; Clément Chatelain (Sanofi R&D) &middot; Chloe-Agathe Azencott (MINES ParisTech) &middot; Jean-Philippe Vert (Google)</i></p>
      <p><b>Learning with Bad Training Data via Iterative Trimmed Loss Minimization</b><br><i>Yanyao Shen (UT Austin) &middot; Sujay Sanghavi (UT Austin)</i></p>
      <p><b>ARSM: Augment-REINFORCE-Swap-Merge Estimator for Gradient Backpropagation Through Categorical Variables</b><br><i>Mingzhang Yin (University of Texas at Austin) &middot; Yuguang Yue (University of Texas at Austin) &middot; Mingyuan Zhou (University of Texas at Austin)</i></p>
      <p><b>Importance Sampling Policy Evaluation with an Estimated Behavior Policy</b><br><i>Josiah Hanna (UT Austin) &middot; Scott Niekum (University of Texas at Austin) &middot; Peter Stone (University of Texas at Austin)</i></p>
      <p><b>Lower Bounds for Smooth Nonconvex Finite-Sum Optimization</b><br><i>Dongruo Zhou (UCLA) &middot; Quanquan Gu (University of California, Los Angeles)</i></p>
      <p><b>Robust Decision Trees Against Adversarial Examples</b><br><i>Hongge Chen (MIT) &middot; Huan Zhang (UCLA) &middot; Duane Boning (MIT) &middot; Cho-Jui Hsieh (UCLA)</i></p>
      <p><b>Revisiting the Softmax Bellman Operator: New Benefits and New Perspective</b><br><i>Zhao Song (Baidu Research) &middot; Ron Parr (Duke University) &middot; Lawrence Carin (Duke University)</i></p>
      <p><b>Active learning for decision-making from imbalanced observational data</b><br><i>Iiris Sundin (Aalto University) &middot; Peter Schulam (Johns Hopkins University) &middot; Eero Siivola (Aalto University) &middot; Aki Vehtari (Aalto University) &middot; Suchi Saria (Johns Hopkins University) &middot; Samuel Kaski (Aalto University)</i></p>
      <p><b>Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds</b><br><i>Andrea Zanette (Stanford University) &middot; Emma Brunskill (Stanford University)</i></p>
      <p><b>On Dropout and Nuclear Norm Regularization</b><br><i>Poorya Mianjy (Johns Hopkins University) &middot; Raman Arora (Johns Hopkins University)</i></p>
      <p><b>Contextual Memory Trees</b><br><i>Wen Sun (Carnegie Mellon University) &middot; Alina Beygelzimer (Yahoo Research) &middot; Hal Daume (Microsoft Research) &middot; John Langford (Microsoft Research) &middot; Paul Mineiro (Microsoft)</i></p>
      <p><b>DeepNose: Using artificial neural networks to represent the space of odorants</b><br><i>Ngoc Tran (Cold Spring Harbor Laboratory) &middot; Daniel Kepple (Cold Spring Harbor Laboratory) &middot; Sergey Shuvaev (Cold Spring Harbor Laboratory) &middot; Alexei Koulakov (Cold Spring Harbor Laboratory)</i></p>
      <p><b>On the Connection Between Adversarial Robustness and Saliency Map Interpretability</b><br><i>Christian Etmann (University of Bremen) &middot; Sebastian Lunz (University of Cambridge) &middot; Peter Maass (University of Bremen) &middot; Carola-Bibiane Schönlieb (University of Cambridge)</i></p>
      <p><b>Unreproducible research is reproducible</b><br><i>Xavier Bouthillier (MILA - Université de Montréal) &middot; César Laurent (MILA) &middot; Pascal Vincent (U Montreal)</i></p>
      <p><b>Open Vocabulary Learning on Source Code with a Graph-Structured Cache</b><br><i>Milan Cvitkovic (California Institute of Technology) &middot; Badal Singh (Amazon Web Services) &middot; Anima Anandkumar (Caltech)</i></p>
      <p><b>Making Convolutional Networks Shift-Invariant Again</b><br><i>Richard Zhang (Adobe)</i></p>
      <p><b>Plug-and-Play Methods Provably Converge with Properly Trained Denoisers</b><br><i>Ernest Ryu (University of California, Los Angeles) &middot; Jialin Liu (University of California, Los Angeles (UCLA)) &middot; Sicheng Wang (TAMU) &middot; Xiaohan Chen (Texas A&M University) &middot; Zhangyang Wang (Texas A&M University) &middot; Wotao Yin (UCLA)</i></p>
      <p><b>Screening rules for Lasso with  non-convex sparse regularizers</b><br><i>alain rakotomamonjy (Universite de Rouen Normandie / Criteo AI Lab) &middot; Gilles Gasso (INSA Rouen) &middot; Joseph Salmon (Université de Montpellier)</i></p>
      <p><b>Taming MAML: Control variates for unbiased meta-reinforcement learning gradient estimation</b><br><i>Hao Liu (Salesforce) &middot; Richard Socher (Salesforce) &middot; Caiming Xiong (Salesforce)</i></p>
      <p><b>Blended Conditional Gradients: the Unconditioning of Conditional Gradients</b><br><i>Gábor Braun (Georgia Institute of Technology) &middot; Sebastian Pokutta (Georgia Tech) &middot; Dan Tu (GEORGIA TECH) &middot; Stephen Wright (University of Wisconsin-Madison)</i></p>
      <p><b>Distributed Learning over Unreliable Networks</b><br><i>Chen Yu (University of Rochester) &middot; Hanlin Tang (University of Rochester) &middot; Cedric Renggli (ETH Zurich) &middot; Simon Kassing (ETH Zurich) &middot; Ankit Singla (ETH Zurich) &middot; Dan Alistarh (IST Austria & ETH Zurich) &middot; Ce Zhang (ETH Zurich) &middot; Ji Liu (Kwai Seattle AI lab, University of Rochester)</i></p>
      <p><b>Similarity of Neural Network Representations Revisited</b><br><i>Simon Kornblith (Google Brain) &middot; Mohammad Norouzi (Google Brain) &middot; Honglak Lee (Google / U. Michigan) &middot; Geoffrey Hinton (Google)</i></p>
      <p><b>Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations</b><br><i>Daniel Brown (University of Texas at Austin) &middot; Wonjoon Goo (University of Texas at Austin) &middot; Prabhat  Nagarajan (Preferred Networks) &middot; Scott Niekum (University of Texas at Austin)</i></p>
      <p><b>A Block Coordinate Descent Proximal Method for Simultaneous Filtering and Parameter Estimation</b><br><i>Ramin Raziperchikolaei (UC MErced) &middot; Harish Bhat (University of California, Merced)</i></p>
      <p><b>Meta Particle Flow for Sequential Bayesian Inference</b><br><i>Xinshi Chen (Georgia Institution of Technology) &middot; Hanjun Dai (Georgia Tech) &middot; Le Song (Georgia Institute of Technology)</i></p>
      <p><b>Minimal Achievable Sufficient Statistic Learning</b><br><i>Milan Cvitkovic (California Institute of Technology) &middot; Günther Koliander (Austrian Academy of Sciences)</i></p>
      <p><b>Active Learning with Disagreement Graphs</b><br><i>Corinna Cortes (Google Research) &middot; Giulia DeSalvo (Google Research) &middot; Mehryar Mohri (Courant Institute and Google Research) &middot; Ningshan Zhang (New York University) &middot; Claudio Gentile (INRIA and Google)</i></p>
      <p><b>$\texttt{DoubleSqueeze}$: Parallel Stochastic Gradient Descent with Double-pass Error-Compensated Compression</b><br><i>Hanlin Tang (University of Rochester) &middot; Chen Yu (University of Rochester) &middot; Xiangru Lian (University of Rochester) &middot; Tong Zhang (Tecent AI Lab) &middot; Ji Liu (Kwai Seattle AI lab, University of Rochester)</i></p>
      <p><b>Learning to Clear the Market</b><br><i>Weiran Shen (Tsinghua University) &middot; Sébastien Lahaie (Google) &middot; Renato Leme (Google Research)</i></p>
      <p><b> Fault Tolerance in Iterative-Convergent Machine Learning</b><br><i>Aurick Qiao (Petuum, Inc. and Carnegie Mellon University) &middot; Bryon Aragam (Carnegie Mellon University) &middot; Bingjing Zhang (Petuum, Inc.) &middot; Eric Xing (Petuum Inc.)</i></p>
      <p><b>Distributed Weighted Matching via Randomized Composable Coresets</b><br><i>Sepehr Assadi (Princeton University) &middot; Mohammad Hossein Bateni (Google Research) &middot; Vahab Mirrokni (Google Research)</i></p>
      <p><b>Online Meta-Learning</b><br><i>Chelsea Finn (Stanford, Google, UC Berkeley) &middot; Aravind Rajeswaran (University of Washington) &middot; Sham Kakade (University of Washington) &middot; Sergey Levine (Berkeley)</i></p>
      <p><b>Adaptive scale-invariant online algorithms for learning linear models</b><br><i>Michal Kempka (Poznan University of Technology) &middot; Wojciech Kotlowski (Poznan University of Technology) &middot; Manfred K. Warmuth (UC Santa Cruz & Google Inc.)</i></p>
      <p><b>Learning Discrete Structures for Graph Neural Networks</b><br><i>Luca Franceschi (Istituto Italiano di Tecnologia - University College London) &middot; Mathias Niepert (NEC Laboratories Europe) &middot; Massimiliano Pontil (Istituto Italiano di Tecnologia and University College London) &middot; Xiao He (NEC Laboratories Europe)</i></p>
      <p><b>Making Decisions that Reduce Discriminatory Impacts</b><br><i>Matt J. Kusner (The Alan Turing Institute) &middot; Chris Russell (The Alan Turing Institute/University of Surrey) &middot; Joshua Loftus (New York University) &middot; Ricardo Silva (University College London)</i></p>
      <p><b>Actor-Attention-Critic for Multi-Agent Reinforcement Learning</b><br><i>Shariq Iqbal (University of Southern California) &middot; Fei Sha (University of Southern California)</i></p>
      <p><b>Noise2Self: Blind Denoising by Self-Supervision</b><br><i>Joshua Batson (Chan Zuckerberg Biohub) &middot; Loic Royer (Chan Zuckerberg Biohub)</i></p>
      <p><b>Iterative Linearized Control: Stable Algorithms and Complexity Guarantees</b><br><i>Vincent Roulet (University of Washington) &middot; Dmitriy Drusvyatskiy (University of Washington) &middot; Siddhartha Srinivasa (University of Washington) &middot; Zaid Harchaoui (University of Washington)</i></p>
      <p><b>Generative Adversarial User Model for Reinforcement Learning Based Recommendation System</b><br><i>Xinshi Chen (Georgia Institution of Technology) &middot; Shuang Li (Georgia Tech) &middot; Hui Li (Ant Financial) &middot; Shaohua Jiang (Ant Financial) &middot; Yuan Qi (Ant Financial Services Group) &middot; Le Song (Georgia Institute of Technology)</i></p>
      <p><b>Trajectory-Based Off-Policy Deep Reinforcement Learning</b><br><i>Andreas Doerr (Bosch Center for Artificial Intelligence, Max Planck Institute for Intelligent Systems) &middot; Michael Volpp (Bosch Center for AI) &middot; Marc Toussaint (University Stuttgart) &middot; Sebastian Trimpe (Max Planck Institute for Intelligent Systems) &middot; Christian Daniel (Bosch Center for Artificial Intelligence)</i></p>
      <p><b>ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation</b><br><i>Yuzhe Yang (MIT) &middot; GUO ZHANG (MIT) &middot; Zhi Xu (MIT) &middot; Dina Katabi (MIT)</i></p>
      <p><b>Characterizing Well-behaved vs. Pathological Deep Neural Networks</b><br><i>Antoine Labatie (Labatie-AI)</i></p>
      <p><b>On the Generalization Gap in Reparameterizable Reinforcement Learning</b><br><i>Huan Wang (Salesforce Research) &middot; Stephan Zheng (Salesforce Research) &middot; Caiming Xiong (Salesforce) &middot; Richard Socher (Salesforce)</i></p>
      <p><b>Geometry and Symmetry in Short-and-Sparse Deconvolution</b><br><i>Han-Wen Kuo (Columbia University) &middot; Yenson Lau (Columbia University) &middot; Yuqian Zhang (Columbia University) &middot; John Wright (Columbia University, USA)</i></p>
      <p><b>CAB: Continuous Adaptive Blending for Policy Evaluation and Learning</b><br><i>Yi Su (Cornell University) &middot; Lequn Wang (Cornell University) &middot; Michele Santacatterina (TRIPODS Center of Data Science - Cornell University) &middot; Thorsten Joachims (Cornell)</i></p>
      <p><b>Exploring interpretable LSTM neural networks over multi-variable data</b><br><i>Tian Guo (ETH Zurich) &middot; Tao LIN (EPFL) &middot; Nino Antulov-Fantulin (ETHZ)</i></p>
      <p><b>Cautious Regret Minimization: Online Optimization with Long-Term Budget Constraints</b><br><i>Nikolaos Liakopoulos (Huawei Paris Research Center) &middot; Apostolos Destounis (Mathematical and Algorithmic Sciences Lab,  France Research Center, Huawei Technologies Co. Ltd.) &middot; Georgios Paschos (Huawei ) &middot; Thrasyvoulos Spyropoulos (EURECOM) &middot; Panayotis Mertikopoulos (CNRS)</i></p>
      <p><b>Accelerated Linear Convergence of Stochastic Momentum Methods in Wasserstein Distances</b><br><i>Bugra Can (Rutgers University) &middot; Mert Gurbuzbalaban (Rutgers University) &middot; Lingjiong  Zhu (Florida State University)</i></p>
      <p><b>Active embedding search via noisy paired comparisons</b><br><i>Gregory H Canal (Georgia Institute of Technology) &middot; Andy Massimino (Gatech) &middot; Mark Davenport (Georgia Institute of Technology) &middot; Christopher Rozell (Georgia Institute of Technology)</i></p>
      <p><b>GOODE: A Gaussian Off-The-Shelf Ordinary Differential Equation Solver</b><br><i>David John (Corporate Research, Robert Bosch GmbH) &middot; Vincent Heuveline (University Heidelberg) &middot; Michael Schober (Bosch Center for Artificial Intelligence)</i></p>
      <p><b>AutoVC:  Zero-Shot Voice Style Transfer with Only Autoencoder Loss</b><br><i>Kaizhi Qian (UIUC) &middot; Yang Zhang (IBM-MIT Research Lab) &middot; Shiyu Chang (MIT-IBM Watson AI Lab) &middot; Xuesong Yang (University of Illinois at Urbana-Champaign) &middot; Mark Hasegawa-Johnson (University of Illinois)</i></p>
      <p><b>Dynamic Measurement Scheduling for Event Forecasting using Deep RL</b><br><i>Chun-Hao Chang (University of Toronto) &middot; Mingjie Mai (University of Toronto) &middot; Anna Goldenberg (University of Toronto)</i></p>
      <p><b>A Framework for Bayesian Optimization in Embedded Subspaces</b><br><i>Amin Nayebi (University of Arizona) &middot; Alexander Munteanu (TU Dortmund) &middot; Matthias Poloczek (Uber AI Labs & The University of Arizona)</i></p>
      <p><b>Concrete Autoencoders for Differentiable Feature Selection and Reconstruction</b><br><i>Muhammed Fatih Balın (Bogazici ) &middot; Abubakar Abid (Stanford) &middot; James Zou (Stanford University)</i></p>
      <p><b>On the design of estimators for bandit off-policy evaluation</b><br><i>Nikos Vlassis (Netflix) &middot; Aurelien Bibaut (UC Berkeley) &middot; Maria Dimakopoulou (Stanford) &middot; Tony Jebara (Netflix)</i></p>
      <p><b>A Multitask Multiple Kernel Learning Algorithm for Survival Analysis with Application to Cancer Biology</b><br><i>Onur Dereli (Koç University) &middot; Ceyda  Oğuz (Koç University) &middot; Mehmet Gönen (Koç University)</i></p>
      <p><b>Bounding User Contributions: A Bias-Variance Trade-off in Differential Privacy</b><br><i>Kareem Amin (Google Research) &middot; Alex Kulesza (Google) &middot; andres munoz (Google) &middot; Sergei Vassilvitskii (Google)</i></p>
      <p><b>Insertion Transformer: Flexible Sequence Generation via Insertion Operations</b><br><i>Mitchell Stern (UC Berkeley) &middot; William Chan (Google Brain) &middot; Jamie Kiros (Google Inc.) &middot; Jakob Uszkoreit (Google, Inc.)</i></p>
      <p><b>Online learning with kernel losses</b><br><i>Niladri S Chatterji (UC Berkeley) &middot; Aldo Pacchiano (UC Berkeley) &middot; Peter Bartlett (UC Berkeley)</i></p>
      <p><b>The Implicit Fairness Criterion of Unconstrained Learning</b><br><i>Lydia T. Liu (University of California Berkeley) &middot; Max Simchowitz (UC Berkeley) &middot; University of California Moritz Hardt (University of California, Berkeley)</i></p>
      <p><b>Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Training</b><br><i>Mor Shpigel Nacson (Technion) &middot; Suriya Gunasekar (Toyota Technological Institute at Chicago) &middot; Jason Lee (University of Southern California) &middot; Nati Srebro (Toyota Technological Institute at Chicago) &middot; Daniel Soudry (Technion)</i></p>
      <p><b>Generalized No Free Lunch Theorem for Adversarial Robustness</b><br><i>Elvis Dohmatob (Criteo Research)</i></p>
      <p><b>On the Spectral Bias of Neural Networks</b><br><i>Nasim Rahaman (University of Heidelberg) &middot; Aristide Baratin (MILA) &middot; Devansh Arpit (Montréal Institute for Learning Algorithms, Canada) &middot; Felix Draxler (Heidelberg University) &middot; Min Lin (University of Montreal) &middot; Fred Hamprecht (Heidelberg Collaboratory for Image Processing) &middot; Yoshua Bengio (Mila / U. Montreal) &middot; Aaron Courville (University of Montreal)</i></p>
      <p><b>Separable value functions across time-scales</b><br><i>Joshua Romoff (McGill University) &middot; Peter Henderson (Stanford University) &middot; Ahmed Touati (MILA / FAIR) &middot; Yann Ollivier (Facebook Artificial Intelligence Research) &middot; Joelle Pineau (McGill University / Facebook) &middot; Emma Brunskill (Stanford University)</i></p>
      <p><b>Proportionally Fair Clustering</b><br><i>Xingyu Chen (Duke University) &middot; Brandon Fain (Duke University) &middot; Liang Lyu (Duke University) &middot; Kamesh Munagala (Duke University)</i></p>
      <p><b>Wasserstein Adversarial Examples via Projected Sinkhorn Iterations</b><br><i>Eric Wong (Carnegie Mellon University) &middot; Frank Schmidt (Robert Bosch GmbH) &middot; Zico Kolter (Carnegie Mellon University / Bosch Center for AI)</i></p>
      <p><b>Katalyst: Boosting Convex Katayusha for  Non-Convex Problems with a  Large Condition Number</b><br><i>Zaiyi Chen (Cainiao AI) &middot; Yi Xu (The University of Iowa) &middot; Haoyuan Hu (Artificial Intelligence Department, Zhejiang Cainiao Supply Chain Management Co.) &middot; Tianbao Yang (The University of Iowa)</i></p>
      <p><b>BayesNAS: A Bayesian Approach for Neural Architecture Search</b><br><i>Hongpeng Zhou (Delft University of Technology) &middot; Minghao Yang (TUDelft) &middot; Jun Wang (UCL) &middot; Wei Pan (TUDelft)</i></p>
      <p><b>Rehashing Kernel Evaluation in High Dimensions</b><br><i>Paris Siminelakis (Stanford University) &middot; Kexin Rong (Stanford University) &middot; Peter Bailis (Stanford University) &middot; Moses Charikar (Stanford University) &middot; Philip Levis (Stanford University)</i></p>
      <p><b>Acceleration of SVRG and Katyusha X by Inexact Preconditioning</b><br><i>Yanli Liu (UCLA math) &middot; Fei Feng (UCLA) &middot; Wotao Yin (UCLA)</i></p>
      <p><b>Learning to Explore via Disagreement</b><br><i>Deepak Pathak (UC Berkeley) &middot; Dhiraj Gandhi (Carnegie Mellon University Robotics Institute) &middot; Abhinav Gupta (Carnegie Mellon University)</i></p>
      <p><b>Towards a Unified Analysis of Random Fourier Features</b><br><i>Zhu Li (University of Oxford) &middot; Jean-Francois Ton (University of Oxford) &middot; Dino Oglic (King's College London) &middot; Dino Sejdinovic (University of Oxford)</i></p>
      <p><b>Adversarially Learned Representations for Information Obfuscation and Inference</b><br><i>Martin A Bertran (Duke University) &middot; Natalia Martinez (Duke University) &middot; Afroditi Papadaki (University College London) &middot; Qiang Qiu (Duke University) &middot; Miguel Rodrigues (University College London) &middot; Galen Reeves (Duke) &middot; Guillermo Sapiro (Duke University)</i></p>
      <p><b>Using Pre-Training Can Improve Model Robustness and Uncertainty</b><br><i>Dan Hendrycks (UC Berkeley) &middot; Kimin Lee (KAIST) &middot; Mantas Mazeika (University of Chicago)</i></p>
      <p><b>Discovering Conditionally Salient Features with Statistical Guarantees</b><br><i>Jaime Roquero Gimenez (Stanford University) &middot; James Zou (Stanford University)</i></p>
      <p><b>Active Manifolds: A non-linear analogue to Active Subspaces</b><br><i>Robert A Bridges (Oak Ridge National Laboratory) &middot; Anthony Gruber (Texas Tech University) &middot; Christopher Felder (Washington University in St. Louis) &middot; Miki Verma (Oak Ridge National Laboratory) &middot; Chelsey Hoff (N/A)</i></p>
      <p><b>Random Walks on Hypergraphs with Edge-Dependent Vertex Weights</b><br><i>Uthsav Chitra (Princeton University) &middot; Benjamin Raphael (Princeton University)</i></p>
      <p><b>A Theoretical Analysis of Contrastive Unsupervised Representation Learning</b><br><i>Nikunj Umesh Saunshi (Princeton University) &middot; Orestis Plevrakis (Princeton University) &middot; Sanjeev Arora ( Princeton University and Institute for Advanced Study) &middot; Mikhail Khodak (CMU) &middot; Hrishikesh Khandeparkar (Princeton University)</i></p>
      <p><b>Fair k-center clustering for data summarization</b><br><i>Matthäus Kleindessner (Rutgers University) &middot; Pranjal Awasthi (Rutgers University) &middot; Jamie Morgenstern (Georgia Institute of Technology)</i></p>
      <p><b>Sensitivity Analysis of Linear Structural Causal Models</b><br><i>Carlos Cinelli (UCLA) &middot; Daniel Kumor (Purdue University) &middot; Bryant Chen (IBM Research AI) &middot; Judea Pearl (UCLA) &middot; Elias Bareinboim (Purdue)</i></p>
      <p><b>Fairwashing: the risk of rationalization</b><br><i>Ulrich AIVODJI (UQAM) &middot; Hiromi Arai (RIKEN AIP) &middot; Olivier Fortineau (Ensta Paristech) &middot; Sébastien Gambs (UQAM) &middot; Satoshi Hara (Osaka University) &middot; Alain Tapp (Université de Montréal)</i></p>
      <p><b>An Optimal Private Stochastic-MAB Algorithm based on Optimal Private Stopping Rule</b><br><i>Touqir Sajed (University of Alberta) &middot; Or Sheffet (University of Alberta)</i></p>
      <p><b>On Connected Sublevel Sets in Deep Learning</b><br><i>Quynh Nguyen (Saarland University)</i></p>
      <p><b>What is the Effect of Importance Weighting in Deep Learning?</b><br><i>Jonathon Byrd (Carnegie Mellon University) &middot; Zachary Lipton (Carnegie Mellon University)</i></p>
      <p><b>Multivariate Submodular Optimization</b><br><i>Richard Santiago (McGill University) &middot; F. Bruce Shepherd (University of British Columbia)</i></p>
      <p><b>Guarantees for Spectral Clustering with Fairness Constraints</b><br><i>Matthäus Kleindessner (Rutgers University) &middot; Samira Samadi (Georgia Tech) &middot; Pranjal Awasthi (Rutgers University) &middot; Jamie Morgenstern (Georgia Institute of Technology)</i></p>
      <p><b>Neurally-Guided Structure Inference</b><br><i>Sidi Lu (Shanghai Jiao Tong University) &middot; Jiayuan Mao (Tsinghua University) &middot; Josh Tenenbaum (MIT) &middot; Jiajun Wu (MIT)</i></p>
      <p><b>More Efficient Policy Value Evaluation through Regularized Targeted Learning</b><br><i>Aurelien Bibaut (UC Berkeley) &middot; Ivana Malenica (UC Berkeley) &middot; Nikos Vlassis (Netflix) &middot; Mark van der Laan (UC Berkeley)</i></p>
      <p><b>AUCµ: A Performance Metric for Multi-Class Machine Learning Models</b><br><i>Ross Kleiman (University of Wisconsin-Madison) &middot; University of Wisconsin David Page (University of Wisconsin, Madison)</i></p>
      <p><b>Diagnosing Bottlenecks in Deep Q-learning Algorithms</b><br><i>Justin Fu (University of California, Berkeley) &middot; Aviral Kumar (University of California Berkeley) &middot; Matthew Soh (UC Berkeley) &middot; Sergey Levine (Berkeley)</i></p>
      <p><b>Flexibly Fair Representation Learning by Disentanglement</b><br><i>Elliot Creager (University of Toronto) &middot; David Madras (University of Toronto) &middot; Joern-Henrik Jacobsen (Vector Institute) &middot; Marissa Weis (University of Tübingen) &middot; Kevin Swersky (Google Brain) &middot; Toniann Pitassi (University of Toronto) &middot; Richard Zemel (Vector Institute)</i></p>
      <p><b>Learning deep kernels for exponential family densities</b><br><i>Li Kevin Wenliang (Gatsby Unit, University College London) &middot; Dougal Sutherland (Gatsby unit, University College London) &middot; Heiko Strathmann (University College London) &middot; Arthur Gretton (Gatsby Computational Neuroscience Unit)</i></p>
      <p><b>Infinite Mixture Prototypes for Few-shot Learning</b><br><i>Kelsey Allen (Massachusetts Institute of Technology) &middot; Evan Shelhamer (UC Berkeley) &middot; Hanul Shin (Massachusetts Institute of Technology) &middot; Josh Tenenbaum (MIT)</i></p>
      <p><b>Supervised Hierarchical Clustering with Exponential Linkage</b><br><i>Nishant  Yadav (University of Massachusetts Amherst) &middot; Ari Kobren (University of Massachusetts Amherst) &middot; Nicholas Monath (University of Massachusetts Amherst) &middot; Andrew McCallum (UMass Amherst)</i></p>
      <p><b>Understanding Priors in Bayesian Neural Networks at the Unit Level</b><br><i>Mariia Vladimirova (Inria) &middot; Jakob Verbeek (INRIA) &middot; Pablo Mesejo (Universidad de Granada) &middot; Julyan Arbel (Inria Grenoble Rhone-Alpes)</i></p>
      <p><b>Functional Transparency for Structured Data: a Game-Theoretic Approach</b><br><i>Guang-He Lee (MIT CSAIL) &middot; Wengong Jin (MIT) &middot; David Alvarez-Melis (MIT) &middot; Tommi Jaakkola (MIT)</i></p>
      <p><b>Loss Landscapes of Regularized Linear Autoencoders</b><br><i>Daniel Kunin (Stanford University) &middot; Jonathan Bloom (Broad Institute) &middot; Aleksandrina Goeva (Broad Institute of MIT and Harvard) &middot; Cotton Seed (Broad Institute of MIT and Harvard)</i></p>
      <p><b>Design by conditioning with adaptive sampling</b><br><i>David Brookes (University of California, Berkeley) &middot; Jennifer Listgarten (University of California, Berkeley)</i></p>
      <p><b>Adversarial camera stickers: A physical camera-based attack on deep learning systems</b><br><i>Juncheng Li (Carnegie Mellon University) &middot; Frank Schmidt (Robert Bosch GmbH) &middot; Zico Kolter (Carnegie Mellon University / Bosch Center for AI)</i></p>
      <p><b>Improved dynamic graph learning through fault-tolerant sparsification</b><br><i>Chunjiang Zhu (University of Connecticut) &middot; Sabine Storandt (University of Wuerzburg) &middot; Kam-Yiu Lam () &middot; Song Han () &middot; Jinbo Bi (University of Connecticut)</i></p>
      <p><b>On Learning Invariant Representation for Domain Adaptation</b><br><i>Han Zhao (Carnegie Mellon University) &middot; Remi Tachet des Combes (Microsoft Research Montreal) &middot; Kun Zhang (Carnegie Mellon University) &middot; Geoff Gordon (Carnegie Mellon University)</i></p>
      <p><b>Concentration Inequalities for Conditional Value at Risk</b><br><i>Philip Thomas (University of Massachusetts Amherst) &middot; Erik Learned-Miller (University of Massachusetts, Amherst)</i></p>
      <p><b>Learning Optimal Fair Policies</b><br><i>Razieh Nabi (Johns Hopkins University) &middot; Daniel Malinsky (Johns Hopkins University) &middot; Ilya Shpitser (Johns Hopkins University)</i></p>
      <p><b>Blackbox Clean-Label Poisoning Attacks on Neural Networks</b><br><i>Chen Zhu (University of Maryland) &middot; Ronny Huang (EY) &middot; Hengduo Li (University of Maryland, College Park) &middot; Gavin Taylor (United States Naval Academy) &middot; Christoph Studer (Cornell University) &middot; Tom Goldstein (University of Maryland)</i></p>
      <p><b>Automatic Posterior Transformation for Likelihood-Free Inference</b><br><i>David Greenberg (Technical University of Munich) &middot; Marcel Nonnenmacher (Technical University of Munich) &middot; Jakob Macke (Technical University of Munich)</i></p>
      <p><b>Formal Privacy for Functional Data with Gaussian Perturbations</b><br><i>Ardalan Mirshani (The Pennsylvania State University) &middot; Matthew Reimherr (Penn State University) &middot; Aleksandra Slavković (Pennsylvania State University)</i></p>
      <p><b>Do ImageNet models generalize to ImageNet?</b><br><i>Benjamin Recht (Berkeley) &middot; Rebecca Roelofs (University of California Berkeley) &middot; Ludwig Schmidt (University of California, Berkeley) &middot; Vaishaal Shankar (UC Berkeley)</i></p>
      <p><b>Variational Annealing of GANs: A Langevin Perspective</b><br><i>Chenyang Tao (Duke University) &middot; Shuyang Dai (Duke University) &middot; Liqun Chen (Duke University) &middot; Ke Bai (Duke University) &middot; Junya Chen (Duke U) &middot; Chang Liu (Tsinghua University) &middot; RUIYI (ROY) ZHANG (Duke University) &middot; Georgiy Bobashev (RTI International) &middot; Lawrence Carin (Duke)</i></p>
      <p><b>Counterfactual Off-Policy Evaluation with Gumbel-Max Structural Causal Models</b><br><i>Michael Oberst (MIT) &middot; David Sontag (Massachusetts Institute of Technology)</i></p>
      <p><b>High-Fidelity Image Generation With Fewer Labels</b><br><i>Mario Lucic (Google Brain) &middot; Michael Tschannen (ETH Zurich) &middot; Marvin Ritter (Google Brain) &middot; Xiaohua Zhai (Google Research, Brain Team) &middot; Olivier Bachem (Google Brain) &middot; Sylvain Gelly (Google Brain)</i></p>
      <p><b>Learning Novel Policies For Tasks</b><br><i>Yunbo Zhang (Georgia Institute of Technology) &middot; Wenhao Yu (Georgia Institute of Technology) &middot; Greg Turk (Georgia Institute of Technology)</i></p>
      <p><b>Finding Options that Minimize Planning Time</b><br><i>Yuu Jinnai (Brown University) &middot; David Abel (Brown University) &middot; David Hershkowitz (Carnegie Mellon University) &middot; Michael L. Littman (Brown University) &middot; George Konidaris (Brown)</i></p>
      <p><b>Categorical Feature Compression via Submodular Optimization</b><br><i>Lin Chen (Yale University) &middot; Mohammad Hossein Bateni (Google Research) &middot; Hossein Esfandiari (Google Research) &middot; Gang Fu (Google LLC) &middot; Vahab Mirrokni (Google Research) &middot; Afshin Rostamizadeh (Google)</i></p>
      <p><b>Rao-Blackwellized Stochastic Gradients for Discrete Distributions</b><br><i>Runjing Liu (UC Berkeley) &middot; Jeffrey Regier (UC Berkeley) &middot; Nilesh Tripuraneni (UC Berkeley) &middot; Michael Jordan (UC Berkeley) &middot; Jon McAuliffe (Voleon Group and University of California at Berkeley)</i></p>
      <p><b>Tensor Variable Elimination for Plated Factor Graphs</b><br><i>Fritz Obermeyer (Uber AI Labs) &middot; Elias Bingham (Uber AI Labs) &middot; Martin Jankowiak (Uber AI Labs) &middot; Neeraj Pradhan (Uber AI Labs) &middot; Justin Chiu (Harvard) &middot; Alexander Rush (Harvard University) &middot; Noah Goodman (Uber AI Labs)</i></p>
      <p><b>Option Discovery for Solving Sparse Reward Reinforcement Learning Problems</b><br><i>Yuu Jinnai (Brown University) &middot; Jee Won Park (Brown University) &middot; David Abel (Brown University) &middot; George Konidaris (Brown)</i></p>
      <p><b>Analyzing and Improving Representations with the Soft Nearest Neighbor Loss</b><br><i>Nicholas Frosst (Google Brain) &middot; Nicolas Papernot () &middot; Geoffrey Hinton (Google)</i></p>
      <p><b>Circuit-GNN: Graph Neural Networks for Distributed Circuit Design</b><br><i>GUO ZHANG (MIT) &middot; Hao He (Massachusetts Institute of Technology) &middot; Dina Katabi (MIT)</i></p>
      <p><b>Semi-Cyclic Stochastic Gradient Descent</b><br><i>Hubert Eichner (Google) &middot; Tomer Koren (Google Brain) &middot; H. Brendan McMahan (Google) &middot; Nati Srebro (Toyota Technological Institute at Chicago) &middot; Kunal Talwar (Google)</i></p>
      <p><b>Adjustment Criteria for Generalizing Experimental Findings</b><br><i>Juan Correa (Purdue University) &middot; Jin Tian (Iowa State University) &middot; Elias Bareinboim (Purdue)</i></p>
      <p><b>Discovering Context Effects from Raw Choice Data</b><br><i>Arjun Seshadri (Stanford University) &middot; Alexander Peysakhovich (Facebook) &middot; Johan Ugander (Stanford University)</i></p>
      <p><b>The Evolved Transformer</b><br><i>David So (Google Brain) &middot; Quoc Le (Google Brain) &middot; Chen Liang (Google Brain)</i></p>
      <p><b>Neuron birth-death dynamics accelerates gradient descent and converges asymptotically</b><br><i>Grant Rotskoff (New York University) &middot; Samy Jelassi (Princeton University) &middot; Joan Bruna (New York University) &middot; Eric Vanden-Eijnden (New York University)</i></p>
      <p><b>Remember and Forget for Experience Replay</b><br><i>Guido Novati (ETH Zurich) &middot; Petros Koumoutsakos (ETH Zurich)</i></p>
      <p><b>Online Algorithms for Rent-Or-Buy with Expert Advice</b><br><i>Sreenivas Gollapudi (Google Research) &middot; Debmalya Panigrahi (Duke University)</i></p>
      <p><b>Trading Redundancy for Communication: Speeding up Distributed SGD for Non-convex Optimization</b><br><i>Farzin Haddadpour (Pennsylvania State University) &middot; Mohammad Mahdi Kamani (The Pennsylvania State University) &middot; Mehrdad Mahdavi (Pennsylvania State University) &middot; Viveck Cadambe (Pennsylvania State University)</i></p>
      <p><b>Data Shapley:  Equitable Valuation of Data for Machine Learning</b><br><i>Amirata Ghorbani (Stanford) &middot; James Zou (Stanford University)</i></p>
      <p><b>Submodular Observation Selection and Information Gathering for Quadratic Models</b><br><i>Abolfazl Hashemi (University of Texas at Austin) &middot; Mahsa Ghasemi (The University of Texas at Austin) &middot; Haris Vikalo (University of Texas at Austin) &middot; Ufuk Topcu (University of Texas at Austin)</i></p>
      <p><b>Latent Normalizing Flows for Discrete Sequences</b><br><i>Zachary Ziegler (Harvard University) &middot; Alexander Rush (Harvard University)</i></p>
      <p><b>A gradual, semi-discrete approach to generative network training via explicit Wasserstein minimization</b><br><i>Yucheng Chen (University of Illinois at Urbana-Champaign) &middot; Matus Telgarsky (UIUC) &middot; Chao Zhang (University of Illinois, Urbana Champaign) &middot; Bolton Bailey (University of Illinois) &middot; Daniel Hsu (Columbia University) &middot; Jian Peng (UIUC)</i></p>
      <p><b>Inference and Sampling of $K_{33}$-free Ising Models</b><br><i>Valerii Likhosherstov (Skolkovo Institute of Science and Technology) &middot; Yury Maximov (LANL) &middot; Michael Chertkov (Los Alamos National Laboratory)</i></p>
      <p><b>Invertible Residual Networks</b><br><i>Jens Behrmann (University of Bremen) &middot; Will Grathwohl (University of Toronto) &middot; Ricky T. Q. Chen (UofT) &middot; David Duvenaud (University of Toronto) &middot; Joern-Henrik Jacobsen (Vector Institute)</i></p>
      <p><b>Classifying Treatment Responders Under Causal Effect Monotonicity</b><br><i>Nathan Kallus (Cornell University)</i></p>
      <p><b>Distribution Reinforcement Learning for Efficient Exploration</b><br><i>Borislav Mavrin (University of Alberta) &middot; Hengshuai Yao (Huawei Technologies) &middot; Linglong Kong (University of Alberta) &middot; Kaiwen Wu (University of Waterloo) &middot; Yaoliang Yu (University of Waterloo)</i></p>
      <p><b>Deep Relational Pooling</b><br><i>Ryan Murphy (Purdue University) &middot; Balasubramaniam Srinivasan (Purdue University) &middot; Vinayak A Rao (Purdue University) &middot; Bruno Ribeiro (Purdue University)</i></p>
      <p><b>On the Statistical Efficiency of Optimal Kernel Sum Classifiers</b><br><i>Raphael A Meyer (Purdue University) &middot; Jean Honorio (Purdue University)</i></p>
      <p><b>Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition</b><br><i>Yao Qin (University of California, San Diego) &middot; Nicholas Carlini (Google) &middot; Garrison Cottrell (University of California, San Diego) &middot; Ian Goodfellow (Google Brain) &middot; Colin Raffel (Google)</i></p>
      <p><b>DAG-GNN: DAG Structure Learning with Graph Neural Networks</b><br><i>Yue Yu (Lehigh University) &middot; Jie Chen (IBM Research) &middot; Tian Gao (IBM Research) &middot; Mo Yu (IBM T. J. Watson)</i></p>
      <p><b>Efficient Full-Matrix Adaptive Regularization</b><br><i>Naman Agarwal (Google AI Princeton) &middot; Brian Bullins (Princeton University) &middot; Xinyi Chen (Google Research) &middot; Elad Hazan (Google Brain and Princeton University) &middot; Karan Singh (Princeton University) &middot; Cyril Zhang (Princeton University) &middot; Yi Zhang (Princeton University)</i></p>
      <p><b>An Investigation into Neural Net Optimization via Hessian Eigenvalue Density</b><br><i>Behrooz Ghorbani (Stanford University) &middot; Shankar Krishnan (Google) &middot; Ying Xiao (Google Inc)</i></p>
      <p><b>Hiring Under Uncertainty</b><br><i>Manish Purohit (Google) &middot; Sreenivas Gollapudi (Google Research) &middot; Manish Raghavan (Cornell)</i></p>
      <p><b>Bit-Swap: Practical Bits Back Coding with Hierarchical Latent Variables</b><br><i>Friso Kingma (UC Berkeley) &middot; Pieter Abbeel (OpenAI / UC Berkeley) &middot; Jonathan Ho (UC Berkeley)</i></p>
      <p><b>Compactifying a network by pruning in the Kronecker-factored eigenbasis</b><br><i>Chaoqi Wang (University of Toronto) &middot; Roger Grosse (University of Toronto and Vector Institute) &middot; Sanja Fidler (University of Toronto, NVIDIA) &middot; Guodong Zhang (University of Toronto)</i></p>
      <p><b>SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning</b><br><i>Marvin Zhang (UC Berkeley) &middot; Sharad Vikram (UCSD) &middot; Laura Smith (UC Berkeley) &middot; Pieter Abbeel (OpenAI / UC Berkeley) &middot; Matthew Johnson (Google Brain) &middot; Sergey Levine (Berkeley)</i></p>
      <p><b>Memory-Optimal Direct Convolutions for Maximizing Classification Accuracy in Embedded Applications</b><br><i>Albert Gural (Stanford University) &middot; Boris Murmann (Stanford University)</i></p>
      <p><b>Tight Kernel Query Complexity of Kernel Ridge Regression and Kernel $k$-means Clustering</b><br><i>Taisuke Yasuda (Carnegie Mellon University) &middot; David Woodruff (Carnegie Mellon University) &middot; Manuel Fernandez (Carnegie Mellon University)</i></p>
      <p><b>Maximum Likelihood Estimation for  Learning Populations of Parameters</b><br><i>Ramya Korlakai Vinayak (University of Washington) &middot; Weihao Kong (Stanford University) &middot; Gregory Valiant (Stanford University) &middot; Sham Kakade (University of Washington)</i></p>
      <p><b>Fair Online Advertising</b><br><i>Anay Mehrotra (Indian Institute of Technology Kanpur) &middot; Elisa Celis (Yale University) &middot; Nisheeth Vishnoi (Yale University)</i></p>
      <p><b>Hybrid Models with Deep and Invertible Features</b><br><i>Eric Nalisnick (UC Irvine) &middot; Akihiro Matsukawa (DeepMind) &middot; Yee Whye Teh (Oxford and DeepMind) &middot; Dilan Gorur () &middot; Balaji Lakshminarayanan (Google DeepMind)</i></p>
      <p><b>Online Control with Adversarial Disturbances</b><br><i>Naman Agarwal (Google AI Princeton) &middot; Brian Bullins (Princeton University) &middot; Elad Hazan (Google Brain and Princeton University) &middot; Sham Kakade (University of Washington) &middot; Karan Singh (Princeton University)</i></p>
      <p><b>Stable and Fair Classification</b><br><i>Lingxiao Huang (EPFL) &middot; Nisheeth Vishnoi (Yale University)</i></p>
      <p><b>On the Feasibility of Learning, Rather than Assuming, Human Biases for Reward Inference</b><br><i>Rohin Shah (UC Berkeley) &middot; Noah Gundotra (University of California, Berkeley) &middot; Pieter Abbeel (OpenAI / UC Berkeley) &middot; EECS Anca Dragan (EECS Department, University of California, Berkeley)</i></p>
      <p><b>Toward Understanding the Importance of Noise in Training Neural Networks</b><br><i>Mo Zhou (Peking University) &middot; Tianyi Liu (Georgia Institute of Technolodgy) &middot; Yan Li (Georgia Tech) &middot; Dachao Lin (Peking University) &middot; Enlu Zhou () &middot; Tuo Zhao (Georgia Institute of Technology)</i></p>
      <p><b>Poission Subsampled R\&#39;enyi Differential Privacy</b><br><i>Yuqing Zhu (University of Santa Barbara) &middot; Yu-Xiang Wang (UC Santa Barbara)</i></p>
      <p><b>LIT: Learned Intermediate Representation Training for Model Compression</b><br><i>Animesh Koratana (Stanford University) &middot; Daniel Kang (Stanford University) &middot; Peter Bailis (Stanford University) &middot; Matei Zaharia (Stanford and Databricks)</i></p>
      <p><b>Mixture Models for Diverse Machine Translation: Tricks of the Trade</b><br><i>Tianxiao Shen (MIT) &middot; Myle Ott (Facebook AI Research) &middot; Michael Auli (Facebook) &middot; Marc'Aurelio Ranzato (Facebook)</i></p>
      <p><b>Subspace Robust Wasserstein Distances</b><br><i>François-Pierre Paty (ENSAE ParisTech) &middot; Marco Cuturi (Google and CREST/ENSAE)</i></p>
      <p><b>The advantages of multiple classes for reducing overfitting from test set reuse</b><br><i>Vitaly Feldman (Google Brain) &middot; Roy Frostig (Google Brain) &middot; Moritz Hardt (Google Brain)</i></p>
      <p><b>Provably Efficient Maximum Entropy Exploration</b><br><i>Elad Hazan (Google Brain and Princeton University) &middot; Sham Kakade (University of Washington) &middot; Karan Singh (Princeton University) &middot; Abby Van Soest (Princeton University)</i></p>
      <p><b>Hierarchical Importance Weighted Autoencoders</b><br><i>Chin-Wei Huang (MILA) &middot; Kris Sankaran (Mila) &middot; Eeshan Dhekane (MILA, Université de Montréal) &middot; Alexandre Lacoste (Element AI) &middot; Aaron Courville (Université de Montréal)</i></p>
      <p><b>Conditional Independence in Testing Bayesian Networks</b><br><i>Yujia Shen (UCLA) &middot; Haiying Huang (UCLA) &middot; Arthur Choi (UCLA) &middot; Adnan Darwiche (UCLA)</i></p>
      <p><b>Beyond Backprop: Online Alternating Minimization with Auxiliary Variables</b><br><i>Anna Choromanska (New York University) &middot; Benjamin Cowen (NYU) &middot; Sadhana Kumaravel (IBM Research) &middot; Ronny Luss (IBM Research) &middot; Mattia Rigotti (IBM Research AI) &middot; Irina Rish (IBM Research AI) &middot; Paolo DiAchille (IBM Research) &middot; Viatcheslav  Gurev (IBM Research) &middot; Brian Kingsbury (IBM Research) &middot; Ravi Tejwani (IBM T.J. Watson Research Center) &middot; Djallel Bouneffouf (IBM Research)</i></p>
      <p><b>Deep Compressed Sensing</b><br><i>Yan Wu (DeepMind) &middot; Mihaela Rosca (DeepMind) &middot; Timothy Lillicrap (Google DeepMind)</i></p>
      <p><b>Multi-Object Representation Learning with Iterative Variational Inference</b><br><i>Klaus Greff (-) &middot; Raphael Lopez Kaufman (Deepmind) &middot; Rishabh Kabra (DeepMind) &middot; Nicholas Watters (DeepMind) &middot; Christopher Burgess (DeepMind) &middot; Daniel Zoran (DeepMind) &middot; Loic Matthey (DeepMind) &middot; Matthew Botvinick (DeepMind) &middot; Alexander Lerchner (DeepMind)</i></p>
      <p><b>A fully differentiable beam search decoder</b><br><i>Ronan Collobert (Facebook AI Research) &middot; Awni Hannun () &middot; Gabriel Synnaeve (Facebook AI Research)</i></p>
      <p><b>Breaking the Softmax Bottleneck via Learnable Monotonic Pointwise Non-linearities</b><br><i>Octavian-Eugen Ganea (ETH Zurich) &middot; Sylvain Gelly (Google Brain) &middot; Aliaksei Severyn (Google) &middot; Gary Becigneul (ETHZ)</i></p>
      <p><b>On variational bounds of mutual information</b><br><i>Ben Poole (Google Brain) &middot; Sherjil Ozair (University of Montreal) &middot; Aäron van den Oord (Google Deepmind) &middot; Alexander Alemi (Google) &middot; George Tucker (Google Brain)</i></p>
      <p><b>DL2: Training and Querying Neural Networks with Logic</b><br><i>Marc Fischer (ETH Zurich) &middot; Mislav Balunovic (ETH Zurich) &middot; Dana Drachsler-Cohen (ETH Zurich) &middot; Timon Gehr (ETH Zurich) &middot; Ce Zhang (ETH Zurich) &middot; Martin Vechev (ETH Zurich)</i></p>
      <p><b>Learning to Generalize from Sparse and Underspecified Rewards</b><br><i>Rishabh Agarwal (Google AI) &middot; Chen Liang (Google Brain) &middot; Dale Schuurmans (Google / University of Alberta) &middot; Mohammad Norouzi (Google Brain)</i></p>